# 머신러닝 Ch1 {.unnumbered}

머신러닝 기초

## 하이퍼파라미터

머신러닝에 이용할 모델에 대한 파리미터($\alpha,\beta$ 등)가 아닌,

학습알고리즘의 파라미터(학습률 등)

$\hat{y}=\beta_0+\beta_1x_1+\dotsm+\beta_kx_k$

여기서, $\beta_n$은 파라미터이며 주어진 데이터를 학습하여 파라미터를 산출하는 것임.

근데 만약에 모델 성능 향상을 위해 각 $\beta$의 제약조건(constraint)를 정한다?

해당 제약조건은 하이퍼파라미터(hyper-parameter, h-para)가 되는 것임

이런 회귀분석을 릿지(Ridge regression)이라고 함.

## 모델의 평가와 검증

![](image/model complexity.png)

낮은 복잡도 = 선형회귀분석 or logistic 분류면
높은 복잡도 = 변수를 추가한 모델 (과대적합 케이스)

훈련데이터(training sample)은 복잡도가 높아질수록 예측오차가 줄어듬 (우하향)

평가데이터(text sample)은 복잡도가 높아지면 오차가 줄어들기는 하지만,

너무 복잡도가 높아지면 평가데이터에서는 오차가 오히려 발생함

즉, 일반화가 어렵고 과대적합(overfitting) 문제가 발생함

## 일반화 오차

평가데이터를 이용하였을 때 발생하는 오차를 **일반화 오차**라고 함

(Generalization error, test error)

$$일반화 오차 = 편향^2+분산+오차$$

### 편향(Bias)

모집단에서 크기 m의 (x,y) 순서쌍을 샘플링할 때,

해당 샘플링을 n번 반복해서 모델링을 한다고 하면,

각각의 $f_1,...,f_n$이 있을 것이고, $\bar{f}=mean(f_m)$이면,

**실제 모집단을 나타내는 모델인 $f_{true}$와 $\bar{f}$의 차이를 편향(bias)**이라고 합니다.

### 분산(Variance)

한편, $f_1,...,f_n$의 추정모델간의 편차의 제곱합이 분산이 됩니다.

### 관계

즉, 모델이 단순할수록 실제로는 더 복잡한 모델을 잘 반영하기 어렵기때문에 편향이 큰 대신,

추정모델간의 오차는 작아지므로 분산이 작습니다.

하지만, 모델이 복잡할수록 추정모델을 평균하면 실제 모델과 유사해질 것 이므로 편향은 작고,

추정모델간의 오차는 클 것이므로 분산이 큽니다.

## 데이터의 분할 방법

### Hold-out 방식

주어진 자료를 목적에 따라 훈련/검증/평가 데이터로 나누어서 활용.

(훈련, 검증이 8~90% / 평가가 1~20%)

검증데이터는 h-para tuning에 주로 사용함.

1. 각 h-para별로 훈련데이터를 통해 모델 도출
2. 각 모델에 대해 검증데이터를 이용해 평가 (MSE 산출)
3. 성능이 가장 좋은 h-para를 채택
4. 해당 h-para 및 훈련+검증데이터를 통해 최종모델 도출
5. 평가데이터를 이용해 최종모델을 평가하여 성능 확인

단점 : 전체 데이터에서 평가데이터는 따로 빼놔야해서 자료가 충분치 않으면 사용하기 애매함

### K-fold 교차검증(Cross-validation) 방식을 이용한 검증

데이터가 그다지 많지 않을때 유용.

모든 데이터가 훈련, 검증, 평가에 활용될 수 있음.

주어진 자료를 K개로 분할하여 반복활용

(3-fold cv 예시)

1. 주어진 자료를 3개로 분할 (1,2 훈련 + 3 검증 / 1,3 훈련 + 2 검증 / 2,3 훈련 + 1 검증)
2. 각 분할데이터로 특정 h-para에 대해 훈련 + 검증데이터로 성능 평가(MSE)
3. 3개의 분할데이터의 성능의 평균이 해당 h-para의 검증결과임
4. 모든 h-para에 대해 1~3 반복
5. h-para의 검증결과 중 가장 성능이 좋은 h-para 채택

6. 다시 주어진 자료를 3개로 분할 (훈련+평가)
7. 각 분할데이터로 훈련 및 평가를 통해 성능 평가
8. 성능의 평균값이 우리의 모델의 성능임.

방법론에 따라 한꺼번에 훈련시켜서 성능을 평가하기도 하고,

이러한 분할(folding)을 수회~수백회 반복해서 모델의 성능을 추정하기도 함.

(folding별 성능의 평균/표준편차 고려)

::: {.callout}
머신러닝으로 분류문제를 해결하는 경우,

실제 세상에서는 분류대상의 비율이 매우 적은 경우가 많음.

이러한 샘플을 imbalanced data라고 하며,

Hold-out, K-fold cv 등을 할 때,

원 자료의 분류대상의 비율을 유지한채로 주어진 자료를 분할해야 함.
:::
