[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "KAIST MFE, 2024 Fall",
    "section": "",
    "text": "Welcome!\n안녕하세요, KAIST MFE 24년 가을학기에 이수한 과목의 과제 등을 정리해두었습니다.",
    "crumbs": [
      "Welcome!"
    ]
  },
  {
    "objectID": "머신러닝1.html",
    "href": "머신러닝1.html",
    "title": "머신러닝 Ch1",
    "section": "",
    "text": "하이퍼파라미터\n머신러닝에 이용할 모델에 대한 파리미터(\\(\\alpha,\\beta\\) 등)가 아닌,\n학습알고리즘의 파라미터(학습률 등)\n\\(\\hat{y}=\\beta_0+\\beta_1x_1+\\dotsm+\\beta_kx_k\\)\n여기서, \\(\\beta_n\\)은 파라미터이며 주어진 데이터를 학습하여 파라미터를 산출하는 것임.\n근데 만약에 모델 성능 향상을 위해 각 \\(\\beta\\)의 제약조건(constraint)를 정한다?\n해당 제약조건은 하이퍼파라미터(hyper-parameter, h-para)가 되는 것임\n이런 회귀분석을 릿지(Ridge regression)이라고 함.",
    "crumbs": [
      "머신러닝('24 가을)",
      "머신러닝 Ch1"
    ]
  },
  {
    "objectID": "머신러닝1.html#모델의-평가와-검증",
    "href": "머신러닝1.html#모델의-평가와-검증",
    "title": "머신러닝 Ch1",
    "section": "모델의 평가와 검증",
    "text": "모델의 평가와 검증\n\n낮은 복잡도 = 선형회귀분석 or logistic 분류면 높은 복잡도 = 변수를 추가한 모델 (과대적합 케이스)\n훈련데이터(training sample)은 복잡도가 높아질수록 예측오차가 줄어듬 (우하향)\n평가데이터(text sample)은 복잡도가 높아지면 오차가 줄어들기는 하지만,\n너무 복잡도가 높아지면 평가데이터에서는 오차가 오히려 발생함\n즉, 일반화가 어렵고 과대적합(overfitting) 문제가 발생함",
    "crumbs": [
      "머신러닝('24 가을)",
      "머신러닝 Ch1"
    ]
  },
  {
    "objectID": "머신러닝1.html#일반화-오차",
    "href": "머신러닝1.html#일반화-오차",
    "title": "머신러닝 Ch1",
    "section": "일반화 오차",
    "text": "일반화 오차\n평가데이터를 이용하였을 때 발생하는 오차를 일반화 오차라고 함\n(Generalization error, test error)\n\\[일반화 오차 = 편향^2+분산+오차\\]\n\n편향(Bias)\n모집단에서 크기 m의 (x,y) 순서쌍을 샘플링할 때,\n해당 샘플링을 n번 반복해서 모델링을 한다고 하면,\n각각의 \\(f_1,...,f_n\\)이 있을 것이고, \\(\\bar{f}=mean(f_m)\\)이면,\n실제 모집단을 나타내는 모델인 \\(f_{true}\\)와 \\(\\bar{f}\\)의 차이를 편향(bias)이라고 합니다.\n\n\n분산(Variance)\n한편, \\(f_1,...,f_n\\)의 추정모델간의 편차의 제곱합이 분산이 됩니다.\n\n\n관계\n즉, 모델이 단순할수록 실제로는 더 복잡한 모델을 잘 반영하기 어렵기때문에 편향이 큰 대신,\n추정모델간의 오차는 작아지므로 분산이 작습니다.\n하지만, 모델이 복잡할수록 추정모델을 평균하면 실제 모델과 유사해질 것 이므로 편향은 작고,\n추정모델간의 오차는 클 것이므로 분산이 큽니다.",
    "crumbs": [
      "머신러닝('24 가을)",
      "머신러닝 Ch1"
    ]
  },
  {
    "objectID": "머신러닝1.html#데이터의-분할-방법",
    "href": "머신러닝1.html#데이터의-분할-방법",
    "title": "머신러닝 Ch1",
    "section": "데이터의 분할 방법",
    "text": "데이터의 분할 방법\n\nHold-out 방식\n주어진 자료를 목적에 따라 훈련/검증/평가 데이터로 나누어서 활용.\n(훈련, 검증이 8~90% / 평가가 1~20%)\n검증데이터는 h-para tuning에 주로 사용함.\n\n각 h-para별로 훈련데이터를 통해 모델 도출\n각 모델에 대해 검증데이터를 이용해 평가 (MSE 산출)\n성능이 가장 좋은 h-para를 채택\n해당 h-para 및 훈련+검증데이터를 통해 최종모델 도출\n평가데이터를 이용해 최종모델을 평가하여 성능 확인\n\n단점 : 전체 데이터에서 평가데이터는 따로 빼놔야해서 자료가 충분치 않으면 사용하기 애매함\n\n\nK-fold 교차검증(Cross-validation) 방식을 이용한 검증\n데이터가 그다지 많지 않을때 유용.\n모든 데이터가 훈련, 검증, 평가에 활용될 수 있음.\n주어진 자료를 K개로 분할하여 반복활용\n(3-fold cv 예시)\n\n주어진 자료를 3개로 분할 (1,2 훈련 + 3 검증 / 1,3 훈련 + 2 검증 / 2,3 훈련 + 1 검증)\n각 분할데이터로 특정 h-para에 대해 훈련 + 검증데이터로 성능 평가(MSE)\n3개의 분할데이터의 성능의 평균이 해당 h-para의 검증결과임\n모든 h-para에 대해 1~3 반복\nh-para의 검증결과 중 가장 성능이 좋은 h-para 채택\n다시 주어진 자료를 3개로 분할 (훈련+평가)\n각 분할데이터로 훈련 및 평가를 통해 성능 평가\n성능의 평균값이 우리의 모델의 성능임.\n\n방법론에 따라 한꺼번에 훈련시켜서 성능을 평가하기도 하고,\n이러한 분할(folding)을 수회~수백회 반복해서 모델의 성능을 추정하기도 함.\n(folding별 성능의 평균/표준편차 고려)\n\n\n\n\n\n\n머신러닝으로 분류문제를 해결하는 경우,\n실제 세상에서는 분류대상의 비율이 매우 적은 경우가 많음.\n이러한 샘플을 imbalanced data라고 하며,\nHold-out, K-fold cv 등을 할 때,\n원 자료의 분류대상의 비율을 유지한채로 주어진 자료를 분할해야 함.",
    "crumbs": [
      "머신러닝('24 가을)",
      "머신러닝 Ch1"
    ]
  },
  {
    "objectID": "머신러닝2.html",
    "href": "머신러닝2.html",
    "title": "머신러닝 Ch2-3",
    "section": "",
    "text": "규제가 있는 선형회귀",
    "crumbs": [
      "머신러닝('24 가을)",
      "머신러닝 Ch2-3"
    ]
  },
  {
    "objectID": "머신러닝2.html#규제가-있는-선형회귀",
    "href": "머신러닝2.html#규제가-있는-선형회귀",
    "title": "머신러닝 Ch2-3",
    "section": "",
    "text": "릿지회귀모형\nL2 규제를 사용하여 파라미터의 범위를 제약\n비용함수 : \\(J(\\theta)=\\frac{1}{2m}(\\sum_{i=1}^m(\\theta^Tx^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^n\\theta_j^2)\\)\n파라미터 추정치는, \\(\\hat\\theta^R=arg\\min_\\theta J(\\theta)\\)\n행렬식 : \\(\\hat\\theta^R=arg\\min_\\theta\\{\\frac{1}{2m}(X\\theta-y)^T(X\\theta-y)+\\lambda\\theta_1^T\\theta_1\\}\\)\nAlter : \\(\\hat\\theta^R=arg\\min_\\theta\\{\\frac{1}{2m}(X\\theta-y)^T(X\\theta-y)\\}\\;subject\\;to\\;\\sum_{j=1}^n\\theta_j^2\\leq t\\)\n즉, 파라미터 제곱합에 일정 상한을 정해놓는 방식으로 보면 됨.\n람다가 커지면? 파라미터 제약이 커지면서 편향이 증가함\n\n파라미터 추정치 계산\n정규방정식 : \\(\\hat\\theta^R=(X^TX+\\lambda I)^{-1}X^Ty\\)\n일반 회귀모형에서는 \\(X^TX\\)가 singular이면 해가 없었으나, 릿지제약 하에서는 이를 해결할 수 있음.\n또한, 다중공선성(multicolinearity)도 해결할 수 있다는 것이 알려져 있음.\n경사하강법 : \\(\\theta_{new}=\\theta_{old}-\\alpha\\,\\triangledown J(\\theta)=(1-\\alpha\\frac{\\lambda}{m})\\theta_{old}-\\alpha\\,\\triangledown J^U(\\theta)\\)\n마지막 식은, 일반선형회귀의 그레디언트를 이용해서 표현한 것이며, 직전 \\(\\theta_{old}\\)의 영향을 상수배로 줄여주는 것으로 해석할 수 있음.\n\n\n\n라쏘회귀모형\nL1 규제를 이용. Least Absolute Shrinkage & Selection Operator\n모델로 널리 이용되지는 않지면, feature가 너무 많은 경우 적절한 변수만 선택할 때 많이 이용됨.\n비용함수 : \\(J(\\theta)=\\frac{1}{2m}(\\sum_{i=1}^m(\\theta^Tx^{(i)}-y^{(i)})^2+\\lambda\\sum_{j=1}^n|\\theta_j|)\\)\n파라미터 추정치는, \\(\\hat\\theta^L=arg\\min_\\theta J(\\theta)\\)\n행렬식 : \\(\\hat\\theta^L=arg\\min_\\theta\\{\\frac{1}{2m}(X\\theta-y)^T(X\\theta-y)+\\lambda 1^T|\\theta_1|\\}\\)\nAlter : \\(\\hat\\theta^L=arg\\min_\\theta\\{\\frac{1}{2m}(X\\theta-y)^T(X\\theta-y)\\}\\;subject\\;to\\;\\sum_{j=1}^n|\\theta_j|\\leq t\\)\n함수꼴에서 보듯, 미분불가능하므로 closed form solution이 존재하지 않음.\n다만, \\(\\theta\\)의 부호에 따라 절대값의 미분값은 -1 또는 1이므로 첨값의 미분값이 0이라고 가정하면 다음과 같이 표현가능함.\n\\(\\theta_{new}\\leftarrow \\theta_{old}-\\alpha\\,\\triangledown J(\\theta_{old})=\\theta_{old}-\\alpha\\bigl(\\triangledown J^U(\\theta_{old})-\\lambda_{(=\\frac{\\lambda}{2m})}\\;sign(\\theta_{old})\\bigr)\\)\n\\(for\\;sign(\\theta)=\\frac{|\\theta|}{\\theta}\\;or\\;0\\;where\\;\\theta=0\\)\n즉, 원점을 향해 일정부분() 계속 보정이 들어가는 형태.\n\n\n비교\n릿지회귀모형 vs. 라쏘회귀모형\n해석력 : 라쏘\n예측력 : 기본적으로, 규제가 생기면 예측력이 증가하긴 함. 어떤 모형이 예측력이 뛰어난지는 데이터에 따라 달려있음\n만약 feature의 수가 샘플의 수보다 작으면, 라쏘를 쓰면 안됌",
    "crumbs": [
      "머신러닝('24 가을)",
      "머신러닝 Ch2-3"
    ]
  },
  {
    "objectID": "머신러닝실습.html",
    "href": "머신러닝실습.html",
    "title": "1  머신러닝 실습",
    "section": "",
    "text": "1.1 Ch2. Linear regression\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.datasets import load_diabetes\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error, r2_score\ndiabetes = load_diabetes()\ndiabetes_DF = pd.DataFrame( diabetes['data'], columns=diabetes['feature_names'])\ndiabetes_DF['Y']=diabetes['target']\ndiabetes_DF.head(5)\n\n\n\n\n\n\n\n\n\nage\nsex\nbmi\nbp\ns1\ns2\ns3\ns4\ns5\ns6\nY\n\n\n\n\n0\n0.038076\n0.050680\n0.061696\n0.021872\n-0.044223\n-0.034821\n-0.043401\n-0.002592\n0.019907\n-0.017646\n151.0\n\n\n1\n-0.001882\n-0.044642\n-0.051474\n-0.026328\n-0.008449\n-0.019163\n0.074412\n-0.039493\n-0.068332\n-0.092204\n75.0\n\n\n2\n0.085299\n0.050680\n0.044451\n-0.005670\n-0.045599\n-0.034194\n-0.032356\n-0.002592\n0.002861\n-0.025930\n141.0\n\n\n3\n-0.089063\n-0.044642\n-0.011595\n-0.036656\n0.012191\n0.024991\n-0.036038\n0.034309\n0.022688\n-0.009362\n206.0\n\n\n4\n0.005383\n-0.044642\n-0.036385\n0.021872\n0.003935\n0.015596\n0.008142\n-0.002592\n-0.031988\n-0.046641\n135.0\ndiabetes_DF.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 442 entries, 0 to 441\nData columns (total 11 columns):\n #   Column  Non-Null Count  Dtype  \n---  ------  --------------  -----  \n 0   age     442 non-null    float64\n 1   sex     442 non-null    float64\n 2   bmi     442 non-null    float64\n 3   bp      442 non-null    float64\n 4   s1      442 non-null    float64\n 5   s2      442 non-null    float64\n 6   s3      442 non-null    float64\n 7   s4      442 non-null    float64\n 8   s5      442 non-null    float64\n 9   s6      442 non-null    float64\n 10  Y       442 non-null    float64\ndtypes: float64(11)\nmemory usage: 38.1 KB\ny_target = diabetes_DF['Y']\nX_data = diabetes_DF.drop(['Y'], axis=1, inplace=False)\nX_train, X_test, y_train, y_test = train_test_split(\nX_data, y_target, test_size=0.4, random_state=123 )\nlr = LinearRegression()\nlr.fit ( X_train, y_train )\n\nLinearRegression()In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.  LinearRegression?Documentation for LinearRegressioniFittedLinearRegression()\nlr.intercept_\n\n151.71551041484278\nnp.round( lr.coef_, decimals=1)\n\narray([ -11.1, -291.1,  553.8,  296.6, -915. ,  528.4,  210.2,  339.6,\n        640.6,  115.7])\ncoeff = pd.Series( data= np.round( lr.coef_, decimals=1), index=X_data.columns )\ncoeff.sort_values(ascending=False)\n\ns5     640.6\nbmi    553.8\ns2     528.4\ns4     339.6\nbp     296.6\ns3     210.2\ns6     115.7\nage    -11.1\nsex   -291.1\ns1    -915.0\ndtype: float64\ny_preds = lr.predict( X_test )\nmse = mean_squared_error( y_test, y_preds )\nrmse = np.sqrt( mse )\nrmse\n\n55.09404732888505\nr2 = r2_score( y_test, y_preds )\nr2\n\n0.4933408690435077\ny_train_preds = lr.predict( X_train )\nmse_train = mean_squared_error( y_train, y_train_preds )\nrmse_train = np.sqrt( mse_train )\nrmse_train\n\n52.9486429330168\nr2_train = r2_score( y_train, y_train_preds )\nr2_train\n\n0.5237974491641986\nfrom sklearn.model_selection import KFold\nkf = KFold(n_splits=5, shuffle=True )\nkfid = kf.split(X_data)\nkf_mse = []\nfor train_i, test_i in kfid:\n    X_trn, X_tst = X_data.iloc[train_i], X_data.iloc[test_i]\n    y_trn, y_tst = y_target.iloc[train_i], y_target.iloc[test_i]\n    lr = LinearRegression()\n    lr.fit ( X_trn, y_trn )\n    y_preds = lr.predict( X_tst )\n    mse = mean_squared_error( y_tst, y_preds )\n    kf_mse.append(mse)\nkf_mse\n\n[2473.5516319387098,\n 3233.267125885358,\n 3553.038452271323,\n 2979.5920996281343,\n 2621.972092449679]\n# 잘 안쓰고 아래꺼 K-fold api를 많이 씀\nkf_rmse = np.sqrt(kf_mse)\nnp.mean(kf_rmse)\n\n54.398968609104465\nfrom sklearn.model_selection import cross_val_score\nneg_mse_scores= cross_val_score(lr, X_data, y_target,\n                                scoring='neg_mean_squared_error', cv=5)\nrmse_scores = np.sqrt( -1 * neg_mse_scores ) # 지표는 값이 큰 것을 선택하도록 내부적으로 (-) 변환\nrmse_scores\n\narray([52.72497937, 55.03486476, 56.90068179, 54.85204179, 53.94638716])\nnp.mean( rmse_scores )\n\n54.69179097275793\n# 변수 표준화\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ndX=diabetes['data']\ndy=diabetes['target']\nscaler.fit( dX )\ndiabetes_X_scaled = scaler.transform( dX )\nnp.round( diabetes_X_scaled[:3], decimals=2 )\n\narray([[ 0.8 ,  1.07,  1.3 ,  0.46, -0.93, -0.73, -0.91, -0.05,  0.42,\n        -0.37],\n       [-0.04, -0.94, -1.08, -0.55, -0.18, -0.4 ,  1.56, -0.83, -1.44,\n        -1.94],\n       [ 1.79,  1.07,  0.93, -0.12, -0.96, -0.72, -0.68, -0.05,  0.06,\n        -0.55]])\nfrom sklearn.linear_model import SGDRegressor\nsgd_reg = SGDRegressor ( max_iter=50, penalty=None, eta0=0.1 )\nsgd_reg.fit( diabetes_X_scaled, dy )\nprint(sgd_reg.intercept_, np.round( sgd_reg.coef_, decimals=1), sep=\"\\n\")\n\n[153.41928257]\n[ -0.2 -12.2  23.5  14.  -26.7  14.2   2.1   5.7  38.2   2.7]",
    "crumbs": [
      "머신러닝('24 가을)",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>머신러닝 실습</span>"
    ]
  },
  {
    "objectID": "머신러닝실습.html#ch3.-restricted-linear-regression",
    "href": "머신러닝실습.html#ch3.-restricted-linear-regression",
    "title": "1  머신러닝 실습",
    "section": "1.2 Ch3. Restricted linear regression",
    "text": "1.2 Ch3. Restricted linear regression\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn.datasets import load_diabetes\ndiabetes = load_diabetes()\ny_target = diabetes['target']\nX_data = diabetes['data']\n\n\n# 데이터 분리\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(\nX_data, y_target, test_size=0.4, random_state=123 )\n\n\n# 규제 선형회귀에서는 반드시 표준화를 해야함\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit( X_train )\nX_train = scaler.transform( X_train )\nX_test = scaler.transform( X_test )\n\n\n\n\n\n\n\n전체 데이터로 표준화하고 데이터를 분리하는 방법이 있고,\n데이터를 분리하고 훈련데이터로 표준화하는 방법이 있음. (교수님 선호)\n표준화하고 데이터를 분리하면 훈련 및 평가 각각에 대해서는 정확히 표준화는 안됌.\n데이터를 분리하고 표준화하는 경우, 훈련데이터는 정확히 평균 0 표준편차 1이 되지만, 평가데이터는 이를 만족하지 않게 됨.\n두 방식에 정답은 없으나, 훈련과 평가데이터를 각각 표준화하는 방법은 피해야 함.\n\n\n\n\n# Hyperparameter (람다) 튜닝\n# Cross validation, 5-fold\nfrom sklearn.linear_model import Ridge\nfrom sklearn.model_selection import cross_val_score\nalphas = [0, 0.01, 0.05, 0.1, 0.5, 1, 5]\nfor al in alphas:\n    ridge = Ridge(alpha=al)\n    neg_mse_scores = cross_val_score(ridge, X_train, y_train,\n                                     scoring='neg_mean_squared_error', cv=5)\n    avg_rmse = np.mean(np.sqrt(-1*neg_mse_scores))\n    print('alpha={} -&gt; RMSE={}'.format(al, np.around(avg_rmse, decimals=3)))\n\nalpha=0 -&gt; RMSE=55.733\nalpha=0.01 -&gt; RMSE=55.733\nalpha=0.05 -&gt; RMSE=55.732\nalpha=0.1 -&gt; RMSE=55.731\nalpha=0.5 -&gt; RMSE=55.733\nalpha=1 -&gt; RMSE=55.745\nalpha=5 -&gt; RMSE=55.812\n\n\n\nridge = Ridge(alpha=0.1)\nridge.fit( X_train, y_train )\nprint(ridge.coef_)\nprint(ridge.intercept_)\n\n[ -0.49870018 -13.84726064  27.2454048   14.23003902 -42.90654351\n  24.39457638   9.53842023  16.72293446  30.53624211   5.88303717]\n152.9811320754717\n\n\n\n# 일반화 성능 평가\ny_preds = ridge.predict( X_test )\nfrom sklearn.metrics import mean_squared_error\nnp.sqrt( mean_squared_error(y_test, y_preds) )\n\n55.089852137313954\n\n\n\nfig, axs = plt.subplots(figsize=(18,6), nrows=1, ncols=len(alphas))\ncoeff_df = pd.DataFrame()\nfor pos, al in enumerate(alphas):\n    ridge = Ridge(alpha=al)\n    ridge.fit ( X_train, y_train)\n    coeff = pd.Series(data=ridge.coef_, index=diabetes['feature_names'])\n    coeff = coeff.sort_values(ascending=False)\n    colname = 'alpha:'+str(al)\n    axs[pos].set_title(colname)\n    axs[pos].set_xlim(-50,50)\n    sns.barplot( x=coeff.values, y=coeff.index, ax=axs[pos])\n    coeff_df[colname]=coeff\n\n\n\n\n\n\n\n\n\ncoeff_df\n\n\n\n\n\n\n\n\n\nalpha:0\nalpha:0.01\nalpha:0.05\nalpha:0.1\nalpha:0.5\nalpha:1\nalpha:5\n\n\n\n\ns5\n31.138611\n31.076226\n30.831553\n30.536242\n28.526648\n26.658856\n20.679753\n\n\nbmi\n27.225471\n27.227572\n27.235733\n27.245405\n27.305084\n27.347486\n27.247605\n\n\ns2\n25.651076\n25.520922\n25.010508\n24.394576\n20.207359\n16.324820\n4.084076\n\n\ns4\n16.927558\n16.906456\n16.823497\n16.722934\n16.023963\n15.344355\n12.722315\n\n\nbp\n14.248636\n14.246725\n14.239197\n14.230039\n14.165214\n14.099670\n13.796797\n\n\ns3\n10.239273\n10.166744\n9.882164\n9.538420\n7.190375\n4.990229\n-2.289360\n\n\ns6\n5.880362\n5.880633\n5.881709\n5.883037\n5.893123\n5.904725\n5.981982\n\n\nage\n-0.508127\n-0.507153\n-0.503328\n-0.498700\n-0.466811\n-0.436305\n-0.321278\n\n\nsex\n-13.873897\n-13.871166\n-13.860395\n-13.847261\n-13.753227\n-13.655907\n-13.164133\n\n\ns1\n-44.504536\n-44.339080\n-43.690071\n-42.906544\n-37.568138\n-32.593582\n-16.514538\n\n\n\n\n\n\n\n\n\n# 하이퍼파라미터 튜닝을 자동으로 해주는 함수임\n# score를 array로 제공하는것 뿐만 아니라, fold별 평균/분산 계산 및 model selection까지 완수\nfrom sklearn.model_selection import GridSearchCV\nparameters={'alpha': [0, 0.01, 0.05, 0.1, 0.5, 1, 5]}\nridge = Ridge( )\ngrid_ridge = GridSearchCV ( ridge, param_grid=parameters, cv=5,\nscoring='neg_mean_squared_error',refit=True)\ngrid_ridge.fit( X_train, y_train )\nscores_df = pd.DataFrame( grid_ridge.cv_results_)\nscores_df.iloc [:, 5:]\n# test score는 validation data로 평가한 score(-mse)임\n# std는 split별 score의 표준편차\n\n\n\n\n\n\n\n\n\nparams\nsplit0_test_score\nsplit1_test_score\nsplit2_test_score\nsplit3_test_score\nsplit4_test_score\nmean_test_score\nstd_test_score\nrank_test_score\n\n\n\n\n0\n{'alpha': 0}\n-3464.061113\n-3073.496800\n-2249.443435\n-3714.684946\n-3135.462679\n-3127.429794\n496.391499\n6\n\n\n1\n{'alpha': 0.01}\n-3463.952339\n-3072.933041\n-2249.812087\n-3714.461827\n-3135.734131\n-3127.378685\n496.206755\n4\n\n\n2\n{'alpha': 0.05}\n-3463.536751\n-3070.771202\n-2251.269676\n-3713.589310\n-3136.808917\n-3127.195171\n495.480636\n3\n\n\n3\n{'alpha': 0.1}\n-3463.057920\n-3068.263953\n-2253.053928\n-3712.540867\n-3138.126372\n-3127.008608\n494.600544\n2\n\n\n4\n{'alpha': 0.5}\n-3460.381708\n-3053.879193\n-2265.950063\n-3705.435057\n-3147.526552\n-3126.634515\n488.447499\n1\n\n\n5\n{'alpha': 1}\n-3458.580847\n-3044.029474\n-2279.280902\n-3698.531771\n-3156.575986\n-3127.399796\n482.282104\n5\n\n\n6\n{'alpha': 5}\n-3451.286784\n-3025.938931\n-2341.662894\n-3662.319607\n-3180.549641\n-3132.351571\n451.978114\n7\n\n\n\n\n\n\n\n\n\n# Random split 후에 튜닝하므로 위와 최적파라미터가 달라질 수 있음.\nprint(grid_ridge.best_params_)\nprint(grid_ridge.best_score_)\n\n{'alpha': 0.5}\n-3126.6345147986067\n\n\n\nridge_update = grid_ridge.best_estimator_\nridge_update.coef_\n\narray([ -0.46681102, -13.75322724,  27.30508411,  14.16521425,\n       -37.56813822,  20.20735883,   7.19037502,  16.02396254,\n        28.52664799,   5.89312283])\n\n\n\ny_pred = ridge_update.predict( X_test )\nnp.sqrt( mean_squared_error(y_test, y_preds) )\n\n55.089852137313954\n\n\n\nfrom sklearn.linear_model import Lasso\nalphas = [0.01, 0.1, 0.5, 1, 5]\nfig, axs = plt.subplots(figsize=(18,6), nrows=1, ncols=len(alphas))\ncoeff_df = pd.DataFrame()\nfor pos, al in enumerate(alphas):\n    lasso = Lasso( alpha=al, max_iter=1000 )\n    lasso.fit ( X_train, y_train)\n    coeff = pd.Series(data=lasso.coef_, index=diabetes['feature_names'])\n    coeff = coeff.sort_values(ascending=False)\n    colname = 'alpha:'+str(al)\n    axs[pos].set_title(colname)\n    axs[pos].set_xlim(-50,50)\n    sns.barplot( x=coeff.values, y=coeff.index, ax=axs[pos])\n    coeff_df[colname]=coeff\n\n\n\n\n\n\n\n\n\ncoeff_df\n\n\n\n\n\n\n\n\n\nalpha:0.01\nalpha:0.1\nalpha:0.5\nalpha:1\nalpha:5\n\n\n\n\ns5\n30.609704\n25.856091\n18.926493\n18.536744\n16.632402\n\n\nbmi\n27.241961\n27.390066\n27.770736\n27.646424\n27.100696\n\n\ns2\n24.527593\n14.429899\n0.000000\n-0.000000\n-0.000000\n\n\ns4\n16.680089\n14.454782\n12.209271\n8.424945\n0.000000\n\n\nbp\n14.221648\n13.978915\n13.382554\n12.793145\n8.933273\n\n\ns3\n9.557877\n3.432768\n-3.656929\n-6.063158\n-7.745877\n\n\ns6\n5.870014\n5.776940\n5.495434\n5.087787\n2.467916\n\n\nage\n-0.486420\n-0.291130\n-0.000000\n-0.000000\n0.000000\n\n\nsex\n-13.844396\n-13.579080\n-12.450801\n-11.420067\n-3.496842\n\n\ns1\n-43.043735\n-29.913885\n-11.357006\n-8.203584\n-0.000000",
    "crumbs": [
      "머신러닝('24 가을)",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>머신러닝 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝1.html",
    "href": "딥러닝1.html",
    "title": "딥러닝 Ch1",
    "section": "",
    "text": "머신러닝 알고리즘의 구분",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch1"
    ]
  },
  {
    "objectID": "딥러닝1.html#머신러닝-알고리즘의-구분",
    "href": "딥러닝1.html#머신러닝-알고리즘의-구분",
    "title": "딥러닝 Ch1",
    "section": "",
    "text": "지도학습\n입력값에 대한 결과값이 주어진 경우,\n모델이 입력값과 결과값을 모두 알고 학습하여 새로운 입력값에 대한 적정 결과값 추정치를 제공하게 됨.\n결과값(label)이 숫자형이면 회귀(regression) 알고리즘, 범주형이면 분류(classification) 알고리즘으로 구분.\n\n\n비지도학습\n결과값이 없고, 주어진 입력값만으로 학습함.\n의미있는 패턴을 추출하는 것이 목적.\n군집화(행을 묶음) 및 차원축소(열을 묶어 열의 갯수를 감소시킴)에 주로 활용\n\n\n강화학습\n모델 자체가 어떠한 변화를 주도하는데,\n해당 변화에 따른 보상/패널티를 주는 환경을 구성함.\n모델은 이러한 변화에 따른 누적보상이 최대가 되도록하는 변화패턴을 학습함",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch1"
    ]
  },
  {
    "objectID": "딥러닝1.html#지도학습-알고리즘의-절차",
    "href": "딥러닝1.html#지도학습-알고리즘의-절차",
    "title": "딥러닝 Ch1",
    "section": "지도학습 알고리즘의 절차",
    "text": "지도학습 알고리즘의 절차\n\n전처리 및 탐색\n적절한 모델 선택\n주어진 데이터로 모델 훈련\n새로운 데이터를 통해 결과값을 예측하여 모델의 성능을 평가\n\n\n경사하강법 (Gradient Descent Method)\n다차원 선형회귀 모형에서 모델결과값과 실제결과값의 차이(MSE; Mean Square Error)를 최소화하는 방식\nMSE의 미분계수(Gradient)의 일정수준(학습률)만큼 선형회귀모형의 각 파라미터가 모두 감소하도록 지속 업데이트하면서,\n결과적으로 MSE의 Gradient가 0이 되면 학습이 종료되는 방식.\nMSE의 미분계수가 0이면 최솟값이고, 모델결과값의 오차가 최소가 되므로 가장 적정한 파라미터를 추론한 것으로 판단.\n\n경사하강법 종류\n한번의 회귀계수 업데이트에 모든 훈련데이터를 사용하면 배치 경사하강법\n임의추출로 하나의 훈련데이터만 사용하면 확률 경사하강법(SGD)\n일부만 사용하면 미니 경사하강법.\n많이 사용할수록 규칙적으로 MSE가 감소하고 일관적으로 움직이나, 산출시간이 오래걸리고, 지역최소값에 갇힐 가능성이 높아짐.",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch1"
    ]
  },
  {
    "objectID": "딥러닝1.html#모델-평가-및-검증",
    "href": "딥러닝1.html#모델-평가-및-검증",
    "title": "딥러닝 Ch1",
    "section": "모델 평가 및 검증",
    "text": "모델 평가 및 검증\nlow bias - high vol\nhigh bias - low vol\n제대로 못들어서 정리 필요\n\n자료의 구분\n일반적으로 전체 데이터를 임의로 3개로 나눔.\n훈련 데이터 / 검증 데이터 / 평가 데이터\ne.g. 훈련데이터로 여러 h-para에 대해 모델 돌림\n검증데이터를 이용해 각 h-para별 성능 평가\n제일 좋은 h-para로 모델을 구성하여 훈련+검증데이터로 다시 훈련\n최종 모델을 평가데이터를 이용하여 평가\n\n딥러닝에서는 검증데이터가 다른 의미로도 활용됨.\n경사하강법 같은걸 복잡한 모델에 사용할 때, 파라미터 튜닝 과정에서 손실함수가 더이상 감소하지 않는다면?\n불필요한 훈련이 될 수 있어 파라미터 자체가 학습이 잘 되고 있는지 모니터링을 해야 함.\n이러한 모니터링에 검증 데이터가 활용됨.\n\n\n모델의 평가를 위한 지표\n\n회귀모형, Regression model\nRMSE : \\(\\sqrt{MSE}\\)\nMAE(mean absolute error) : \\(\\frac{1}{n}\\sum_{i=1}^n|y_i-\\hat{y}_i|\\)\nR square(결정계수) : \\(1-\\frac{\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}{\\sum_{i=1}^n(y_i-\\bar{y})^2}=1-\\frac{SSE}{SST}(=\\frac{SSR}{SST})\\)\n\n\n분류모형\n정오분류표 : TN(true negative), TP(true positive), FN, FP\n정확도, 정분류율 (Accuracy) : \\(\\frac{TN+TP}{TN+TP+FN+FP}\\)\n오분류율 : 1 - 정분류율\n교차엔트로피 오차(Cross Entropy Error), Multiclass classification에 많이 씀\n\\[-\\frac{1}{n}\\sum_{i=1}^n\\sum_{k=1}^Ky_k^{(i)}log(\\hat{p}_k^(i))\\]\ny는 타깃확률, p는 예측확률, K는 범주의 개수\nK=2인 경우, 위의 교차엔트로피 손실함수를 로그손실함수라고 부르며, 많이 활용함.\n\n\n\n\n\n\n삼중분류문제의 경우,\n모델은 훈련자료를 기반으로 훈련 후 0,1,2에 각각 속할 확률을 계산하여 반환함.(\\(p_0+p_1+p_2=1\\))\n최종적으로 각 확률중 가장 큰 값을 \\(\\hat{y}\\)로 산출하게 됨.\n교차 엔트로피의 타깃 확률이란 1을 의미하며, 실제 y가 특정 범주 k에 속할 때 1이며, 아닐 때 0임.\n따라서, 교차엔트로피의 수식을 볼 때 타깃확률이 1이고 예측확률이 1에 가까울수록 오차는 0에 수렴하며\n예측확률이 1보다 작을수록 오차는 커지게 됨",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch1"
    ]
  },
  {
    "objectID": "딥러닝2.html",
    "href": "딥러닝2.html",
    "title": "딥러닝 Ch2",
    "section": "",
    "text": "퍼셉트론 (Perceptron)\n하나의 인공뉴런으로 구성된 신경망. 가장 기본적인 구조.\n주어진 데이터로 분류면을 찾는 것이 목표",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch2"
    ]
  },
  {
    "objectID": "딥러닝2.html#퍼셉트론-perceptron",
    "href": "딥러닝2.html#퍼셉트론-perceptron",
    "title": "딥러닝 Ch2",
    "section": "",
    "text": "로젠블랜의 퍼셉트론 (Simple perceptron)\n활성화함수 \\(f(.)\\)를 1 또는 -1를 가지는 임계함수로 구성.\ny = 1인데 f=-1인 경우, \\(w_i^*=w_i+x_i\\)\ny = -1인데 f=1인 경우, \\(w_i^*=w_i-x_i\\)\n즉, 실제는 1인데 \\(s=\\sum w_ix_i&lt;0\\)이 되어 임계가 -1로 출력되는 경우,\n\\(\\sum (w_i^*x_i+b^*_{(w^*_0x_0)})=\\sum (w_ix_i+x_i^2+b)\\)이 되어 s가 증가하는 방향으로 움직이게 됨.\n\n\n선형 퍼셉트론 (Linear perceptron)\n활성화함수로 선형함수를 사용함 \\(f(s)=s\\)\n파라미터 학습시 델타규칙(delta rule)을 사용하는데, 경사하강법(GDM)으로 보면 됨\nN개의 훈련자료 \\(D_N=\\{(x^{(d),y^{(d)}})\\}_{d=1}^N\\)에 대해 \\(f^{(d)}=\\sum_i w_ix_i^{(d)}\\)가 되며,\n학습오차 \\(E_d=\\frac{1}{2}(y^{(d)}-f(s)^{(d)})^2\\) 및 \\(E_N=\\sum E_d\\)\n(N으로 나누던 안나누던 파라미터 업데이트 결정에는 영향 없음)\n여기에 SGD(Stochastic Gredient Descent)를 적용하여 파라미터 업데이트\n\\(w_i\\leftarrow w_i+\\Delta w_i=w_i-\\eta \\frac{\\partial E_d}{\\partial w_i}=w_i+\\eta(y^{(d)}-f^{(d)})x_i\\)\n\n\n\n\n\n\n초기 델타규칙의 파라미터 업데이트는 경사하강법의 표현법이 아니였음.\n\\(w_i\\leftarrow w_i+\\eta ex_i\\;,\\;e=y-x_i\\) 방식으로 업데이트.\n결국 목적함수를 미분하면 해당 꼴이 나타나므로 경사하강법과 동일한 논리임.\n\n\n\n\n\n시그모이드 퍼셉트론 (Sigmoid perceptron)\n머신러닝의 logistic regression과 거의 유사함. (비용함수만 조금 다름)\n활성함수를 시그모이드 함수 \\(f=\\frac{1}{1+e^{-s}}\\in (0,1)\\)로 사용함.\n즉, y가 이진분류 문제일 때 y=1일 확률값을 예측해주는 모델임.\n어차피 퍼셉트론에서는 확률=0.5를 기준으로 분류하므로 선형분류면을 제공하지만,\n네트워크를 구성하면 비선형 경계면을 구성할 수도 있음.\n\\(f^{(d)}=\\sigma(s^{(d)})=\\frac{1}{1+e^{-s^{(d)}}}=\\frac{1}{1+e^{-\\sum w_ix^{(d)}_i}}\\)\n\\(E_d=\\frac{1}{2}(y^{(d)}-\\sigma(s^{(d)}))^2\\)\n\\(\\frac{\\partial E_d}{\\partial w_i}=(y^{(d)}-\\sigma^{(d)})\\sigma^{(s)}(1-\\sigma^{(s)})(-x_i^{(d)})\\)\n\\(\\therefore w_i^*\\;\\leftarrow\\;w_i+\\eta (y^{(d)}-f^{(d)})\\,f^{(s)}\\,(1-f^{(s)})x_i^{(d)}\\)\n\\(w_i\\)의 업데이트는 동시에 이루어져야함에 유의\n\n\n\n\n\n\n시그모이드 함수 미분\n\\(\\frac{d\\sigma(s)}{ds}=\\frac{+e^{-s}}{(1+e^{-s})^2}=\\sigma(s)(1-\\sigma(s))\\)",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch2"
    ]
  },
  {
    "objectID": "딥러닝2.html#다층-퍼셉트론-multi-layer-perceptron",
    "href": "딥러닝2.html#다층-퍼셉트론-multi-layer-perceptron",
    "title": "딥러닝 Ch2",
    "section": "다층 퍼셉트론 (Multi-layer perceptron)",
    "text": "다층 퍼셉트론 (Multi-layer perceptron)\nXOR문제 : \\((x_1,x_2,y)=(1,0,1),\\;(0,1,1),\\;(0,0,0),\\;(1,1,0)\\)\n기존 퍼셉트론은 이 간단한 XOR문제도 해결할 수 없음.\n여러개의 퍼셉트론을 여러 층으로 쌓는다면 이를 해결 가능함.\n선을 두개를 그어서 \\(z_1,z_2\\)를 구성하고, \\(f=z_1\\times z_2\\)를 최종 모델로 결정하면 문제 해결 가능.\n\n다층 퍼셉트론의 구조\n여러 개의 퍼셉트론 뉴런을 여러 층으로 쌓은 구조이며, 층 내에서 뉴런간 교류는 없음.\n입력 - 은닉 - 출력 다층퍼셉트론이 대표적인 구조. (I-H-K 다층퍼셉트론)\n입력층, 은닉층을 거쳐 출력층의 연산을 통해 최종적으로 값을 출력\n파라미터 학습은 각 층마다 가중치로 존재하므로, 실질적으로 층이 2개인 MLP라고 하기도 함.\n\n\n\n\n\n\ne.g. 10-3-1 MLP는?\n10개의 입력층(+1 bias항), 3개의 은닉층(+1 bias항), 1개의 출력층\n총 11개의 입력층과 3개의 은닉층이 모두 연결되어 총 33개의 연결이 생기고,\n4개의 은닉층과 1개의 출력층이 연결되어 4개의 연결이 생김. 전체 37개의 연결.\n\n\n\n층의 개수나 뉴런의 개수를 모두 돌려봐서 최적의 모델을 찾으면 좋지 않나?\n그러나, 딥러닝 모델은 하나의 학습에 많은 시간이 걸려서 그런식으로 하지 않고, 유사 사례를 참고하는 등 적정 모델을 초기부터 잘 설정해야할 필요가 있음.\n\n\n다층 퍼셉트론의 학습\n\n전향계산 Forward Calculation\n각 층간에는 퍼셉트론과 동일한 연산이 적용되며, 따라서 층이 많아질수록 계산이 기하급수적으로 증가.\n\nI-H-K MLP에서, I개의 입력층과 H개의 은닉층 사이에 \\(H\\times (I+1)\\)개의 가중치가 필요하며,\n은닉층과 출력층 사이에 \\(K\\times (H+1)\\)개의 가중치가 필요.\n이러한 가중치를 학습할 때 어떻게하는지? 오류역전파 알고리즘 사용\n\n\n오류역전파 알고리즘 Error back-propagation",
    "crumbs": [
      "딥러닝('24 가을)",
      "딥러닝 Ch2"
    ]
  },
  {
    "objectID": "딥러닝실습.html",
    "href": "딥러닝실습.html",
    "title": "2  딥러닝 Ch1 실습",
    "section": "",
    "text": "2.1 1. 텐서 데이터 만들기\nimport numpy as np\nimport tensorflow as tf\ntest = tf.constant( 123 ) # 텐서 상수. numpy array 같은 데이터타입임.\ntest\n\n&lt;tf.Tensor: shape=(), dtype=int32, numpy=123&gt;\nprint(test)\n\ntf.Tensor(123, shape=(), dtype=int32)\ntest.numpy()\n\n123\ntf.constant([1.2, 5, np.pi], dtype = tf.float32)\n\n&lt;tf.Tensor: shape=(3,), dtype=float32, numpy=array([1.2      , 5.       , 3.1415927], dtype=float32)&gt;\nndarr = np.array([[1,2,3], [4,5,6]])\nndarr\n\narray([[1, 2, 3],\n       [4, 5, 6]])\ntsarr = tf.convert_to_tensor( ndarr )\ntsarr\n\n&lt;tf.Tensor: shape=(2, 3), dtype=int64, numpy=\narray([[1, 2, 3],\n       [4, 5, 6]])&gt;\ntsones = tf.ones((2,3))\ntsones\n\n&lt;tf.Tensor: shape=(2, 3), dtype=float32, numpy=\narray([[1., 1., 1.],\n       [1., 1., 1.]], dtype=float32)&gt;",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#텐서-데이터-타입-크기",
    "href": "딥러닝실습.html#텐서-데이터-타입-크기",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.2 2. 텐서 데이터 타입, 크기",
    "text": "2.2 2. 텐서 데이터 타입, 크기\n\ntsarr.shape\n\nTensorShape([2, 3])\n\n\n\ntsarr.ndim\n\n2\n\n\n\ntsarr.dtype\n\ntf.int64\n\n\n\ntf.cast( tsarr, dtype=tf.float64 )\n\n&lt;tf.Tensor: shape=(2, 3), dtype=float64, numpy=\narray([[1., 2., 3.],\n       [4., 5., 6.]])&gt;\n\n\n\ntsarr[0]\n\n&lt;tf.Tensor: shape=(3,), dtype=int64, numpy=array([1, 2, 3])&gt;\n\n\n\ntsarr[:1,:1]\n\n&lt;tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[1]])&gt;\n\n\n\ntsarr[0,0]\n\n&lt;tf.Tensor: shape=(), dtype=int64, numpy=1&gt;\n\n\n\nt = tf.random.uniform(shape=(3,4)) # shape 생략 가능\nt\n\n&lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy=\narray([[0.27102935, 0.99095666, 0.82080793, 0.8639691 ],\n       [0.85583425, 0.93023646, 0.27964818, 0.6046418 ],\n       [0.6279595 , 0.66343117, 0.95931494, 0.633675  ]], dtype=float32)&gt;\n\n\n\nt.numpy()\n\narray([[0.27102935, 0.99095666, 0.82080793, 0.8639691 ],\n       [0.85583425, 0.93023646, 0.27964818, 0.6046418 ],\n       [0.6279595 , 0.66343117, 0.95931494, 0.633675  ]], dtype=float32)\n\n\n\ntnormal = tf.random.normal((3,4), mean = 0, stddev = 1)\ntnormal\n\n&lt;tf.Tensor: shape=(3, 4), dtype=float32, numpy=\narray([[-1.9991201e+00,  8.1910379e-02, -1.4346092e+00, -1.2580566e+00],\n       [-1.9888286e-01, -2.6047745e+00, -3.6573273e-01,  1.3136085e+00],\n       [ 1.3390584e+00,  1.1091279e+00, -1.4892147e+00, -4.3599159e-04]],\n      dtype=float32)&gt;\n\n\n\nt_tr = tf.transpose( t )\nt_tr\n\n&lt;tf.Tensor: shape=(4, 3), dtype=float32, numpy=\narray([[0.27102935, 0.85583425, 0.6279595 ],\n       [0.99095666, 0.93023646, 0.66343117],\n       [0.82080793, 0.27964818, 0.95931494],\n       [0.8639691 , 0.6046418 , 0.633675  ]], dtype=float32)&gt;\n\n\n\nt_sh = tf.reshape( t, shape = (6,2))\nt_sh\n\n&lt;tf.Tensor: shape=(6, 2), dtype=float32, numpy=\narray([[0.27102935, 0.99095666],\n       [0.82080793, 0.8639691 ],\n       [0.85583425, 0.93023646],\n       [0.27964818, 0.6046418 ],\n       [0.6279595 , 0.66343117],\n       [0.95931494, 0.633675  ]], dtype=float32)&gt;",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#수학-연산의-적용",
    "href": "딥러닝실습.html#수학-연산의-적용",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.3 3. 수학 연산의 적용",
    "text": "2.3 3. 수학 연산의 적용\n\na = tf.constant(10)\nb = tf.constant(20)\nc = tf.constant(30)\n\n\nad = tf.add(a,b) # substract, multiply, divide 가능\nad.numpy()\n\n30\n\n\n\ntf.reduce_mean( [a,b,c] ).numpy()\n\n20\n\n\n\ntf.reduce_sum( [a,b,c] ).numpy()\n\n60\n\n\n\nM1 = tf.random.uniform( shape=(5,2), minval=-1.0, maxval=1.0 )\nM1\n\n&lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=\narray([[-0.9798057 ,  0.2996223 ],\n       [ 0.6667137 , -0.8872769 ],\n       [-0.8612046 , -0.01308417],\n       [ 0.87081766,  0.48059368],\n       [ 0.47037864,  0.9244766 ]], dtype=float32)&gt;\n\n\n\nM2 = tf.random.normal( shape=(5,2), mean=0, stddev=1 )\nM2\n\n&lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=\narray([[ 0.46776655, -0.9643099 ],\n       [ 1.9229217 , -1.1512105 ],\n       [-1.3375244 , -0.8699059 ],\n       [ 1.1244664 , -0.9323824 ],\n       [-0.44402772, -0.86854166]], dtype=float32)&gt;\n\n\n\ntf.reduce_mean( M1, axis=0 ).numpy()\n\narray([0.03337993, 0.1608663 ], dtype=float32)\n\n\n\ntf.reduce_mean( M1, axis=1 ).numpy()\n\narray([-0.3400917 , -0.11028159, -0.4371444 ,  0.6757057 ,  0.69742763],\n      dtype=float32)\n\n\n\ntf.multiply( M1, M2 ).numpy\n\n&lt;bound method _EagerTensorBase.numpy of &lt;tf.Tensor: shape=(5, 2), dtype=float32, numpy=\narray([[-0.45832035, -0.28892875],\n       [ 1.2820382 ,  1.0214425 ],\n       [ 1.1518822 ,  0.011382  ],\n       [ 0.9792052 , -0.44809708],\n       [-0.20886116, -0.80294645]], dtype=float32)&gt;&gt;\n\n\n\ntf.matmul( M1, tf.transpose(M2) )\n\n&lt;tf.Tensor: shape=(5, 5), dtype=float32, numpy=\narray([[-0.74724907, -2.229018  ,  1.0498708 , -1.3811212 ,  0.17482644],\n       [ 1.1674762 ,  2.3034806 , -0.11989848,  1.5769786 ,  0.47459757],\n       [-0.39022553, -1.6409663 ,  1.1632642 , -0.9561962 ,  0.3937629 ],\n       [-0.05610187,  1.1212497 , -1.5828111 ,  0.5311081 , -0.8040828 ],\n       [-0.67145455, -0.15976597, -1.4333506 , -0.33304074, -1.0118076 ]],\n      dtype=float32)&gt;\n\n\n\ntf.matmul( tf.transpose(M1), M2 )\n\n&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 2.7459443, -0.2940031],\n       [-1.4185921, -0.5071478]], dtype=float32)&gt;\n\n\n\ntf.transpose(M1) @ M2\n\n&lt;tf.Tensor: shape=(2, 2), dtype=float32, numpy=\narray([[ 2.7459443, -0.2940031],\n       [-1.4185921, -0.5071478]], dtype=float32)&gt;\n\n\n\nnp.linalg.det( M1 @ tf.transpose(M2) )\n\n1.3290616e-21\n\n\n\nnp.linalg.det( tf.transpose(M1) @ M2 )\n\n-1.8096701\n\n\n\nnp.linalg.inv( tf.transpose(M1) @ M2 )\n\narray([[ 0.28024325, -0.16246226],\n       [-0.78389543, -1.5173728 ]], dtype=float32)\n\n\n\nnp.linalg.eig(tf.transpose(M1) @ M2 )\n\nEigResult(eigenvalues=array([ 2.8694618, -0.6306653], dtype=float32), eigenvectors=array([[ 0.9219415 ,  0.08674232],\n       [-0.38732904,  0.9962308 ]], dtype=float32))\n\n\n\ntf.norm( M1, ord=2, axis=1 ).numpy\n\n&lt;bound method _EagerTensorBase.numpy of &lt;tf.Tensor: shape=(5,), dtype=float32, numpy=\narray([1.024594 , 1.1098502, 0.861304 , 0.9946324, 1.0372623],\n      dtype=float32)&gt;&gt;",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#텐서-데이터의-분할-및-통합",
    "href": "딥러닝실습.html#텐서-데이터의-분할-및-통합",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.4 4. 텐서 데이터의 분할 및 통합",
    "text": "2.4 4. 텐서 데이터의 분할 및 통합\n\nt = tf.random.uniform((6,))\nt.numpy()\n\narray([0.3974868 , 0.1660564 , 0.13296926, 0.23851097, 0.8188273 ,\n       0.17868054], dtype=float32)\n\n\n\nt_spl = tf.split( t, num_or_size_splits=3 )\n[ item.numpy() for item in t_spl ]\n\n[array([0.3974868, 0.1660564], dtype=float32),\n array([0.13296926, 0.23851097], dtype=float32),\n array([0.8188273 , 0.17868054], dtype=float32)]\n\n\n\nt_spl2 = tf.split( t, num_or_size_splits=[4,2])\n[ item.numpy() for item in t_spl2 ]\n\n[array([0.3974868 , 0.1660564 , 0.13296926, 0.23851097], dtype=float32),\n array([0.8188273 , 0.17868054], dtype=float32)]\n\n\n\nt2 = tf.random.uniform((6,3))\nt2\n\n&lt;tf.Tensor: shape=(6, 3), dtype=float32, numpy=\narray([[0.06770313, 0.39880705, 0.0192132 ],\n       [0.8971355 , 0.26258385, 0.20514679],\n       [0.9233587 , 0.3713503 , 0.31647992],\n       [0.2020793 , 0.7772484 , 0.7695662 ],\n       [0.96660733, 0.99510026, 0.12588048],\n       [0.656651  , 0.7093884 , 0.20617867]], dtype=float32)&gt;\n\n\n\nt_spl3 = tf.split( t2, num_or_size_splits=[4,2], axis=0)\n[ item.numpy() for item in t_spl3 ]\n\n[array([[0.06770313, 0.39880705, 0.0192132 ],\n        [0.8971355 , 0.26258385, 0.20514679],\n        [0.9233587 , 0.3713503 , 0.31647992],\n        [0.2020793 , 0.7772484 , 0.7695662 ]], dtype=float32),\n array([[0.96660733, 0.99510026, 0.12588048],\n        [0.656651  , 0.7093884 , 0.20617867]], dtype=float32)]\n\n\n\nt_conc = tf.concat([t2, tf.reshape(t, (6,1))], axis=1)\nt_conc\n\n&lt;tf.Tensor: shape=(6, 4), dtype=float32, numpy=\narray([[0.06770313, 0.39880705, 0.0192132 , 0.3974868 ],\n       [0.8971355 , 0.26258385, 0.20514679, 0.1660564 ],\n       [0.9233587 , 0.3713503 , 0.31647992, 0.13296926],\n       [0.2020793 , 0.7772484 , 0.7695662 , 0.23851097],\n       [0.96660733, 0.99510026, 0.12588048, 0.8188273 ],\n       [0.656651  , 0.7093884 , 0.20617867, 0.17868054]], dtype=float32)&gt;\n\n\n\ntf.concat([t_conc, tf.random.uniform((1,4))], axis=0)\n\n&lt;tf.Tensor: shape=(7, 4), dtype=float32, numpy=\narray([[0.06770313, 0.39880705, 0.0192132 , 0.3974868 ],\n       [0.8971355 , 0.26258385, 0.20514679, 0.1660564 ],\n       [0.9233587 , 0.3713503 , 0.31647992, 0.13296926],\n       [0.2020793 , 0.7772484 , 0.7695662 , 0.23851097],\n       [0.96660733, 0.99510026, 0.12588048, 0.8188273 ],\n       [0.656651  , 0.7093884 , 0.20617867, 0.17868054],\n       [0.37776804, 0.5832181 , 0.45536697, 0.59192   ]], dtype=float32)&gt;",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#tf.data를-활용한-데이터-전처리",
    "href": "딥러닝실습.html#tf.data를-활용한-데이터-전처리",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.5 5. tf.data를 활용한 데이터 전처리",
    "text": "2.5 5. tf.data를 활용한 데이터 전처리\n\narr1 = [ 1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7 ]\narr1\n\n[1.1, 2.2, 3.3, 4.4, 5.5, 6.6, 7.7]\n\n\n\nds1 = tf.data.Dataset.from_tensor_slices( arr1 )\nprint( ds1 )\n\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.float32, name=None)&gt;\n\n\n\nfor item in ds1:\n    print(item)\n\ntf.Tensor(1.1, shape=(), dtype=float32)\ntf.Tensor(2.2, shape=(), dtype=float32)\ntf.Tensor(3.3, shape=(), dtype=float32)\ntf.Tensor(4.4, shape=(), dtype=float32)\ntf.Tensor(5.5, shape=(), dtype=float32)\ntf.Tensor(6.6, shape=(), dtype=float32)\ntf.Tensor(7.7, shape=(), dtype=float32)\n\n\n2024-09-26 11:19:37.757995: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds1_batch = ds1.batch(3)\nfor item in ds1_batch: print( item )\n\ntf.Tensor([1.1 2.2 3.3], shape=(3,), dtype=float32)\ntf.Tensor([4.4 5.5 6.6], shape=(3,), dtype=float32)\ntf.Tensor([7.7], shape=(1,), dtype=float32)\n\n\n2024-09-26 11:19:37.801993: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\ntf.random.set_seed(1)\nX = tf.random.uniform( shape = (10,3), dtype = tf.float32 )\nY = tf.range(1, 11)\n\n\nX.numpy()\n\narray([[0.16513085, 0.9014813 , 0.6309742 ],\n       [0.4345461 , 0.29193902, 0.64250207],\n       [0.9757855 , 0.43509948, 0.6601019 ],\n       [0.60489583, 0.6366315 , 0.6144488 ],\n       [0.8893349 , 0.6277617 , 0.53197503],\n       [0.02597821, 0.44087505, 0.25267076],\n       [0.8862232 , 0.88729346, 0.78728163],\n       [0.05955195, 0.0710938 , 0.3084147 ],\n       [0.25118268, 0.9084705 , 0.47147965],\n       [0.24238515, 0.63300395, 0.5860311 ]], dtype=float32)\n\n\n\nY.numpy()\n\narray([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10], dtype=int32)\n\n\n\nds_X = tf.data.Dataset.from_tensor_slices( X )\nds_Y = tf.data.Dataset.from_tensor_slices( Y )\nds_joint = tf.data.Dataset.zip((ds_X, ds_Y))\nds_joint2 = tf.data.Dataset.from_tensor_slices((X, Y))\n\n\nfor item in ds_X: print(ds_X)\n\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(3,), dtype=tf.float32, name=None)&gt;\n\n\n2024-09-26 11:19:37.975953: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nfor item in ds_Y: print(ds_Y)\n\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n&lt;_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)&gt;\n\n\n2024-09-26 11:19:37.989305: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nfor item in ds_joint:\n    print( item[0].numpy(),':',item[1].numpy() )\n\n[0.16513085 0.9014813  0.6309742 ] : 1\n[0.4345461  0.29193902 0.64250207] : 2\n[0.9757855  0.43509948 0.6601019 ] : 3\n[0.60489583 0.6366315  0.6144488 ] : 4\n[0.8893349  0.6277617  0.53197503] : 5\n[0.02597821 0.44087505 0.25267076] : 6\n[0.8862232  0.88729346 0.78728163] : 7\n[0.05955195 0.0710938  0.3084147 ] : 8\n[0.25118268 0.9084705  0.47147965] : 9\n[0.24238515 0.63300395 0.5860311 ] : 10\n\n\n2024-09-26 11:19:38.005100: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\n# 똑같음\nfor item in ds_joint2:\n    print( item[0].numpy(),':',item[1].numpy() )\n\n[0.16513085 0.9014813  0.6309742 ] : 1\n[0.4345461  0.29193902 0.64250207] : 2\n[0.9757855  0.43509948 0.6601019 ] : 3\n[0.60489583 0.6366315  0.6144488 ] : 4\n[0.8893349  0.6277617  0.53197503] : 5\n[0.02597821 0.44087505 0.25267076] : 6\n[0.8862232  0.88729346 0.78728163] : 7\n[0.05955195 0.0710938  0.3084147 ] : 8\n[0.25118268 0.9084705  0.47147965] : 9\n[0.24238515 0.63300395 0.5860311 ] : 10\n\n\n2024-09-26 11:19:38.018400: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds_trans = ds_joint.map( lambda x, y: (x*2-1, y/10))\nfor item in ds_trans:\n    print( item[0].numpy(),':',item[1].numpy() )\n\n[-0.6697383   0.80296254  0.26194835] : 0.1\n[-0.13090777 -0.41612196  0.28500414] : 0.2\n[ 0.951571   -0.12980103  0.32020378] : 0.3\n[0.20979166 0.27326298 0.22889757] : 0.4\n[0.77866983 0.25552344 0.06395006] : 0.5\n[-0.9480436  -0.11824989 -0.49465847] : 0.6\n[0.7724464  0.7745869  0.57456326] : 0.7\n[-0.8808961 -0.8578124 -0.3831706] : 0.8\n[-0.49763465  0.816941   -0.05704069] : 0.9\n[-0.5152297   0.2660079   0.17206216] : 1.0\n\n\n2024-09-26 11:19:38.055700: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds_trans2 = ds_joint.map( lambda x, y: ([x[0]+1,x[1]+2,x[2]+3], y/10))\nfor item in ds_trans2:\n    print( item[0].numpy(),':',item[1].numpy() )\n\n[1.1651309 2.9014812 3.6309743] : 0.1\n[1.4345461 2.291939  3.642502 ] : 0.2\n[1.9757855 2.4350996 3.660102 ] : 0.3\n[1.6048958 2.6366315 3.6144488] : 0.4\n[1.8893349 2.6277618 3.531975 ] : 0.5\n[1.0259782 2.440875  3.2526708] : 0.6\n[1.8862232 2.8872933 3.7872815] : 0.7\n[1.059552  2.0710938 3.3084147] : 0.8\n[1.2511827 2.9084706 3.4714797] : 0.9\n[1.2423851 2.633004  3.586031 ] : 1.0\n\n\n2024-09-26 11:19:38.101633: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds_shfl = ds_joint.shuffle( buffer_size = len( X ) )\nfor item in ds_shfl:\n  print( item[0].numpy(),':', item[1].numpy() )\n\n[0.60489583 0.6366315  0.6144488 ] : 4\n[0.25118268 0.9084705  0.47147965] : 9\n[0.16513085 0.9014813  0.6309742 ] : 1\n[0.24238515 0.63300395 0.5860311 ] : 10\n[0.4345461  0.29193902 0.64250207] : 2\n[0.8862232  0.88729346 0.78728163] : 7\n[0.05955195 0.0710938  0.3084147 ] : 8\n[0.02597821 0.44087505 0.25267076] : 6\n[0.9757855  0.43509948 0.6601019 ] : 3\n[0.8893349  0.6277617  0.53197503] : 5\n\n\n2024-09-26 11:19:38.157071: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds_batch = ds_joint.batch(3, drop_remainder = True )\nfor item in ds_batch :\n  print( item[0].numpy(),':', item[1].numpy() )\n\n[[0.16513085 0.9014813  0.6309742 ]\n [0.4345461  0.29193902 0.64250207]\n [0.9757855  0.43509948 0.6601019 ]] : [1 2 3]\n[[0.60489583 0.6366315  0.6144488 ]\n [0.8893349  0.6277617  0.53197503]\n [0.02597821 0.44087505 0.25267076]] : [4 5 6]\n[[0.8862232  0.88729346 0.78728163]\n [0.05955195 0.0710938  0.3084147 ]\n [0.25118268 0.9084705  0.47147965]] : [7 8 9]\n\n\n2024-09-26 11:19:38.177016: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds_rpt = ds_joint.batch(3, drop_remainder = True ).repeat( count = 2 )\nfor item in ds_rpt :\n  print( item[0].numpy(),':', item[1].numpy() )\n\n[[0.16513085 0.9014813  0.6309742 ]\n [0.4345461  0.29193902 0.64250207]\n [0.9757855  0.43509948 0.6601019 ]] : [1 2 3]\n[[0.60489583 0.6366315  0.6144488 ]\n [0.8893349  0.6277617  0.53197503]\n [0.02597821 0.44087505 0.25267076]] : [4 5 6]\n[[0.8862232  0.88729346 0.78728163]\n [0.05955195 0.0710938  0.3084147 ]\n [0.25118268 0.9084705  0.47147965]] : [7 8 9]\n[[0.16513085 0.9014813  0.6309742 ]\n [0.4345461  0.29193902 0.64250207]\n [0.9757855  0.43509948 0.6601019 ]] : [1 2 3]\n[[0.60489583 0.6366315  0.6144488 ]\n [0.8893349  0.6277617  0.53197503]\n [0.02597821 0.44087505 0.25267076]] : [4 5 6]\n[[0.8862232  0.88729346 0.78728163]\n [0.05955195 0.0710938  0.3084147 ]\n [0.25118268 0.9084705  0.47147965]] : [7 8 9]\n\n\n2024-09-26 11:19:38.190962: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nds_rpt2 = ds_joint.repeat( count = 2 ).batch(3, drop_remainder = True )\nfor item in ds_rpt2 :\n  print( item[0].numpy(),':', item[1].numpy() )\n\n[[0.16513085 0.9014813  0.6309742 ]\n [0.4345461  0.29193902 0.64250207]\n [0.9757855  0.43509948 0.6601019 ]] : [1 2 3]\n[[0.60489583 0.6366315  0.6144488 ]\n [0.8893349  0.6277617  0.53197503]\n [0.02597821 0.44087505 0.25267076]] : [4 5 6]\n[[0.8862232  0.88729346 0.78728163]\n [0.05955195 0.0710938  0.3084147 ]\n [0.25118268 0.9084705  0.47147965]] : [7 8 9]\n[[0.24238515 0.63300395 0.5860311 ]\n [0.16513085 0.9014813  0.6309742 ]\n [0.4345461  0.29193902 0.64250207]] : [10  1  2]\n[[0.9757855  0.43509948 0.6601019 ]\n [0.60489583 0.6366315  0.6144488 ]\n [0.8893349  0.6277617  0.53197503]] : [3 4 5]\n[[0.02597821 0.44087505 0.25267076]\n [0.8862232  0.88729346 0.78728163]\n [0.05955195 0.0710938  0.3084147 ]] : [6 7 8]\n\n\n2024-09-26 11:19:38.204338: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\n# ppt 56번 제일 흔하게 씀\nds_all = ds_joint.shuffle( len(X) ).batch( 3 ).repeat( 2 )\nfor item in ds_all :\n  print( item[0].numpy(),':', item[1].numpy() )\n\n[[0.8893349  0.6277617  0.53197503]\n [0.16513085 0.9014813  0.6309742 ]\n [0.25118268 0.9084705  0.47147965]] : [5 1 9]\n[[0.05955195 0.0710938  0.3084147 ]\n [0.9757855  0.43509948 0.6601019 ]\n [0.8862232  0.88729346 0.78728163]] : [8 3 7]\n[[0.24238515 0.63300395 0.5860311 ]\n [0.4345461  0.29193902 0.64250207]\n [0.60489583 0.6366315  0.6144488 ]] : [10  2  4]\n[[0.02597821 0.44087505 0.25267076]] : [6]\n[[0.16513085 0.9014813  0.6309742 ]\n [0.02597821 0.44087505 0.25267076]\n [0.4345461  0.29193902 0.64250207]] : [1 6 2]\n[[0.24238515 0.63300395 0.5860311 ]\n [0.8862232  0.88729346 0.78728163]\n [0.8893349  0.6277617  0.53197503]] : [10  7  5]\n[[0.9757855  0.43509948 0.6601019 ]\n [0.05955195 0.0710938  0.3084147 ]\n [0.60489583 0.6366315  0.6144488 ]] : [3 8 4]\n[[0.25118268 0.9084705  0.47147965]] : [9]\n\n\n2024-09-26 11:19:38.221573: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#선형회귀분석-low-lever-ver.",
    "href": "딥러닝실습.html#선형회귀분석-low-lever-ver.",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.6 6. 선형회귀분석 (low-lever ver.)",
    "text": "2.6 6. 선형회귀분석 (low-lever ver.)\n\n# alpha=0.8, beta=0.2, error term 일반적인 선형회귀식\nX = tf.random.uniform( minval=0, maxval=10, shape=(36,))\nY = 0.2 * X + 0.8 + tf.random.normal(mean=0, stddev=0.15, shape=(36, ))\n\n\nimport matplotlib.pyplot as plt\nplt.plot(X, Y, 'ro', label='Original Data')\n\n\n\n\n\n\n\n\n\n# 훈련데이터와 평가데이터로 구분\ntrainX, testX = tf.split( X, num_or_size_splits= [30, 6] )\ntrainY, testY = tf.split( Y, num_or_size_splits= [30, 6] )\n\n\nds_train = tf.data.Dataset.from_tensor_slices( ( trainX, trainY ) )\n\n\nW = tf.Variable( np.random.randn() )\nb = tf.Variable( np.random.randn() )\n\n\nprint( W.numpy(), b.numpy() )\n\n-0.9058514 -0.7786096\n\n\n\n# y^=wx=b\n# L = sum(y^-y)**2\ndef linear_regression( x ):\n  return tf.add( tf.multiply( W, x ), b )\n\ndef mean_square( ypred, y ):\n  return tf.reduce_mean( tf.square( y-ypred ) )\n\noptimizer = tf.optimizers.SGD( learning_rate= 0.01 )\n\n\nnum_epochs = 100\nlog_steps = 50\nbatch_size = 5\nsteps_per_epoch = int( np.ceil( len(ds_train)/ batch_size ) )\nL=[]\nds_train = ds_train.shuffle( buffer_size = len( ds_train ) ).batch( batch_size ).repeat( count=num_epochs )\nlen( ds_train )\n\n600\n\n\n\n# enumerate : index와 item을 동시에 반환함\nfor i, batch in enumerate( ds_train ):\n  bX, bY = batch\n  # pred, loss의 미니배치별 반복연산을 tape에 저장 (tf.GT함수)\n  with tf.GradientTape() as tape:\n    pred = linear_regression( bX )\n    loss = mean_square( pred, bY ) # 각 미치배치에 대한 MSE\n  \n  # 미분값 자동 계산하여 gradient 산출 (손실함수, [변수]) &gt; output은 gredient vector 형태\n  gradients = tape.gradient( loss, [W, b] )\n  # 위 gredient를 이용해서 W, b의 값 자체를 업데이트시킴\n  optimizer.apply_gradients( zip( gradients, [W, b] ) )\n  \n  if i % log_steps == 0 :\n    print( i, loss.numpy(), W.numpy(), b.numpy() )\n    L.append( loss.numpy() )\n\n0 69.40471 0.11469287 -0.61661613\n50 0.43844503 0.39045188 -0.32226366\n100 0.46575123 0.33767676 -0.1271174\n150 0.12025349 0.33699113 0.04169075\n200 0.15756947 0.2899113 0.17330694\n250 0.06758316 0.2755403 0.2876421\n300 0.071345985 0.27407777 0.38137773\n350 0.039882302 0.24708605 0.4576195\n400 0.023926783 0.24857457 0.5242689\n450 0.012039001 0.22822896 0.57613546\n500 0.067414835 0.22391716 0.62088096\n550 0.06226217 0.2308571 0.6605001\n\n\n2024-09-26 11:19:39.702336: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n\n\n\nimport matplotlib.pyplot as plt\nplt.plot(X, Y, 'ro', label='Original Data')\nplt.plot(X, np.array( W * X + b ), label='Fitted Line' )\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(L, 'bo-')\nplt.ylabel('Train Loss')\nplt.xlabel('iter')\n\nText(0.5, 0, 'iter')\n\n\n\n\n\n\n\n\n\n\ntpred = linear_regression( testX )\ntest_mse = mean_square( tpred, testY )\ntest_mse.numpy()\n\n0.05091959",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#선형회귀분석-tf.keras-ver.",
    "href": "딥러닝실습.html#선형회귀분석-tf.keras-ver.",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.7 7. 선형회귀분석 (tf.keras ver.)",
    "text": "2.7 7. 선형회귀분석 (tf.keras ver.)\n\nds_train2 = tf.data.Dataset.from_tensor_slices((trainX, trainY))\nds_train2 = ds_train2.shuffle(30).batch(5)\n\n\nmodel = tf.keras.models.Sequential()\nmodel.add( tf.keras.layers.Dense(1, input_dim = 1, activation='linear'))\nmodel.summary()\n\n/Users/hwan/.pyenv/versions/3.10.14/envs/hwan/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\nModel: \"sequential\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense (Dense)                   │ (None, 1)              │             2 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 2 (8.00 B)\n\n\n\n Trainable params: 2 (8.00 B)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\nmodel.compile( loss='mse', optimizer = tf.keras.optimizers.SGD( learning_rate=0.01 ) )\nhistory = model.fit( ds_train2, epochs=100, verbose=1 )\n\nEpoch 1/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1681  \nEpoch 2/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1446\nEpoch 3/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1665\nEpoch 4/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1156 \nEpoch 5/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 695us/step - loss: 0.1528\nEpoch 6/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.1309\nEpoch 7/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1159\nEpoch 8/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1285\nEpoch 9/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.1414\nEpoch 10/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 670us/step - loss: 0.1199\nEpoch 11/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 854us/step - loss: 0.1437\nEpoch 12/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 843us/step - loss: 0.0942\nEpoch 13/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1115\nEpoch 14/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0951\nEpoch 15/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0794\nEpoch 16/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.1033\nEpoch 17/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 783us/step - loss: 0.1107\nEpoch 18/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 928us/step - loss: 0.0790\nEpoch 19/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0789\nEpoch 20/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0734\nEpoch 21/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 993us/step - loss: 0.0675\nEpoch 22/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 791us/step - loss: 0.0678\nEpoch 23/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 742us/step - loss: 0.0688\nEpoch 24/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0651\nEpoch 25/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0819\nEpoch 26/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0674\nEpoch 27/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 820us/step - loss: 0.0587\nEpoch 28/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 988us/step - loss: 0.0911\nEpoch 29/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 975us/step - loss: 0.0583\nEpoch 30/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0651\nEpoch 31/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 740us/step - loss: 0.0709\nEpoch 32/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 627us/step - loss: 0.0492\nEpoch 33/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 699us/step - loss: 0.0653\nEpoch 34/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0421\nEpoch 35/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0511\nEpoch 36/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 878us/step - loss: 0.0713\nEpoch 37/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 676us/step - loss: 0.0476\nEpoch 38/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0532\nEpoch 39/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 14ms/step - loss: 0.0485\nEpoch 40/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0441\nEpoch 41/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0466\nEpoch 42/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0356\nEpoch 43/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 813us/step - loss: 0.0592\nEpoch 44/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0473\nEpoch 45/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 913us/step - loss: 0.0395\nEpoch 46/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 941us/step - loss: 0.0423\nEpoch 47/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0375\nEpoch 48/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 885us/step - loss: 0.0550\nEpoch 49/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0450\nEpoch 50/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 810us/step - loss: 0.0458\nEpoch 51/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0360\nEpoch 52/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0381\nEpoch 53/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 847us/step - loss: 0.0296\nEpoch 54/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 984us/step - loss: 0.0347\nEpoch 55/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 830us/step - loss: 0.0438\nEpoch 56/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 2ms/step - loss: 0.0418\nEpoch 57/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 973us/step - loss: 0.0328\nEpoch 58/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 924us/step - loss: 0.0435\nEpoch 59/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0354\nEpoch 60/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0317\nEpoch 61/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0268\nEpoch 62/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0273\nEpoch 63/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 920us/step - loss: 0.0424\nEpoch 64/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0270\nEpoch 65/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0250\nEpoch 66/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0264\nEpoch 67/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0370\nEpoch 68/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 866us/step - loss: 0.0263\nEpoch 69/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 935us/step - loss: 0.0238\nEpoch 70/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 828us/step - loss: 0.0244\nEpoch 71/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 845us/step - loss: 0.0207\nEpoch 72/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 784us/step - loss: 0.0263\nEpoch 73/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 656us/step - loss: 0.0270\nEpoch 74/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 3ms/step - loss: 0.0238\nEpoch 75/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 865us/step - loss: 0.0431\nEpoch 76/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 1ms/step - loss: 0.0302\nEpoch 77/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 659us/step - loss: 0.0256\nEpoch 78/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 654us/step - loss: 0.0209\nEpoch 79/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 702us/step - loss: 0.0206\nEpoch 80/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 683us/step - loss: 0.0269\nEpoch 81/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 679us/step - loss: 0.0213\nEpoch 82/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 629us/step - loss: 0.0304\nEpoch 83/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 640us/step - loss: 0.0212\nEpoch 84/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 697us/step - loss: 0.0199\nEpoch 85/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 667us/step - loss: 0.0238\nEpoch 86/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 592us/step - loss: 0.0298\nEpoch 87/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 629us/step - loss: 0.0200\nEpoch 88/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 749us/step - loss: 0.0323\nEpoch 89/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 535us/step - loss: 0.0214\nEpoch 90/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 508us/step - loss: 0.0248\nEpoch 91/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 535us/step - loss: 0.0242\nEpoch 92/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 579us/step - loss: 0.0261\nEpoch 93/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 904us/step - loss: 0.0186\nEpoch 94/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 564us/step - loss: 0.0297\nEpoch 95/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 475us/step - loss: 0.0333\nEpoch 96/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 495us/step - loss: 0.0237\nEpoch 97/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 617us/step - loss: 0.0273\nEpoch 98/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 477us/step - loss: 0.0248\nEpoch 99/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 513us/step - loss: 0.0283\nEpoch 100/100\n6/6 ━━━━━━━━━━━━━━━━━━━━ 0s 429us/step - loss: 0.0233\n\n\n\nmodel.weights\n\n[&lt;KerasVariable shape=(1, 1), dtype=float32, path=sequential/dense/kernel&gt;,\n &lt;KerasVariable shape=(1,), dtype=float32, path=sequential/dense/bias&gt;]\n\n\n\nW2 = model.weights[0][0][0]\nb2 = model.weights[1][0]\nprint( W2, b2 )\n\ntf.Tensor(0.21290928, shape=(), dtype=float32) tf.Tensor(0.7482932, shape=(), dtype=float32)\n\n\n\nplt.plot(X, Y, 'ro', label='Original Data')\nplt.plot(X, np.array( W2 * X + b2 ), label='Fitted Line' )\nplt.legend()\n\n\n\n\n\n\n\n\n\ntpred2 = model.predict( testX )\ntest_mse2 = mean_square( tpred2, testY )\ntest_mse2.numpy()\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 22ms/step\n\n\n0.70052314\n\n\n\nplt.plot(history.history['loss'])\nplt.ylabel('loss')\nplt.xlabel('Epoch')\n\nText(0.5, 0, 'Epoch')",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "딥러닝실습.html#ch2-neural-network-실습",
    "href": "딥러닝실습.html#ch2-neural-network-실습",
    "title": "2  딥러닝 Ch1 실습",
    "section": "2.8 Ch2 Neural Network 실습",
    "text": "2.8 Ch2 Neural Network 실습\n\nimport pandas as pd\nresign_df = pd.read_csv('실습/resign.csv')\nresign_df.head()\n\n\n\n\n\n\n\n\n\nsatisfaction\nevaluation\nproject\nworkhour\nyears\naccident\nresign\npromotion\ngood\n\n\n\n\n0\n0.38\n0.53\n2\n157\n3\n0\n1\n0\n0\n\n\n1\n0.80\n0.86\n5\n262\n6\n0\n1\n0\n1\n\n\n2\n0.11\n0.88\n7\n272\n4\n0\n1\n0\n1\n\n\n3\n0.72\n0.87\n5\n223\n5\n0\n1\n0\n1\n\n\n4\n0.37\n0.52\n2\n159\n3\n0\n1\n0\n0\n\n\n\n\n\n\n\n\n\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nresign_df_X = scaler.fit_transform( resign_df.iloc[:, [0, 1, 2, 3, 4, 5, 7]])\nresign_df_Y = resign_df['resign']\n\n\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(\nresign_df_X, resign_df_Y, test_size=0.2, random_state=0)\n\n\nimport tensorflow as tf\nmodel = tf.keras.Sequential()\nmodel.add( tf.keras.layers.Dense ( units=3, input_dim=7, activation='relu') )\nmodel.add( tf.keras.layers.Dense ( units=1, activation='sigmoid') )\n\n/Users/hwan/.pyenv/versions/3.10.14/envs/hwan/lib/python3.10/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n\n\n\nmodel.summary()\n\nModel: \"sequential_1\"\n\n\n\n┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃ Layer (type)                    ┃ Output Shape           ┃       Param # ┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ dense_1 (Dense)                 │ (None, 3)              │            24 │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_2 (Dense)                 │ (None, 1)              │             4 │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n\n\n\n Total params: 28 (112.00 B)\n\n\n\n Trainable params: 28 (112.00 B)\n\n\n\n Non-trainable params: 0 (0.00 B)\n\n\n\n\nmodel.compile( optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n\n\nresult = model.fit( x_train, y_train, validation_split=0.2, epochs=40, verbose=1)\n\nEpoch 1/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 738us/step - accuracy: 0.7315 - loss: 0.6126 - val_accuracy: 0.7621 - val_loss: 0.5153\nEpoch 2/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 474us/step - accuracy: 0.7626 - loss: 0.5068 - val_accuracy: 0.7625 - val_loss: 0.4653\nEpoch 3/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 477us/step - accuracy: 0.7626 - loss: 0.4642 - val_accuracy: 0.7625 - val_loss: 0.4393\nEpoch 4/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 470us/step - accuracy: 0.7626 - loss: 0.4398 - val_accuracy: 0.7625 - val_loss: 0.4182\nEpoch 5/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 470us/step - accuracy: 0.7626 - loss: 0.4192 - val_accuracy: 0.7625 - val_loss: 0.3986\nEpoch 6/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 475us/step - accuracy: 0.7626 - loss: 0.4000 - val_accuracy: 0.7625 - val_loss: 0.3803\nEpoch 7/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 472us/step - accuracy: 0.7623 - loss: 0.3822 - val_accuracy: 0.7613 - val_loss: 0.3638\nEpoch 8/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 473us/step - accuracy: 0.7602 - loss: 0.3661 - val_accuracy: 0.7721 - val_loss: 0.3488\nEpoch 9/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 472us/step - accuracy: 0.7779 - loss: 0.3518 - val_accuracy: 0.8071 - val_loss: 0.3350\nEpoch 10/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 474us/step - accuracy: 0.8115 - loss: 0.3390 - val_accuracy: 0.8554 - val_loss: 0.3226\nEpoch 11/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 512us/step - accuracy: 0.8507 - loss: 0.3277 - val_accuracy: 0.8654 - val_loss: 0.3117\nEpoch 12/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 646us/step - accuracy: 0.8544 - loss: 0.3178 - val_accuracy: 0.8788 - val_loss: 0.3024\nEpoch 13/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 574us/step - accuracy: 0.8727 - loss: 0.3094 - val_accuracy: 0.8867 - val_loss: 0.2947\nEpoch 14/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 590us/step - accuracy: 0.8815 - loss: 0.3022 - val_accuracy: 0.8942 - val_loss: 0.2881\nEpoch 15/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 515us/step - accuracy: 0.8859 - loss: 0.2960 - val_accuracy: 0.8963 - val_loss: 0.2826\nEpoch 16/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 499us/step - accuracy: 0.8896 - loss: 0.2907 - val_accuracy: 0.8979 - val_loss: 0.2779\nEpoch 17/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 483us/step - accuracy: 0.8908 - loss: 0.2860 - val_accuracy: 0.9000 - val_loss: 0.2737\nEpoch 18/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 643us/step - accuracy: 0.8935 - loss: 0.2817 - val_accuracy: 0.9033 - val_loss: 0.2700\nEpoch 19/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 472us/step - accuracy: 0.8955 - loss: 0.2781 - val_accuracy: 0.9050 - val_loss: 0.2668\nEpoch 20/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 474us/step - accuracy: 0.8982 - loss: 0.2748 - val_accuracy: 0.9042 - val_loss: 0.2639\nEpoch 21/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 514us/step - accuracy: 0.8994 - loss: 0.2717 - val_accuracy: 0.9042 - val_loss: 0.2613\nEpoch 22/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 557us/step - accuracy: 0.9024 - loss: 0.2690 - val_accuracy: 0.9054 - val_loss: 0.2590\nEpoch 23/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 481us/step - accuracy: 0.9042 - loss: 0.2665 - val_accuracy: 0.9058 - val_loss: 0.2570\nEpoch 24/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 470us/step - accuracy: 0.9056 - loss: 0.2641 - val_accuracy: 0.9071 - val_loss: 0.2551\nEpoch 25/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 473us/step - accuracy: 0.9084 - loss: 0.2620 - val_accuracy: 0.9096 - val_loss: 0.2534\nEpoch 26/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 479us/step - accuracy: 0.9085 - loss: 0.2602 - val_accuracy: 0.9112 - val_loss: 0.2520\nEpoch 27/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 512us/step - accuracy: 0.9111 - loss: 0.2587 - val_accuracy: 0.9121 - val_loss: 0.2507\nEpoch 28/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 580us/step - accuracy: 0.9124 - loss: 0.2574 - val_accuracy: 0.9129 - val_loss: 0.2495\nEpoch 29/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 886us/step - accuracy: 0.9125 - loss: 0.2562 - val_accuracy: 0.9150 - val_loss: 0.2485\nEpoch 30/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 767us/step - accuracy: 0.9128 - loss: 0.2552 - val_accuracy: 0.9150 - val_loss: 0.2475\nEpoch 31/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 518us/step - accuracy: 0.9136 - loss: 0.2542 - val_accuracy: 0.9158 - val_loss: 0.2466\nEpoch 32/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 483us/step - accuracy: 0.9138 - loss: 0.2532 - val_accuracy: 0.9158 - val_loss: 0.2458\nEpoch 33/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 475us/step - accuracy: 0.9150 - loss: 0.2524 - val_accuracy: 0.9162 - val_loss: 0.2451\nEpoch 34/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 484us/step - accuracy: 0.9149 - loss: 0.2515 - val_accuracy: 0.9171 - val_loss: 0.2443\nEpoch 35/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 480us/step - accuracy: 0.9148 - loss: 0.2506 - val_accuracy: 0.9162 - val_loss: 0.2437\nEpoch 36/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 503us/step - accuracy: 0.9148 - loss: 0.2498 - val_accuracy: 0.9158 - val_loss: 0.2431\nEpoch 37/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 551us/step - accuracy: 0.9138 - loss: 0.2491 - val_accuracy: 0.9167 - val_loss: 0.2426\nEpoch 38/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 603us/step - accuracy: 0.9139 - loss: 0.2484 - val_accuracy: 0.9171 - val_loss: 0.2420\nEpoch 39/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 589us/step - accuracy: 0.9132 - loss: 0.2477 - val_accuracy: 0.9171 - val_loss: 0.2415\nEpoch 40/40\n300/300 ━━━━━━━━━━━━━━━━━━━━ 0s 511us/step - accuracy: 0.9138 - loss: 0.2470 - val_accuracy: 0.9175 - val_loss: 0.2408\n\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nepochs=np.arange(1, 40+1)\nplt.plot(epochs, result.history['loss'], label='training loss')\nplt.plot(epochs, result.history['val_loss'], label='validation loss')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()\n# 검증데이터의 loss가 더 낮은게 이상해보일 수 있는데, epoch를 키울수록 훈련데이터가 낮아짐\n\n\n\n\n\n\n\n\n\nepochs=np.arange(1, 40+1)\nplt.plot(epochs, result.history['accuracy'], label='training accuracy')\nplt.plot(epochs, result.history['val_accuracy'], label='validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend()\nplt.show()\n\n\n\n\n\n\n\n\n\nmodel.evaluate(x_test, y_test) # 평가데이터를 이용하여 모델 일반화 성능 평가\n\n94/94 ━━━━━━━━━━━━━━━━━━━━ 0s 404us/step - accuracy: 0.9167 - loss: 0.2322\n\n\n[0.23656116425991058, 0.9156666398048401]\n\n\n\nx_test[0, ]\n\narray([-0.69516483, -0.85358047, -1.46286291, -1.20241514, -0.34123516,\n       -0.41116529, -0.14741182])\n\n\n\nx_new = np.array([-0.7,-0.9,-1.3,-0.9,0.3,0.4,-0.02], dtype=np.float32)\ny_pred = model.predict(x_new.reshape(1,7)) # 차원변환 필요\ny_pred\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 25ms/step\n\n\narray([[0.33662271]], dtype=float32)\n\n\n\nx_new2 = np.array([[-0.7,-0.9,-1.3,-0.9,0.3,0.4,-0.02],[0,0,0,0,0,0,0]])\ny_pred2 = model.predict(x_new2)\ny_pred2\n\n1/1 ━━━━━━━━━━━━━━━━━━━━ 0s 26ms/step\n\n\narray([[0.33662271],\n       [0.20525527]], dtype=float32)",
    "crumbs": [
      "딥러닝('24 가을)",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>딥러닝 Ch1 실습</span>"
    ]
  },
  {
    "objectID": "시뮬레이션1.html",
    "href": "시뮬레이션1.html",
    "title": "시뮬레이션방법론 Ch1",
    "section": "",
    "text": "블랙숄즈공식 예시\n\\(1.\\;f_t+\\frac{1}{2}\\sigma^2S^2f_{ss}+rSf_s-rf=0\\)\n-&gt; 수치해석적인 방법으로 풀게 됨, FDM(Finite Difference Method)\n\\(2.\\;P(0)=e^{-rT}E^Q[P(T)]\\)\n-&gt; 마팅게일, 몬테카를로 시뮬레이션(Montecarlo simulation, MCS)을 주로 사용함",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch1"
    ]
  },
  {
    "objectID": "시뮬레이션1.html#volume과-적분",
    "href": "시뮬레이션1.html#volume과-적분",
    "title": "시뮬레이션방법론 Ch1",
    "section": "Volume과 적분",
    "text": "Volume과 적분\n\\(x\\sim uniform[0,1]\\;일 때,\\;\\;\\alpha=E[f(x)]=\\int_0^1f(x)dx\\)\n그러나, MCS를 이용하는 경우 임의변수 \\(x_1,x_2,...,x_n\\)을 샘플링하여 \\(\\hat{\\alpha}=\\frac{1}{N}\\sum_i^Nf(x_i)\\)로 산출함\n두 값이 정확히 일치하지는 않지만, 표본이 커질수록 그 오차는 0으로 수렴함(\\(\\alpha\\approx\\hat{\\alpha}\\))\n이는 대수의 법칙과 중심극한정리에 따라 수학적으로 정의할 수 있음\n\n\n\n\n\n\n중심극한정리\n\n\n\n표본평균(\\(\\hat{\\alpha}\\))은 정규분포를 따르므로, \\(\\hat{\\alpha}-\\alpha\\sim N(0,\\frac{\\sigma^2}{N})\\)\n즉, 표본의 크기가 커질수록 두 차이는 0으로 수렴함(probibility convergence)\n오차의 표준편차는 \\(\\frac{\\sigma}{\\sqrt{N}}\\)이므로, 표본의 크기가 100배 증가하면 오차의 표준편차는 10배 감소함\n\n\n이외에도 간단힌 사다리꼴(trapezoidal) 방식을 이용해볼 수 있음.\n\\(3.\\;\\alpha\\approx \\frac{f(0)+f(1)}{2n}+\\frac{1}{n}\\sum_{i=1}^{n-1}f(\\frac{i}{n})\\;\\;(구분구적법의\\;앞뒤\\;평균치)\\)\n이는 매우 간단하고 효율적인 방법이지만, 변수가 늘어날 수록 효율이 급감함.",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch1"
    ]
  },
  {
    "objectID": "시뮬레이션1.html#mcs-기초",
    "href": "시뮬레이션1.html#mcs-기초",
    "title": "시뮬레이션방법론 Ch1",
    "section": "MCS 기초",
    "text": "MCS 기초\n몬테카를로 시뮬레이션을 개념적으로 설명함\n예를 들어, 1X1 사각형에 내접한 원에 대하여, 사각형 안에 임의의 점을 찍을 때 원에 포함될 확률?\n직관적으로 면적을 통해 \\(\\Pi/4\\)임을 알 수 있음.\n이를 다변수, 다차원, 복잡한 함수꼴로 확장한다면 면적을 구하는 적분을 통해 구할 수 있음을 의미함.\n근데 그런 복잡한 계산 대신에 랜덤변수를 생성해서 시행횟수를 수없이 시행하고,\n원(면적) 안에 속할 확률을 구한다면? 이게 몬테카를로 시뮬레이션의 기초임.\n수없이 많은 \\((x,y)\\)를 생성하고, 좌표평면의 1X1 사각형에 대해 원안에 속할 확률은 \\(x^2+y^2&lt;1/4\\)임.\n이러한 확률을 구하는 것은 기대값으로 표현할 수 있게 되고, 결국 이 확률은 \\(\\Pi/4\\)로 수렴\n\\[Pr(x\\in B)=E(\\int_A 1_B)=\\Pi/4\\]\n\n확률기대값 및 원주율 계산 예시\n\nimport numpy as np\nn = 10000\nx = np.random.rand(n) # uniform random number in (0,1)\nx -= 0.5\ny = np.random.rand(n)\ny -= 0.5\n\nd = np.sqrt(x**2+y**2)\ni = d&lt;0.5\nprob = i.sum() / n\npi = 4 * i.sum() / n\n\nprint(prob,pi,sep=\"\\n\")\n\n0.7924\n3.1696\n\n\n\n\n표본표준편차 계산 : numpy는 n으로 나누고, pandas는 n-1로 나누는 것이 기본\n\nimport pandas as pd\nnp_s = i.std()\npd_s = pd.Series(i).std()\nnp_s_df1 = i.std(ddof=1)\nprint(np_s, pd_s, np_s_df1, sep = \"\\n\")\n\n0.4055887572406316\n0.4056090381995782\n0.4056090381995782\n\n\n\n\n표준오차 계산 및 95% 신뢰구간 계산\n\nse = pd_s / np.sqrt(n)\nprob_95lb = prob - 2*se\nprob_95ub = prob + 2*se\npi_95lb = prob_95lb*4\npi_95ub = prob_95ub*4\nprint(se, pi_95lb, pi_95ub, sep=\"\\n\")\n\n0.004056090381995782\n3.1371512769440337\n3.202048723055966",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch1"
    ]
  },
  {
    "objectID": "시뮬레이션1.html#경로의존성-path-dependent",
    "href": "시뮬레이션1.html#경로의존성-path-dependent",
    "title": "시뮬레이션방법론 Ch1",
    "section": "경로의존성 (Path-dependent)",
    "text": "경로의존성 (Path-dependent)\n일반적인(Plain vanilla) 옵션은 pay-off가 기초자산의 만기시점의 가격 \\(S(T)\\)에 의해서만 결정되므로,\n그 사이의 기초자산의 가격을 생성할 필요는 없음(0~T)\n그러나, 아시안옵션 등은 \\(S(T)\\) 뿐만 아니라 그 과정에 의해서 pay-off가 결정되므로 그 경로를 알아야 함.\n또한, 블랙숄즈의 가정이 성립하지 않는 경우 모델링을 하기 위해서도 그 경로를 알아야 할 필요가 있음.\n이를 경로의존성이라고 함.\n\n시뮬레이션 예시\n일반적인 주가에 대한 확률과정이 GBM을 따른다면,\n\\(dS(t)=rS(t)dt+\\sigma S(t)dW(t)\\)\n그러나, 변동성이 주가에 따라 변하면 주가의 흐름에 따라 변동성이 바뀌므로 경로의존성이 발생\n즉, \\(dS(t)=rS(t)dt+\\sigma (S(t)) S(t)dW(t)\\)를 따르게 되므로\n우리가 앞서 사용한 \\(S(T)=S(0)e^{(r-\\frac{1}{2}\\sigma^2)T+\\sigma\\sqrt{T}Z}\\)를 사용할 수 없음.\n따라서, Analytic solution이 없으므로 근사치를 구할 수 밖에 없으며 그 예시로 이산오일러근사가 있음\n(0~T) 구간을 m개로 나누고, 각 구간의 길이 \\(\\frac{T}{m}=\\Delta t\\)라고 하면 기초자산의 경로 \\(S(t)\\)는,\n\\[S(t+\\Delta t)=S(t)+rS(t)\\Delta t+\\sigma (S(t)) S(t)\\sqrt{\\Delta t}Z\\]\n다만, 이러한 경우에는 그 경로의 길이를 얼마나 짧게 구성하는지에 따라 시뮬레이션 정밀도에 영향을 미침.\n즉, 시뮬레이션 횟수 n과 경로의 길이 m이 모두 정확도를 결정하는 파라미터가 됨.",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch1"
    ]
  },
  {
    "objectID": "시뮬레이션1.html#mcs-추정치-개선-방향",
    "href": "시뮬레이션1.html#mcs-추정치-개선-방향",
    "title": "시뮬레이션방법론 Ch1",
    "section": "MCS 추정치 개선 방향",
    "text": "MCS 추정치 개선 방향\nMCS의 효율성은 아래 3개의 기준에 따라 평가할 수 있습니다.\n\n계산시간 (Computing time)\n편의 (Bias)\n분산 (Variance)\n\n여기서, 시뮬레이션의 \\(Prediction\\;error\\;=\\;Variance\\;+\\;Bias^2\\)\n\n\n\n\n\n\n\\(Var[\\epsilon]=E[\\epsilon^2]-(E[\\epsilon])^2\\)\n\\(MSE=E[\\epsilon^2)=Var[\\epsilon]+(E[\\epsilon])^2=Variance+Bias^2\\)\n\n\n\n\n분산감소와 계산시간\n시행횟수가 증가하면 분산은 감소함. (\\(n\\rightarrow\\infty,Var[\\epsilon]\\rightarrow 0\\))\n한번의 시뮬레이션에 정확한방법을 사용할 수록 편의는 감소함(\\(m\\rightarrow\\infty,Bias\\rightarrow 0\\))\n(정확한방법을 사용할 수록 분산은 증가할 수 있음 (머신러닝 overfitting 같은 문제?))\n(정확한방법을 쓸수록 계산비용이 증가하여 시뮬레이션 횟수가 감소함, 분산이 그래서 증가함)\n\n시뮬레이션의 횟수\n계산 예산에 \\(s\\)이고, 한번의 시뮬레이션의 계산량이 \\(\\tau\\)일 때, 가능한 시뮬레이션 횟수는 \\(s/\\tau\\)임\n이 때, 추정치의 분포 \\(\\sqrt{\\frac{s}{\\tau}}[\\hat{C}-C]\\rightarrow N(0,\\sigma_c^2)\\)\n\\(\\Rightarrow [\\hat{C}-C]\\rightarrow N(0,\\sigma_c^2(\\frac{\\tau}{c}))\\) 이므로,\n계산오차는 분산이 \\(\\sigma_c^2(\\frac{tau}{c})\\)인 정규분포에 수렴함을 의미\n\n\n편의\n경로의존성이 있는 시뮬레이션 중, 과거 연속적인 수치에 따라 pay-off가 정해진다면,\n이산오일러근사를 사용할 때 편의가 발생함.\ne.g. 룩백옵션의 경우 시뮬레이션이 항상 실제 pay-off를 과소평가 = (-) bias 존재\n이 때, 이산구간의 간격 m을 작게할 수록 편의는 감소함.\n또는, 기초자산이 비선형구조인 경우 등에도 편의가 발생할 수 있음.\ne.g. Compound 옵션의 경우 기초자산인 옵션 가격이 비선형이므로,\nCompound 옵션을 Analytic solution을 적용하여 푸는 경우 항상 실제 옵션보다 가격이 높음 = (+) bias 존재\n이 때, \\(T_1\\sim T_2\\)의 \\(n_2\\)개의 경로를 추가로 생성하여 경로를 이중으로 구성한다면 bias 제거가 가능함.",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch1"
    ]
  },
  {
    "objectID": "시뮬레이션1.html#asian-option-평가-해볼-것",
    "href": "시뮬레이션1.html#asian-option-평가-해볼-것",
    "title": "시뮬레이션방법론 Ch1",
    "section": "Asian Option 평가 해볼 것",
    "text": "Asian Option 평가 해볼 것",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch1"
    ]
  },
  {
    "objectID": "시뮬레이션2.html",
    "href": "시뮬레이션2.html",
    "title": "시뮬레이션방법론 Ch3-4",
    "section": "",
    "text": "Brownian bridge\nGBM에 따라 결정된 t시점의 값이 있을 때, 0과 t 사이의 시점 s에 대한 분포를 어떻게 구하지?\nBrownina bridge를 이용해 베리어옵션 평가\n먼저, T시점의 값을 생성하고, ITM일 때만 bridge를 생성해서 베리어옵션 평가!",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션방법론 Ch3-4"
    ]
  },
  {
    "objectID": "시뮬레이션실습.html",
    "href": "시뮬레이션실습.html",
    "title": "3  시뮬레이션방법론 실습",
    "section": "",
    "text": "3.1 Ch2. 난수 생성 방법",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>시뮬레이션방법론 실습</span>"
    ]
  },
  {
    "objectID": "시뮬레이션실습.html#ch2.-난수-생성-방법",
    "href": "시뮬레이션실습.html#ch2.-난수-생성-방법",
    "title": "3  시뮬레이션방법론 실습",
    "section": "",
    "text": "3.1.1 Acceptance-rejection method\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\nf = lambda x: 2/np.sqrt(2*np.pi)*np.exp(-x**2/2)\ng = lambda x: np.exp(-x)\nGinv = lambda x: -np.log(1-x)\nx = np.linspace(0,5,501)\nc = np.sqrt(2/np.pi)*np.exp(0.5)\n\n#c = 1\nplt.plot(x,f(x)/(c*g(x)))\nplt.show()\n\n\n\n\n\n\n\n\n\nplt.plot(x,f(x))\nplt.plot(x,c*g(x))\nplt.show()\n\n\n\n\n\n\n\n\n\n#random sampling from Exponential dist.\nn = 100000\ne = np.random.rand(n)\nx = Ginv(e)\nplt.hist(x, bins=50)\nplt.show()\n\n\n\n\n\n\n\n\n\n#acceptance-rejection\nu = np.random.rand(n)\nidx = u &lt; (f(x) / (c*g(x)))\ny = x[idx]\n\n#signx\ns = np.random.rand(len(y))\nsign = (+1)*(s&gt;0.5) + (-1)*(s&lt;=0.5)\nz  = y * sign\n\nfig, ax = plt.subplots(2,1,figsize=(5,10))\nax[0].hist(z, bins=50)\nstats.probplot(z, dist=\"norm\", plot=ax[1])\nplt.show()\n\n\n\n\n\n\n\n\n\n# accept된 갯수, 통계량\nz = pd.Series(z)\nprint(\"Size = \", len(z))\nprint(\"Mean = \", z.mean())\nprint(\"Std = \", z.std())\nprint(\"Skewness = \", z.skew())\nprint(\"Kurtosis = \", z.kurt())\n\nSize =  76149\nMean =  -0.0007738332678312738\nStd =  1.0026630200413653\nSkewness =  0.0014052484620287072\nKurtosis =  0.02832094979234201\n\n\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n\nu1 = np.random.rand(10000)\nu2 = np.random.rand(10000)\n\nz1 = np.sqrt(-2*np.log(u1))*np.cos(2*np.pi*u2)\nz2 = np.sqrt(-2*np.log(u1))*np.sin(2*np.pi*u2)\n\nfig, ax = plt.subplots(2,2,figsize=(10,10))\nax[0,0].plot(u1,u2,'.')\nax[0,0].set_xlabel(\"u1\")\nax[0,0].set_ylabel(\"u2\")\nax[0,1].plot(z1,z2,'.')\nax[0,1].set_xlabel(\"z1\")\nax[0,1].set_ylabel(\"z2\")\n\nz = np.concatenate([z1,z2])\nax[1,0].hist(z, bins=50)\nstats.probplot(z, dist=\"norm\", plot=ax[1,1])\n\nz = pd.Series(z)\nprint(\"Mean = \", z.mean())\nprint(\"Std = \", z.std())\nprint(\"Skewness = \", z.skew())\nprint(\"Kurtosis = \", z.kurt())\n\nMean =  -0.0005109536692502728\nStd =  1.0033155307284243\nSkewness =  0.02486394723725498\nKurtosis =  0.004147895282052172\n\n\n\n\n\n\n\n\n\n\n\n3.1.2 Box-muller method\n\n3.1.2.1 u1과 u2를 극좌표 변환(길이,각도)하여 표준정규난수를 생성\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\n\nu1 = np.random.rand(1000)\n# u1 = np.array(np.repeat(0.2,1000))\n\nu2 = np.random.rand(1000)\n# u2 = np.repeat(0.3,1000)\n\nz1 = np.sqrt(-2*np.log(u1))*np.cos(2*np.pi*u2)\nz2 = np.sqrt(-2*np.log(u1))*np.sin(2*np.pi*u2)\n\nfig, ax = plt.subplots(2,2,figsize=(10,10))\nax[0,0].plot(u1,u2,'.')\nax[0,0].set_xlabel(\"u1\")\nax[0,0].set_ylabel(\"u2\")\nax[0,1].plot(z1,z2,'.')\nax[0,1].set_xlabel(\"z1\")\nax[0,1].set_ylabel(\"z2\")\n\nz = np.concatenate([z1,z2])\nax[1,0].hist(z, bins=50)\nstats.probplot(z, dist=\"norm\", plot=ax[1,1])\n\n((array([-3.39232293, -3.14126578, -3.00201262, ...,  3.00201262,\n          3.14126578,  3.39232293]),\n  array([-3.60306231, -3.13548782, -2.83263488, ...,  3.03258201,\n          3.06619721,  3.32173166])),\n (1.0327708990587872, 0.05466952756732349, 0.9996989636334398))\n\n\n\n\n\n\n\n\n\n\nz = pd.Series(z)\nprint(\"Mean = \", z.mean())\nprint(\"Std = \", z.std())\nprint(\"Skewness = \", z.skew())\nprint(\"Kurtosis = \", z.kurt())\n\nMean =  0.05466952756732329\nStd =  1.0317810356699553\nSkewness =  -0.018633416552330598\nKurtosis =  -0.17031449124549036\n\n\n\n\n\n3.1.3 Marsaglia’s polar method\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\n\nu1 = 2*np.random.rand(10000) - 1\nu2 = 2*np.random.rand(10000) - 1\nidx = u1**2+u2**2&lt;1\nu1 = u1[idx]\nu2 = u2[idx]\nr = np.sqrt(u1**2 + u2**2)\nz1 = u1*np.sqrt(-2*np.log(r)/(r**2))\nz2 = u2*np.sqrt(-2*np.log(r)/(r**2))\n\nfig, ax = plt.subplots(2,2,figsize=(10,10))\nax[0,0].plot(u1,u2,'.')\nax[0,0].set_xlabel(\"u1\")\nax[0,0].set_ylabel(\"u2\")\nax[0,1].plot(z1,z2,'.')\nax[0,1].set_xlabel(\"z1\")\nax[0,1].set_ylabel(\"z2\")\n\nz = np.concatenate([z1,z2])\nax[1,0].hist(z, bins=50)\nstats.probplot(z, dist=\"norm\", plot=ax[1,1])\n\n((array([-3.92157497, -3.70243821, -3.58239836, ...,  3.58239836,\n          3.70243821,  3.92157497]),\n  array([-2.39692813, -2.31770256, -2.29498998, ...,  2.50125154,\n          2.86382852,  3.07531846])),\n (0.7077405533780114, 0.0010379840057725947, 0.9999066551363593))\n\n\n\n\n\n\n\n\n\n\n# 표준편차 이상함\nz = pd.Series(z)\nprint(\"Mean = \", z.mean())\nprint(\"Std = \", z.std())\nprint(\"Skewness = \", z.skew())\nprint(\"Kurtosis = \", z.kurt())\n\nMean =  0.001037984005772708\nStd =  0.7076612420548687\nSkewness =  -0.007878945852490927\nKurtosis =  -0.0333895630592389\n\n\n\n\n3.1.4 Correlated random\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\ncorr = np.array([[1,0.3,0.5],[0.3,1,0.6],[0.5,0.6,1]])\npos_def = np.all(np.linalg.eigvals(corr) &gt; 0)\nprint(corr)\nprint(pos_def)\n\n[[1.  0.3 0.5]\n [0.3 1.  0.6]\n [0.5 0.6 1. ]]\nTrue\n\n\n\n#Cholesky Decomposition\nc = np.linalg.cholesky(corr)\nx = np.random.randn(10000,3)\ny = x @ c.T\n\ny = pd.DataFrame(y, columns=['z1','z2','z3'])\nprint(\"Mean\")\nprint(y.apply(['mean','std']))\nprint()\n\nprint(\"Correlation\")\nprint(y.corr())\n\nMean\n            z1        z2        z3\nmean  0.015803 -0.003859 -0.004027\nstd   1.000498  1.011745  1.008933\n\nCorrelation\n          z1        z2        z3\nz1  1.000000  0.308514  0.509939\nz2  0.308514  1.000000  0.602482\nz3  0.509939  0.602482  1.000000\n\n\n\n#Positive Definite 하지 않은 상관계수 행렬 생성 (3번째 변수를 선형결합으로 생성)\npos_def = True\nwhile pos_def:\n    x = np.random.randn(1000, 2)\n    x = np.concatenate([x[:,0:1], x[:,0:1]+x[:,1:2], x[:,0:1]-2*x[:,1:2]], axis=1)\n    corr = pd.DataFrame(x).corr()\n    pos_def = np.all(np.linalg.eigvals(corr) &gt; 0)\n\nprint(corr)\nprint(pos_def)\n\n          0         1         2\n0  1.000000  0.726141  0.460392\n1  0.726141  1.000000 -0.276035\n2  0.460392 -0.276035  1.000000\nFalse\n\n\n\n#cholesky: error\n#c = np.linalg.cholesky(corr)\n\n#Eigenvalue Decomposition\nvalues, vectors = np.linalg.eig(corr)\nvalues = np.maximum(0, values)\nB = vectors @ np.diag(np.sqrt(values))\nprint(B)\nprint()\nprint(B @ B.T)\nprint()\n\n[[ 0.          0.98367741  0.17994096]\n [ 0.          0.83800603 -0.54566097]\n [ 0.          0.29314128  0.95606913]]\n\n[[ 1.          0.72614084  0.46039245]\n [ 0.72614084  1.         -0.27603545]\n [ 0.46039245 -0.27603545  1.        ]]\n\n\n\n\nz = np.random.randn(10000,3)\ny = z @ B.T\n\ny = pd.DataFrame(y, columns=['z1','z2','z3'])\nprint(\"Mean\")\nprint(y.apply(['mean','std']))\nprint()\nprint(\"Correlation\")\nprint(y.corr())\n\nMean\n            z1        z2        z3\nmean -0.009456 -0.017486  0.009358\nstd   1.004328  1.003282  0.998185\n\nCorrelation\n          z1        z2        z3\nz1  1.000000  0.729317  0.460086\nz2  0.729317  1.000000 -0.271913\nz3  0.460086 -0.271913  1.000000\n\n\n\n#Singular value decomposition\nprint(\"=== original data ===\")\nprint(pd.DataFrame(x).apply(['mean','std']))\nprint(pd.DataFrame(x).corr())\nprint()\n\nU, S, Vh = np.linalg.svd(x)\nnp.allclose(U[:,:3] @ np.diag(S) @ Vh, x)\n\nB = Vh.T @ np.diag(S) / np.sqrt(len(x))\nz = np.random.randn(10000,3)\ny = z @ B.T\n\nprint(\"=== simulation data ===\")\ny = pd.DataFrame(y, columns=['z1','z2','z3'])\nprint(\"Mean\")\nprint(y.apply(['mean','std']))\nprint()\nprint(\"Correlation\")\nprint(y.corr())\n\n=== original data ===\n             0         1         2\nmean  0.044162  0.067192 -0.001899\nstd   1.039992  1.440805  2.231840\n          0         1         2\n0  1.000000  0.726141  0.460392\n1  0.726141  1.000000 -0.276035\n2  0.460392 -0.276035  1.000000\n\n=== simulation data ===\nMean\n            z1        z2        z3\nmean  0.008099  0.014018 -0.003738\nstd   1.041920  1.451097  2.234800\n\nCorrelation\n          z1        z2        z3\nz1  1.000000  0.727481  0.453941\nz2  0.727481  1.000000 -0.281128\nz3  0.453941 -0.281128  1.000000",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>시뮬레이션방법론 실습</span>"
    ]
  },
  {
    "objectID": "시뮬레이션실습.html#ch3.-샘플-경로-생성-방법",
    "href": "시뮬레이션실습.html#ch3.-샘플-경로-생성-방법",
    "title": "3  시뮬레이션방법론 실습",
    "section": "3.2 Ch3. 샘플 경로 생성 방법",
    "text": "3.2 Ch3. 샘플 경로 생성 방법\n\n3.2.1 Variance reduction\n\nimport numpy as np\nfrom blackscholes import bsprice\n\ndef mcprice_controlvariates(s,k,r,q,t,sigma,nsim,flag):\n    z = np.random.randn(nsim)\n    st = s*np.exp((r-q-0.5*sigma**2)*t + sigma*np.sqrt(t)*z)\n    callOrPut = 1 if flag.lower()=='call' else -1    \n    payoff = np.maximum(callOrPut*(st-k), 0)    \n    disc_payoff = np.exp(-r*t)*payoff\n    price = disc_payoff.mean()    \n    se = disc_payoff.std(ddof=1) / np.sqrt(nsim)\n\n    c = np.cov((disc_payoff, st), ddof=1)    \n    cv_disc_payoff = disc_payoff - c[1,0]/c[1,1]*(st-s*np.exp((r-q)*t))\n    cv_price = cv_disc_payoff.mean()\n    cv_se = cv_disc_payoff.std(ddof=1) / np.sqrt(nsim)\n\n    return price, se, cv_price, cv_se \n\n\ndef mcprice_antithetic(s,k,r,q,t,sigma,nsim,flag):\n    z = np.random.randn(nsim)\n    st = s*np.exp((r-q-0.5*sigma**2)*t + sigma*np.sqrt(t)*z)\n    callOrPut = 1 if flag.lower()=='call' else -1    \n    payoff = np.maximum(callOrPut*(st-k), 0)    \n    disc_payoff = np.exp(-r*t)*payoff\n    price = disc_payoff.mean()    \n    se = disc_payoff.std(ddof=1) / np.sqrt(nsim)\n\n    z[nsim/2:] = -z[:nsim]\n    st = s*np.exp((r-q-0.5*sigma**2)*t + sigma*np.sqrt(t)*z)\n    payoff = np.maximum(callOrPut*(st-k), 0)    \n    disc_payoff = np.exp(-r*t)*payoff\n    price2 = disc_payoff.mean()    \n    se2 = disc_payoff.std(ddof=1) / np.sqrt(nsim)\n    return price, se, price2, se2 \n\ns, k, r, q, t, sigma = 100, 100, 0.03, 0.01, 0.25, 0.2\nflag = 'put'\n\n#Analytic Formula\nprice = bsprice(s,k,r,q,t,sigma,flag)\nprint(f\"   Price = {price:0.6f}\")\nprint(\"-\"*50)\n#Control-Variates Simulation\nnsim = 100000\nmc_price, se, cv_price, cv_se= mcprice_controlvariates(s,k,r,q,t,sigma,nsim,flag)\nprint(f\"MC Price = {mc_price:0.6f} / se = {se:0.6f}\")\nprint(f\"CV Price = {cv_price:0.6f} / se = {cv_se:0.6f}\")\nprint(\"-\"*50)\n#Antithetic\nmc_price, se, price2, se2= mcprice_controlvariates(s,k,r,q,t,sigma,nsim,flag)\nprint(f\"MC Price = {mc_price:0.6f} / se = {se:0.6f}\")\nprint(f\"Antithetic Price = {price2:0.6f} / se = {se2:0.6f}\")\nprint(\"-\"*50)\n\n   Price = 3.724086\n--------------------------------------------------\nMC Price = 3.742272 / se = 0.016858\nCV Price = 3.744590 / se = 0.009456\n--------------------------------------------------\nMC Price = 3.728164 / se = 0.016863\nAntithetic Price = 3.728332 / se = 0.009425\n--------------------------------------------------",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>시뮬레이션방법론 실습</span>"
    ]
  },
  {
    "objectID": "시뮬레이션hw1.html",
    "href": "시뮬레이션hw1.html",
    "title": "시뮬레이션 과제1 (베리어옵션)",
    "section": "",
    "text": "Question",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션 과제1 (베리어옵션)"
    ]
  },
  {
    "objectID": "시뮬레이션hw1.html#answer-1",
    "href": "시뮬레이션hw1.html#answer-1",
    "title": "시뮬레이션 과제1 (베리어옵션)",
    "section": "Answer 1",
    "text": "Answer 1\n\n파라미터 및 알고리즘\n먼저, MCS를 이용한 베리어옵션의 가격 계산에 필요한 파라미터는 아래와 같습니다.\ns : 기초자산의 가격\nk : 옵션의 행사가격\nt : 옵션의 만기(연)\nb : 옵션의 베리어\nr : 무위험 금리\nstd : 기초자산의 변동성(표준편차)\nUpDown : \"U\"이면 기초자산이 베리어보다 크면 knock, \"D\"이면 작으면 knock\nInOut : \"I\"이면 Knock-in, \"O\"이면 Knock-out\nCallPut : \"C\"이면 콜옵션, \"P\"이면 풋옵션\nn : 시뮬레이션의 반복 횟수\nm : 기초자산의 가격 관측 횟수\nseed(=0) : 난수 생성의 최초 시드값\n위 파라미터를 이용해 베리어옵션 가격 산출 함수를 구성할 계획이며, 알고리즘은 아래와 같습니다.\n\nGBM을 따르는 기초자산의 가격 경로를 이산오일러근사를 이용하여 구성\n이를 통해, 관측된 m개의 기초자산의 가격과 초기값 \\(S_0\\)까지 m+1개의 기초자산 기준값 생성\n기초자산 기준값과 베리어를 비교하여 옵션 pay-off 발생 여부 판단\n\nUp and Out : 모든 기준값이 베리어보다 작은 경우, pay-off 발생\nDown and Out : 모든 기준값이 베리어보다 큰 경우, pay-off 발생\nUp and In : 어느 기준값 중 하나라도 베리어보다 큰 경우, pay-off 발생\nDown and In : 어느 기준값 중 하나라도 베리어보다 작은 경우, pay-off 발생\n\npay-off가 없으면 옵션가치는 0, 있으면 Call/Put 종류에 따라 pay-off를 계산하고, 그 현재가치가 이번 시뮬레이션의 옵션의 가치\n1~5를 n번 반복후 모든 옵션가치를 평균하여 최종적으로 베리어옵션의 가격 산출\n\n이에 따른 Python 코드는 아래와 같습니다.\n\n\nPython 구현\n\nimport numpy as np\n\ndef GBM_path(s, r, std, t, m):\n    dt = t/m\n    z = np.random.standard_normal( m )\n    ratio_path = np.exp((r-0.5*(std**2))*dt+std*np.sqrt(dt)*z)\n    price_path = s*ratio_path.cumprod()\n    return price_path\n\ndef BarrierOptionsPrice(s, k, t, b, r, std, UpDown, InOut, CallPut, n=10000,m=250):\n    '''\n    s : underlying price at t=0\n    k : strike price\n    t : maturity (year)\n    b : barrier price\n    r : risk-free rate (annualization, 1%=0.01)\n    std : standard deviation of underlying return (annualization, 1%=0.01)\n    UpDown : Up is \"U\", Down is \"D\" (should be capital)\n    InOut : In is \"I\", Out is \"O\" (should be capital)\n    CallPut : Call is \"C\", Put is \"P\" (should be capital)\n    n : number of simulation\n    m : number of euler-discrete partition\n    '''\n    barrier_simulation = np.zeros(n)\n    for i in range(n):\n        underlying_path = GBM_path(s,r,std,t,m)\n\n        if UpDown==\"U\" and InOut==\"O\" :\n            payoff_logic = 1 if np.sum(underlying_path&gt;=b)==0 else 0\n        elif UpDown==\"U\" and InOut==\"I\" :\n            payoff_logic = 0 if np.sum(underlying_path&gt;=b)==0 else 1\n        elif UpDown==\"D\" and InOut==\"O\" :\n            payoff_logic = 1 if np.sum(underlying_path&lt;b)==0 else 0\n        elif UpDown==\"D\" and InOut==\"O\" :\n            payoff_logic = 0 if np.sum(underlying_path&lt;b)==0 else 1\n       \n        if CallPut==\"C\" :\n            plain_price = np.maximum(underlying_path[-1]-k,0)*np.exp(-r*t)\n        elif CallPut==\"P\" :\n            plain_price = np.maximum(k-underlying_path[-1],0)*np.exp(-r*t)\n\n        barrier_simulation[i] = plain_price*payoff_logic\n    \n    barrier_price = barrier_simulation.mean()\n\n    return barrier_price, barrier_simulation\n\n\n\n\n\n\n\n저는 한번의 시뮬레이션에 이용되는 이산-오일러 구간마다의 기초자산가격 m개를,\n먼저 m개의 z분포 변수를 생성하고, log-normal dist.에 따른 구간별 수익률로 변환 후,\n해당 수익률을 누적곱하여 path를 생성하였습니다.\n즉, 구간별 가격을 하나씩 생성하여 총 n*m번의 루프문을 작성하는 대신 n번의 루프문을 작성한 것 입니다.\n또한 이러한 방식 외에도, 한번에 nm개의 z분포 변수를 생성하고, mn matrix로 변환하여\n루프문 없이 한번의 행렬연산으로 MCS를 진행하는 방법도 생각해볼 수 있으나, (속도는 빠를 것으로 예상)\n시뮬레이션의 횟수 n이 100만번 혹은 그 이상 커질 경우 메모리부족 등이 우려되어 고려하지 않았습니다.\n\n\n\n\n\nAnalytic Solution과 비교\n해당 코드를 이용하여 베리어옵션 가격을 추정할 수 있으며, 이를 예재(QuantLib)의 결과값과 비교해보겠습니다.\n시뮬레이션 파라미터는 n=10000, m=250으로 설정하였습니다.\n\nimport QuantLib as ql\n\nS = 100; r = 0.03; vol = 0.2; T = 1; K = 100; B = 120; rebate = 0\nbarrierType = ql.Barrier.UpOut; optionType = ql.Option.Call\n\n#Barrier Option\ntoday = ql.Date().todaysDate(); maturity = today + ql.Period(T, ql.Years)\n\npayoff = ql.PlainVanillaPayoff(optionType, K)\neuExercise = ql.EuropeanExercise(maturity)\nbarrierOption = ql.BarrierOption(barrierType, B, rebate, payoff, euExercise)\n\n#Market\nspotHandle = ql.QuoteHandle(ql.SimpleQuote(S))\nflatRateTs = ql.YieldTermStructureHandle(ql.FlatForward(today, r, ql.Actual365Fixed()))\nflatVolTs = ql.BlackVolTermStructureHandle(ql.BlackConstantVol(today, ql.NullCalendar(), vol, ql.Actual365Fixed()))\nbsm = ql.BlackScholesProcess(spotHandle, flatRateTs, flatVolTs)\nanalyticBarrierEngine = ql.AnalyticBarrierEngine(bsm)\n\n#Pricing\nbarrierOption.setPricingEngine(analyticBarrierEngine)\nQL_UOCprice = barrierOption.NPV()\n\n# Hyeonghwan Pricing\nHH_UOCprice, HH_UOCmatrix = BarrierOptionsPrice(S, K, T, B, r, vol, \"U\", \"O\", \"C\")\n\nprint(\"Up & Out Call with S=100, K=100, B=120, T=1, Vol=0.2, r= 0.03\",\"\\n\",\n    \"QuantLib price :\", QL_UOCprice,\"\\n\",\n    \"Hyeonghwan price :\", HH_UOCprice,\"\\n\",\n    \"Difference is\", QL_UOCprice - HH_UOCprice)\n\nUp & Out Call with S=100, K=100, B=120, T=1, Vol=0.2, r= 0.03 \n QuantLib price : 1.155369999815115 \n Hyeonghwan price : 1.308270076750196 \n Difference is -0.152900076935081\n\n\n다음은 동일한 파라미터를 이용하여 Up and In Call Barrier Option price를 비교하였습니다.\n\n\nUp & In Call with S=100, K=100, B=120, T=1, Vol=0.2, r= 0.03 \n QuantLib price : 8.258033384037908 \n Hyeonghwan price : 8.07106974868496 \n Difference is 0.18696363535294758\n\n\n비교결과, 대체로 유사하였으나 오차가 상당수준 발생하였습니다.\nUp&Out에서는 MCS의 결과값이 크고 Up&In에서는 Analytic form의 결과값이 큰 경향이 있는데,\n이는 이산-오일러 근사을 통해 Continuous 구간을 m개(discrete)로 나누면서 발생한 것으로 추정됩니다.\n(모형 이산화 오류(Model Discretization Error)로 인해 편의(Bias) 발생)\n즉, 실제 베리어 Knock 여부는 기초자산의 연속적인 가격흐름을 모두 관측하여 판단해야하지만,\n이산화 과정에서 m번만 관측(m=250은 1일에 1번꼴)하게 되면서 그 사이의 가격을 관측할 수 없게 됩니다.\n이로 인해 Knock-out 방식의 옵션은 고평가되고, Knock-in 방식의 옵션은 저평가되는 결과가 나타납니다.\n이러한 편의는 m이 커질수록 작아져서 0으로 수렴하게 되며, 이에 대해서는 Answer3에서 다루겠습니다.",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션 과제1 (베리어옵션)"
    ]
  },
  {
    "objectID": "시뮬레이션hw1.html#answer-2",
    "href": "시뮬레이션hw1.html#answer-2",
    "title": "시뮬레이션 과제1 (베리어옵션)",
    "section": "Answer 2",
    "text": "Answer 2\n\nIn-Out parity 정의\n베리어옵션의 In-Out parity란, 특정 상황에서 베리어옵션과 plain vanilla option의 가격 사이에 성립하는 등식을 말합니다.\n구체적으로 plain vanilla call option이 \\(c_{plain}=f(S,K,T,r,\\sigma,d)\\)로 주어져있고,\n베리어 B를 Knock할 때, 위 옵션과 동일한 pay-off를 제공하는 베리어옵션을 \\(c_{In}\\), \\(c_{Out}\\)라고 한다면,\n이들 옵션 사이에는 아래와 같은 등식이 성립하게 됩니다.\n\\[c_{In}+c_{Out}=c_{plain}\\]\n이는 풋옵션에서도 동일하게 성립되며, 일반적인 유로피안 옵션은 Knock-In + Knock-Out 배리어옵션으로 분해할 수 있다는 의미가 됩니다.\n\n\n증명\n예시를 통해 In-Out parity가 성립함을 쉽게 알 수 있습니다.\n배리어가 B로 동일한 Knock-In & Out 옵션을 각각 I와 O라고 하겠습니다.\nI는 lookback period동안 기초자산의 가격이 B를 한번이라도 Knock하는 경우 payoff가 발생합니다. (Up & Down 포괄)\nO는 lookback period동안 기초자산의 가격이 B를 한번이라도 Knock하지 않는 경우 payoff가 발생합니다.\n따라서, 기간동안 Knock가 발생하면 I는 payoff가 발생하고 O는 payoff가 0이 되며,\nKnock가 발생하지 않으면 I는 payoff가 0이 되고 O는 payoff가 발생합니다.\n즉, I+O로 구성된 배리어옵션 포트폴리오를 생각하면 모든 기초자산의 가격범위에 대하여 payoff가 한번 발생하고\n해당 payoff는 plain vanilla 옵션의 payoff와 동일하므로 In-Out parity가 성립하게 됩니다.\n이를 수식으로 표현하면 아래와 같습니다.\n\\(c_{In}+c_{Out}=E^Q[e^{-rT}(S_T-K)^+\\mathbb{I}_{(\\exists S_t\\geq B)}]+E^Q[e^{-rT}(S_T-K)^+\\mathbb{I}_{(\\forall S_t&lt; B)}]\\)\n\\(\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=E^Q[e^{-rT}(S_T-K)^+](\\mathbb{I}_{(\\exists S_t\\geq B)}+\\mathbb{I}_{(\\forall S_t&lt;B)})=E^Q[e^{-rT}(S_T-K)^+]\\)\n\\(\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;\\;=c_{plain}\\;where\\;\\mathbb{I}_A=1\\;if\\;A\\;is\\;true\\;else\\;0\\)\n이는 MCS방식으로 베리어옵션을 가치평가를 할 때에도 쉽게 알 수 있는데,\n위 python코드에서 베리어옵션의 종류에 따라 payoff 발생여부를 판별할 때 사용한 if문에서\nIn, Out의 차이는 동전던지기의 앞뒷면처럼 상호배타적(mutually exclusive)임을 알 수 있습니다.\n\n\nMCS에서의 활용\n한종류의 베리어옵션과 plain 옵션의 가격을 알고 있다면 다른 한 종류의 베리어옵션의 가격이 결정되므로,\nMCS를 이용하여 베리어옵션의 가격을 계산할 때 두번의 시뮬레이션을 한번으로 축소할 수 있을 것으로 생각해볼 수 있습니다.\n그러나, 이는 현재 위 코드가 사전에 In, Out을 지정하고 한 경우에 대해서 return값을 반환하기 때문인데\n이를 수정하여 Input으로 In, Out을 지정하지 않고 함수 내에서 In, Out 결과값을 각각 반환하게 한다면\n시뮬레이션의 축소효과는 사라지게 됩니다.\n더 나아가, 한번의 GBM경로를 생성하는 것에서 plain vanilla call&put, 배리어 In&Out, Up&Down옵션의 가격을\n모두 산출할 수 있으므로 parity를 이용하여 시뮬레이션 시간을 극적으로 단축하기는 어려울 것 같습니다.\n이외에도 산출된 결과값들끼리 parity를 이용해 적정성 여부를 검증하는 용도로는 활용성이 있을 것 같습니다.\n이때에도, parity가 성립하려면 bsm fomula를 통한 plain vanilla옵션이 아닌,\n베리어옵션과 동일한 이산오일러근사를 사용한 plain vanilla옵션의 가격을 사용해야 합니다.",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션 과제1 (베리어옵션)"
    ]
  },
  {
    "objectID": "시뮬레이션hw1.html#answer-3",
    "href": "시뮬레이션hw1.html#answer-3",
    "title": "시뮬레이션 과제1 (베리어옵션)",
    "section": "Answer 3",
    "text": "Answer 3\nN, M에 따른 bias와 variance의 변화를 살펴보겠습니다.\n이를 살펴보기 위해 시뮬레이션 결과값인 베리어옵션가격. 즉, 표본평균 \\(\\bar y\\)의 분포를 이용하겠습니다.\nCLT에 따라 베리어옵션가격의 분포는 \\(\\bar y\\sim N(y_{real}, \\frac{\\sigma^2}{N})\\)를 따르게 됩니다.\n\\(Bias^2=(E[\\bar y]-y_{real})^2\\), \\(Variance=E[(\\bar y-E[\\bar y])^2]\\)이므로,\n주어진 N, M의 값에 대하여 K(&gt;30)번 시뮬레이션을 반복하여 \\(\\bar y_k\\)를 얻은 후 이를 계산해보겠습니다.\n\\(y_{real}\\)은 QuantLib의 결과값이라고 가정하고, Up&Out call옵션을 예시로 살펴보았습니다.\n\n\n\n\n\n\nN값이 충분히 크다면 \\(\\bar y\\)의 분산이 충분히 작아지므로, 한번의 시뮬레이션으로 이 근사값을 계산할 수 있습니다.\n\\(Bias^2\\approx (\\bar y-y_{real})^2\\)\n\\(Variance=Var[\\bar y]=\\frac{\\sigma^2}{N}\\approx \\frac{s^2}{N}=S.E^2\\)\n\n\n\n\nimport time\ny_real = QL_UOCprice\n\nN = 1000; M = 250\ny_k, se_k = np.zeros(30), np.zeros(30)\n\nstart = time.time()\nfor i in range(30):\n    y_mean, y = BarrierOptionsPrice(S, K, T, B, r, vol, \"U\", \"O\", \"C\", n=N, m=M)\n    se = y.std(ddof = 1) / np.sqrt(N)\n    y_k[i], se_k[i] = y_mean, se\nend = time.time()\n\nbias = (y_k.mean()-y_real)**2\nvariance = y_k.var(ddof = 1)\nstan_error = se_k.mean()**2\ncal_time = (end-start)/30\n\nprint(\"When N :\",N,\" and M :\",M,\"\\n\",\n\"Bias^2 :\",bias,\"\\n\",\n\"Variance :\", variance, \"\\n\",\n\"S.E^2 :\", stan_error, \"\\n\",\n\"MSE :\", bias+variance, \"\\n\",\n\"Time for 1 simulation:\", cal_time, \"second\", \"\\n\")\n\nWhen N : 1000  and M : 250 \n Bias^2 : 0.02034260381728806 \n Variance : 0.011172493745371749 \n S.E^2 : 0.011352372141769877 \n MSE : 0.03151509756265981 \n Time for 1 simulation: 0.019492228825887043 second \n\n\n\nN을 증가시킬수록 시뮬레이션의 분산은 감소하나 편의는 감소하지 않는 경향이 있습니다. \n\n\nWhen N : 3000  and M : 250 \n Bias^2 : 0.021898165754529512 \n Variance : 0.0030069115133548887 \n S.E^2 : 0.003844552850899204 \n MSE : 0.0249050772678844 \n Time for 1 simulation: 0.05749679406483968 second \n\n\n\n\n\nWhen N : 5000  and M : 250 \n Bias^2 : 0.022792874372837498 \n Variance : 0.0021947889967483592 \n S.E^2 : 0.002318727780316533 \n MSE : 0.02498766336958586 \n Time for 1 simulation: 0.0960538387298584 second \n\n\n\n\n\nWhen N : 10000  and M : 250 \n Bias^2 : 0.020293637118458125 \n Variance : 0.0012303064071476398 \n S.E^2 : 0.0011491453338025096 \n MSE : 0.021523943525605764 \n Time for 1 simulation: 0.19469877084096274 second \n\n\n\nM을 증가시킬수록 편의는 감소하나 분산은 유사한 경향이 있습니다. \n\n\nWhen N : 3000  and M : 100 \n Bias^2 : 0.052700199147094576 \n Variance : 0.00488221648081155 \n S.E^2 : 0.0041419361049547685 \n MSE : 0.05758241562790613 \n Time for 1 simulation: 0.04366606871287028 second \n\n\n\n\n\nWhen N : 3000  and M : 250 \n Bias^2 : 0.020866053684230154 \n Variance : 0.0037050776372161347 \n S.E^2 : 0.003828211154638729 \n MSE : 0.02457113132144629 \n Time for 1 simulation: 0.05730129877726237 second \n\n\n\n\n\nWhen N : 3000  and M : 500 \n Bias^2 : 0.008911122160032332 \n Variance : 0.0034038382851468113 \n S.E^2 : 0.003636138747387505 \n MSE : 0.012314960445179143 \n Time for 1 simulation: 0.08127163251241049 second \n\n\n\n\n\nWhen N : 3000  and M : 1000 \n Bias^2 : 0.005096172348748554 \n Variance : 0.0026514947754144465 \n S.E^2 : 0.0035802674641335582 \n MSE : 0.007747667124163001 \n Time for 1 simulation: 0.12787216504414875 second \n\n\n\nN과 M을 증가시킬수록 계산시간도 증가하므로, 한정된 계산시간 하에 MSE를 최소화하도록 N과 M을 정해야할 필요가 있습니다.",
    "crumbs": [
      "시뮬레이션 방법론('24 가을)",
      "시뮬레이션 과제1 (베리어옵션)"
    ]
  },
  {
    "objectID": "이자율hw1.html",
    "href": "이자율hw1.html",
    "title": "이자율파생상품 과제1",
    "section": "",
    "text": "Question 1",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  },
  {
    "objectID": "이자율hw1.html#question-1",
    "href": "이자율hw1.html#question-1",
    "title": "이자율파생상품 과제1",
    "section": "",
    "text": "Answer 1 : 0.631%\n(ㄱ)은행은 문제의 채권발행으로 인해 향후 3년간 연 4%의 고정금리 이자를 지급해야하는 상황이며,\n이 고정금리 이자지급을 변동금리로 바꾸는 것이 목표입니다.\n스왑딜러와 IRS를 체결함으로써 이를 해결할 수 있고, (ㄱ)은행은 4% fixed receiver가 됩니다.\n4%만큼 fixed rate를 지급하고, (변동금리+x)만큼 Float rate를 지급하게 되는데, 계약체결시점에서 (ㄱ)은행의 NPV가 0이 되도록 하는 스프레드(x)를 산출하면 됩니다.\n한편, swap rate를 이용하여 IRS를 체결하면 체결시점의 NPV는 0입니다. (swap rate vs. float rate)\n따라서, 4%-annual swap rate를 통해 간단히 스프레드 x를 계산할 수 있습니다.\n6개월 스왑금리를 annal로 바꾸면 \\((1+\\frac{0.03341}{2})^2=1+r,\\;r=0.03369\\)이므로, \\(x=0.03369-0.04=-0.00631\\)입니다.\n즉, (ㄱ)은행과 스왑딜러가 (4% vs. float rate + 0.631%)의 IRS를 체결하면 됩니다..",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  },
  {
    "objectID": "이자율hw1.html#question-2",
    "href": "이자율hw1.html#question-2",
    "title": "이자율파생상품 과제1",
    "section": "Question 2",
    "text": "Question 2\n\n\nAnswer 2 : 최소 5.01%\n고객은 은행으로부터 USD SOFR를 받고, EUR fixed를 지급하므로,\n은행은 EUR fixed를 받고, USD SOFR를 지급해야합니다.\n따라서, 은행은 고객과의 계약헤지를 위해 USD SOFR를 받고, EUR fixed를 지급하는 cashflow를 만들어야 합니다.\n이를 위해 두가지 계약을 사용합니다.\n\nEUR 금리스왑, fixed payer\n베이시스 통화스왑 EUR ESTR payer / USD SOFR receiver\n\n1번 계약에서 은행은 5.05% 고정금리를 지급하고 EUR ESTR을 수취합니다.\n2번 계약에서 은행은 EUR ESTR - 4bp를 지급하고, USD SOFR를 수취합니다.\n두 계약을 결합하면, 은행은 5.01% 고정금리를 지급하고 USD SOFR를 수취하게 됩니다.\n따라서, 고객과의 계약에서 은행은 최소 5.01%의 EUR fixed를 받아야합니다.",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  },
  {
    "objectID": "이자율hw1.html#question-3",
    "href": "이자율hw1.html#question-3",
    "title": "이자율파생상품 과제1",
    "section": "Question 3",
    "text": "Question 3\n \n\nAnswer 3\n트레이더는 현재 두가지 위험에 직면해있습니다.\n\n현재(6월)부터 9.16일까지의 금리하락으로 initial level SOFR가 하락할 위험\n11.6-7 FOMC 결과에 따라 target rate SOFR가 하락할 위험\n\n이 두가지 위험을 주어진 hedging instrument를 통해 관리하려면, 1개월 10월 SOFR선물을 매도하면 됩니다.\n1개월 10월 SOFR선물은 10.16일 initial level과 11월 FOMC target rate에 영향을 받는 상품입니다.\n문제의 가정처럼 오직 두가지의 요소에 의해 선물가격이 영향을 받는다면, 9.16~11.6까지 및 11.7~12월 만기까지의 SOFR의 변화가 없다는 의미입니다.\n따라서 현재시점에 1개월 10월 SOFR선물을 매도한다면, 9.16일 initial level의 변동위험은 10.16일 initial level 변동위험과 정확하게 상쇄되며 11월 FOMC target rate 리스크도 정확히 상쇄될 것 입니다.\n즉, 9.16부터 10.16까지 SOFR의 변동이 없고, 11월 선물만기일 이후 12월 선물만기일까지 SOFR의 변동이 없다면 1개월 10월선물은 완전헷지가 가능한 hedge instrument가 됩니다.\n한편, 1개월 11월 SOFR선물의 경우 11.16일 initial level에 영향을 받으며 이후 FOMC가 없으므로 오직 initial level에 따라서 가격이 결정되는 상품이 됩니다.\n하지만 11월 initial level은 현재시점부터 9월까지의 initial level 변동과 그 이후의 금리변동, 11월 FOMC target rate 변동이 모두 반영되어있는 금리입니다.\n따라서 간접적으로 트레이더의 위험을 모두 내포하고 있는 상품이며, 이를 현재시점에 매도한다면 헷지가 가능하게 됩니다.\n다만, 1개월 11월 선물을 이용하는 경우, 기존 포지션의 모든 가격변동분이 11.16일에 일시반영되므로 그 사이에 FOMC 급락으로 일일정산 손실이 누적되는 등 유동성 위험에 직면할 수 있습니다.\n또한, 실제 시장에서는 SOFR금리가 일일단위로 변동하며 3개월 선물과 1개월 선물의 compounding 기간이 달라 이러한 완전헷지는 불가능할 것으로 보입니다.",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  },
  {
    "objectID": "이자율hw1.html#question-4",
    "href": "이자율hw1.html#question-4",
    "title": "이자율파생상품 과제1",
    "section": "Question 4",
    "text": "Question 4\n\n\nAnswer 4 : -0.1980\n\nMarket price of risk \\(\\lambda=\\frac{e^{-r_0t}E[P_1(2)]-P_0(2)}{P_{1,0}-P_{1,1}}\\)입니다.\n위 그림처럼 이를 각각 계산하면, \\(\\lambda=-0.1980\\)입니다.",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  },
  {
    "objectID": "이자율hw1.html#question-5",
    "href": "이자율hw1.html#question-5",
    "title": "이자율파생상품 과제1",
    "section": "Question 5",
    "text": "Question 5\n\n\nAnswer 5 : 0.2974\n\n포트폴리오 복제 및 위험중립가치평가를 통해 옵션가격을 계산할 수 있습니다.\n위험중립가치평가를 이용할 때, 위험중립확률은 \\(p^*=\\frac{e^{r_0/2}P_0(2)-P_{1,1}}{P_{1,0}-P_{1,1}}=0.7000\\)이므로,\n\\(c=e^{-r_0t}(p^*(P_{1,0}-K)^++(1-p^*)(P_{1,1}-K)^+)=0.2974\\)",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  },
  {
    "objectID": "수치해석1.html",
    "href": "수치해석1.html",
    "title": "수치해석학 Ch1",
    "section": "",
    "text": "강의 개요 : 금융수치해석의 필요성\n주로 파생상품 평가와 최적화 방법론에 대해서 다룰 예정",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch1"
    ]
  },
  {
    "objectID": "수치해석1.html#강의-개요-금융수치해석의-필요성",
    "href": "수치해석1.html#강의-개요-금융수치해석의-필요성",
    "title": "수치해석학 Ch1",
    "section": "",
    "text": "파생상품 평가\n\\(ds=rSdt+\\sigma SdW^Q\\)\n기하학적 브라운운동을 따르는 기초자산에 대한 파생상품의 가격 \\(f(t,S)\\)는 아래의 PDE로 표현됨\n\\(f_t+\\frac{1}{2}\\sigma^2S^2f_{ss}+rSf_s-rf=0\\)\n이 블랙숄즈 미분방정식을 컴퓨터로 풀어내는 것이 주요 내용임\n여기에는 반드시 연속적인 수식을 이산화하는 과정이 필요하며, 다양한 수치해석적인 기법이 활용됨\n대표적으로 유한차분법(Finite Difference Method, FDM)이 존재\n\n\n최적화 방법론\n이외의 다양한 최적화방법론은 시간이 여유롭다면 이것저것 다룰 예정\n\nMinimum Variance Portfolio : Single-period에 대해 Sharpe ratio 극대화 등\nStochastic programming : Multi-period에 대해 Minimum var 문제 해결 등\nNon-convex optimization : 미분을 통해 극값을 산출할 수 없는 경우의 최적화\nParameter estimation 또는 Model calibration : \\(min_{\\theta,\\sigma,k}\\sum(model\\;price - market\\;price)^2\\)와 같은 문제 등",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch1"
    ]
  },
  {
    "objectID": "수치해석1.html#컴퓨터-연산에-대한-이해",
    "href": "수치해석1.html#컴퓨터-연산에-대한-이해",
    "title": "수치해석학 Ch1",
    "section": "컴퓨터 연산에 대한 이해",
    "text": "컴퓨터 연산에 대한 이해\n수치해석기법을 사용할 때 필연적으로 오차(error) 발생\n\nTruncation error : 연속적인 수학적인 모델을 이산화하면서 발생하는 오차(e.g. 미분계수)\nRounding error : 컴퓨터 시스템상 실수(real number)를 정확히 표현할 수 없는 데에서 기인(2진법 vs. 10진법)\n\n\nimport numpy as np\n\na = 0.1\n\nprint(a+a+a==0.3,a+a+a+a==0.4)\n\nFalse True\n\n\n\nRounding error 관련\n컴퓨터가 실수를 나타내는 방법은 일반적으로 \\(x=\\pm n\\times b^e\\)로 나타냄.\n여기서 \\(n\\)은 가수, \\(e\\)는 지수이며, 일반적으로 밑인 \\(b\\)는 2를 사용함.\n컴퓨터에서 많이 사용하는 float타입 실수는 32bit를 사용하여 실수를 표현하며,\n이는 \\(2^32\\)가지로 모든 실수를 표현하게됨을 의미함. (정수는 int타입으로 모두 표현가능)\n따라서 소수점에 따라 정확한 값을 나타내지 못하는 문제는 항상 존재.\n\nPrecision of floating point arithmetic\n실수표현의 정밀도는 \\(float(1+\\epsilon_{math})&gt;1\\)이 되는 가장 작은 \\(\\epsilon_{math}\\)를 의미\n\ne = 1\nwhile 1 + e &gt; 1:\n    e = e/2\ne_math = 2 * e\nprint(e_math)\n\n2.220446049250313e-16\n\n\n내장함수 활용 가능. 파이썬에서는 기본적으로 64bit double타입을 사용함\n\nimport numpy as np\nprint(np.finfo(np.double).eps,\n      np.finfo(float).eps)\n\n2.220446049250313e-16 2.220446049250313e-16\n\n\n\nprint(1+e, 1+e+e, 1+2*e, 1+1.0000001*e)\n\n1.0 1.0 1.0000000000000002 1.0000000000000002\n\n\n많이 쓰이는 double타입의 경우 64bit로 실수를 표현하는데,\n\\(x=\\pm n\\times 2^e\\)에서 부호(\\(\\pm\\)) 1자리, 가수(\\(n\\)) 52자리, 지수 11자리(\\(e\\))를 의미",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch1"
    ]
  },
  {
    "objectID": "수치해석1.html#계산오차",
    "href": "수치해석1.html#계산오차",
    "title": "수치해석학 Ch1",
    "section": "계산오차",
    "text": "계산오차\n절대오차 : \\(|{\\hat{x}-x}|\\)\n상대오차 : \\(\\frac{|{\\hat{x}-x}|}{|x|}\\)\n결합오차 : \\(e_{comb}=\\frac{|{\\hat{x}-x}|}{|x|+1}\\)\n\n유한차분을 이용한 도함수의 근사\n\\[f'(x)=\\lim_{h\\rightarrow 0}\\frac{f(x+h)-f(x)}{h}\\]\n컴퓨터로는 \\(h\\rightarrow 0\\)을 정확히 표현할 수 없음.\n따라서, 적당히 작은 값으로 이를 대체하여 \\(f'(x)\\)를 근사해야함.\n\nTruncation error 최소화를 위해서는 h는 작을 수록 좋음\n그러나, 너무 작은 값을 선택하면 rounding error가 발생하여 \\(x=x+h\\) 될 가능성\n\n\nTaylor expansion\n\\[f(x)=\\sum_{k=0}^\\infty \\frac{f^{(k)}(x_0)}{k!}(x-x_0)^{k}=\\sum_{k=0}^n \\frac{f^{(k)}(x_0)}{k!}(x-x_0)^{k}+\\frac{f^{(n+1)}(\\xi)}{(n+1)!}(x-x_0)^{n+1}\\]\n이를 도함수에 적용하면,\n\\[f(x+h)=f(x)+hf'(x)+\\frac{h^2}{2}f''(x)+\\frac{h^3}{3!}f'''(x)+\\dotsm+\\frac{h^n}{n!}f^{(n)}(x)+R_n(x+h)\\]\n\\(n=1\\)을 적용하면,\n\\(\\Rightarrow\\;f(x+h)=f(x)+hf'(x)+\\frac{h^2}{2}f''(\\xi)\\;for\\;\\xi\\in[x,x+h]\\)\n\\(\\Rightarrow\\;f'(x)=\\frac{f(x+h)-f(x)}{h}-\\frac{h}{2}f''(\\xi)\\;(Forward\\;Approximation)\\)\n\\(n=2\\)를 적용하고 forward - backward를 정리하면,\n\\(f'(x)=\\frac{f(x+h)-f(x-h)}{h}-\\frac{h^2}{3}f'''(\\xi)\\;(Central\\;Difference\\;Approximation)\\)\n::: {.callout, title=“Central Difference Approximation”} \\(for\\;n=2,\\)\n\\((Forward)\\;f(x+h)=f(x)+hf'(x)+\\frac{h^2}{2}f''(x)+\\frac{h^3}{3!}f'''(\\xi_+),\\;\\xi\\in[x,x+h]\\)\n\\((Backward)\\;f(x-h)=f(x)-hf'(x)+\\frac{h^2}{2}f''(x)-\\frac{h^3}{3!}f'''(\\xi_-),\\;\\xi\\in[x-h,x]\\)\n\\(f(x+h)-f(x-h)=2hf'(x)+\\frac{h^2}{6}\\{f'''(\\xi_+)+f'''(\\xi_-)\\}\\)\n\\(\\Rightarrow\\;f'(x)=\\frac{f(x+h)-f(x-h)}{h}-\\frac{h^2}{3}f'''(\\xi),\\;\\xi\\in[x-h,x+h]\\) :::\n위의 식에서 볼 수 있는 것처럼, Central 방식에서는 truncation error의 order가 \\(h^2\\)이므로,\n다른 방식에 비해서 오차가 훨씬 줄어들게 됨\n유사한 방식으로 이계도함수와 편도함수를 유도하면,\n\\(f''(x)=\\frac{f(x+h)+f(x-h)-2f(x)}{h^2}-\\frac{h^2}{24}f^{(4)}(\\xi)\\)\n\\(f_x(x,y)=\\frac{f(x+h_x,y)-f(x-h_x,y)}{2h_x}+trunc.\\;error\\)\n\n\n\n총오차 및 최적의 h 산출\nForward difference approximation을 사용하고, \\(|f''(x)|&lt;=M\\)이라고 하면,\n\\(|f_h'(x)-f'(x)|=\\frac{h}{2}|f''(x)|&lt;=\\frac{h}{2}M\\;(trunc.\\;error)\\)\n유인물 참조\n총오차 최소화를 위한 \\(h^*\\) 산출이 목표\n\n\n유한차분을 이용한 도함수 근사 예시\n\\(f(x)=cos(x^x)-sin(e^x)\\)\n함수 및 도함수(analytic form) 정의 및 도식화\n\nimport numpy as np \nimport matplotlib.pyplot as plt \ndef fun(x):\n    return np.cos(x**x) - np.sin(np.exp(x))\n\ndef fprime(x):\n    return -np.sin(x**x)*(x**x)*(np.log(x)+1)  - np.cos(np.exp(x))*np.exp(x)\n\nx = np.linspace(0.5,2.5,101)\ny = fun(x)\nplt.plot(x,y,'-')\n\n\n\n\n\n\n\n\n미분계수 산출\n\nx = 1.5\nd = fprime(x)\nprint(\"derivative = \", d)\n\nderivative =  -1.466199173237208\n\n\nforward 및 central difference approx. 산출 및 비교, 총오차를 log scale로 표현\ntrunc. error는 h가 작아질수록 감소하지만 특정구간 이후에는 rounding error가 발생하므로\n총오차는 항상 감소하지 않게 됨.\n최적 \\(h^*\\)를 찾는 것이 매우 중요함\n\np = np.linspace(1,16,151)\nh = 10**(-p)\n\ndef forward_difference(x,h):\n    return (fun(x+h)-fun(x)) / h\n\ndef central_difference(x,h):\n    return (fun(x+h)-fun(x-h)) / (2*h)\n\nfd = forward_difference(x, h)\ncd = central_difference(x, h)\nprint(\"forward = \", fd)\nprint(\"central = \", cd)\n\nfd_error = np.log(np.abs(fd-d)/np.abs(d))\ncd_error = np.log(np.abs(cd-d)/np.abs(d))\nplt.plot(p,fd_error, p, cd_error)\nplt.legend(['forward difference', 'central difference'])\n\nforward =  [-2.62212289 -2.37366424 -2.17930621 -2.02733993 -1.90838758 -1.81511559\n -1.74184228 -1.68417626 -1.63872005 -1.60283855 -1.57448171 -1.55204964\n -1.53429022 -1.52022092 -1.50906909 -1.50022597 -1.49321118 -1.48764519\n -1.48322779 -1.47972134 -1.47693759 -1.47472735 -1.4729723  -1.4715786\n -1.47047179 -1.46959277 -1.46889464 -1.46834015 -1.46789975 -1.46754995\n -1.4672721  -1.46705142 -1.46687612 -1.46673689 -1.46662629 -1.46653844\n -1.46646866 -1.46641323 -1.46636921 -1.46633424 -1.46630646 -1.46628439\n -1.46626686 -1.46625294 -1.46624188 -1.4662331  -1.46622612 -1.46622058\n -1.46621618 -1.46621268 -1.4662099  -1.4662077  -1.46620594 -1.46620455\n -1.46620344 -1.46620257 -1.46620187 -1.46620131 -1.46620087 -1.46620053\n -1.46620025 -1.46620002 -1.46619985 -1.46619971 -1.46619959 -1.46619951\n -1.46619944 -1.46619939 -1.46619934 -1.46619931 -1.46619927 -1.46619923\n -1.46619922 -1.46619918 -1.46619921 -1.46619915 -1.46619915 -1.46619919\n -1.46619909 -1.46619907 -1.46619916 -1.46619915 -1.46619876 -1.46619938\n -1.46619893 -1.46619919 -1.46619932 -1.46619869 -1.46619769 -1.4662003\n -1.46619716 -1.46619985 -1.46619876 -1.46620071 -1.46619865 -1.46619427\n -1.46619269 -1.46620314 -1.46618158 -1.46619854 -1.46618273 -1.46617469\n -1.46619173 -1.46614311 -1.46615961 -1.46626449 -1.46620595 -1.46619201\n -1.46615356 -1.46621617 -1.46616053 -1.46617469 -1.46608615 -1.46578868\n -1.46632693 -1.46612406 -1.46518938 -1.46619201 -1.46545305 -1.46568705\n -1.46438417 -1.46757238 -1.46221506 -1.46202287 -1.46130718 -1.46050672\n -1.45413969 -1.46897416 -1.45004198 -1.46392328 -1.44328993 -1.4535955\n -1.40766793 -1.46202287 -1.39437708 -1.40433339 -1.32596324 -1.44671698\n -1.40100674 -1.41101039 -1.66533454 -1.39768798 -1.05575095 -0.88607446\n -1.11550166 -0.70216669 -0.88397549 -1.11285921 -1.40100674 -1.76376299\n  0.        ]\ncentral =  [-1.5635526  -1.52856423 -1.50592274 -1.49141188 -1.48216656 -1.4762975\n -1.47258018 -1.47022905 -1.46874334 -1.46780503 -1.46721263 -1.46683872\n -1.46660274 -1.46645382 -1.46635985 -1.46630056 -1.46626314 -1.46623954\n -1.46622464 -1.46621524 -1.46620931 -1.46620557 -1.46620321 -1.46620172\n -1.46620078 -1.46620019 -1.46619981 -1.46619958 -1.46619943 -1.46619933\n -1.46619927 -1.46619924 -1.46619921 -1.4661992  -1.46619919 -1.46619918\n -1.46619918 -1.46619918 -1.46619918 -1.46619917 -1.46619917 -1.46619917\n -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917\n -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917\n -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917\n -1.46619918 -1.46619917 -1.46619917 -1.46619917 -1.46619917 -1.46619917\n -1.46619917 -1.46619917 -1.46619918 -1.46619918 -1.46619917 -1.46619916\n -1.46619918 -1.46619915 -1.46619918 -1.46619915 -1.46619923 -1.46619922\n -1.46619909 -1.46619924 -1.46619938 -1.46619908 -1.46619894 -1.46619938\n -1.46619879 -1.46619919 -1.4661991  -1.46619925 -1.46619804 -1.46620118\n -1.46619883 -1.46620125 -1.46619876 -1.46620071 -1.46620423 -1.46619603\n -1.4661949  -1.46620592 -1.46619208 -1.46620736 -1.46619383 -1.46617469\n -1.46620932 -1.46616527 -1.4661875  -1.46626449 -1.46622805 -1.46619201\n -1.46629366 -1.46630436 -1.46638257 -1.46624457 -1.46626211 -1.46612096\n -1.46632693 -1.4662996  -1.46585236 -1.46647023 -1.46615356 -1.46612799\n -1.46493928 -1.46827122 -1.46485444 -1.46645324 -1.46409593 -1.46401756\n -1.4607695  -1.47732061 -1.46054953 -1.46392328 -1.45439216 -1.46757238\n -1.44285963 -1.50632659 -1.45015216 -1.43944172 -1.41436079 -1.50235994\n -1.40100674 -1.58738669 -1.72084569 -1.67722557 -1.40766793 -1.10759308\n -1.39437708 -1.05325004 -1.32596324 -1.66928882 -2.10151011 -2.64564449\n  0.        ]",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch1"
    ]
  },
  {
    "objectID": "수치해석1.html#수치적-불안정성과-악조건",
    "href": "수치해석1.html#수치적-불안정성과-악조건",
    "title": "수치해석학 Ch1",
    "section": "수치적 불안정성과 악조건",
    "text": "수치적 불안정성과 악조건\n수치적 불안정성 : 알고리즘이 rounding error를 증폭시켜 결과값이 크게 달라짐\n악조건 : input data의 작은 변동이 output solution에 큰 변화를 일으킴\n\n행렬의 조건수\n문제 f(x)의 해가 x(input)에 얼마나 영향을 받는지 나타내는 값\n탄력성의 절대값 : \\(cond(f(x))\\approx\\frac{|xf'(x)|}{|f(x)|}\\)\n탄력성의 절대값이 크면 악조건임\nLinear system에서 행렬의 조건수 \\(k(A)=||A^{-1}||\\;||A||\\)\n\\(조건수&gt;1/\\sqrt{eps}\\approx 6.7\\times 10^7\\)이면 약조건 우려",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch1"
    ]
  },
  {
    "objectID": "수치해석1.html#알고리즘의-계산-복잡도",
    "href": "수치해석1.html#알고리즘의-계산-복잡도",
    "title": "수치해석학 Ch1",
    "section": "알고리즘의 계산 복잡도",
    "text": "알고리즘의 계산 복잡도\n실행시간을 많이 다룰거임.\n\n알고리즘 복잡도\norder가 중요함\nbig-O를 표현식으로 쓰는데, 계산효율성이나 오차크기를 나타낼때 씀\n\\(O(n^2)\\) : 데이터를 10배 늘리면 계산이 100배 늘어남\n\\(O(n^{-2})\\) : 데이터를 10배 늘리면 오차가 100배 감소함",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch1"
    ]
  },
  {
    "objectID": "수치해석2.html",
    "href": "수치해석2.html",
    "title": "수치해석학 Ch2",
    "section": "",
    "text": "Cholesky factorization\n춀레스키 분해\n\\(Ax=b\\)에서, A가 대칭이고 positive-definite인 경우 적용 가능.\nPLU보다 연산량이 적음.\n다변량 정규분포 난수를 생성할 때, 공분산행렬에 춀레스키 분해를 적용하면 쉽게 생성 가능.",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch2"
    ]
  },
  {
    "objectID": "수치해석2.html#qr-분해",
    "href": "수치해석2.html#qr-분해",
    "title": "수치해석학 Ch2",
    "section": "QR 분해",
    "text": "QR 분해",
    "crumbs": [
      "수치해석학('24 가을)",
      "수치해석학 Ch2"
    ]
  },
  {
    "objectID": "수치해석실습.html",
    "href": "수치해석실습.html",
    "title": "4  수치해석기법 실습",
    "section": "",
    "text": "4.1 Ch3. Linear system",
    "crumbs": [
      "수치해석학('24 가을)",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>수치해석기법 실습</span>"
    ]
  },
  {
    "objectID": "수치해석실습.html#ch3.-linear-system",
    "href": "수치해석실습.html#ch3.-linear-system",
    "title": "4  수치해석기법 실습",
    "section": "",
    "text": "4.1.1 Equations\n\nimport numpy as np\nfrom scipy.linalg import lu\nfrom numpy.linalg import eig, cholesky, qr, svd\nimport time\n\n# 예제 행렬 A와 벡터 b 정의\nA = np.array([[1,2,3],[3,2,1],[5,1,1]], dtype=float)\nb = np.array([12,10,8], dtype=float)\n\n#\nn = 5\nA = np.random.randn(n, n)\nb = np.random.randn(n)\n\n\n###################################\n# Forward / Backward Substitution\n###################################\ndef forward(L, b):\n    # 전방 대입 (Ly = Pb)\n    y = np.zeros_like(b)\n    y[0] = b[0]/L[0,0]\n    for i in range(1,len(y)):\n        y[i] = (b[i] - np.dot(L[i, :i], y[:i])) / L[i,i]\n    return y\n\ndef backward(U, y):\n    # 후방 대입 (Ux = y)\n    x = np.zeros_like(y)\n    x[-1] = y[-1] / U[-1,-1]\n    for i in range(len(x)-2, -1, -1):\n        x[i] = (y[i] - np.dot(U[i, i+1:], x[i+1:])) / U[i, i]\n    return x\n\n\n###################################\n# LU Decomposition\n###################################\n# LU 분해 수행: A = P @ L @ U\nt0 = time.time()\nP, L, U = lu(A)\nPb = np.dot(P.T, b)\ny = forward(L, Pb)\nx = backward(U, y)\nt1 = time.time()\n\n\n# 결과 출력\nprint(\"Solution x from PLU decomposition:\")\nprint(x)\n\nprint(\"\\nSolution x from A inverse\")\nprint(np.linalg.inv(A).dot(b))\n\nSolution x from PLU decomposition:\n[ 12.76083942   2.28155216 -26.85469595 -23.45033461  28.17326524]\n\nSolution x from A inverse\n[ 12.76083942   2.28155216 -26.85469595 -23.45033461  28.17326524]\n\n\n\n###################################\n#cholesky decomposition\n###################################\n#check whether A is positive definite\neigen_values, eigen_vectors = eig(A)\nprint(eigen_values)\n#c = cholesky(A)  #error\n\n[ 0.67444857+1.16816178j  0.67444857-1.16816178j  0.08484185+0.j\n -1.10418616+0.68605571j -1.10418616-0.68605571j]\n\n\n\nB = A.T @ A\nprint(\"B = \\n\", B, '\\n')\n\nB = \n [[ 6.75980329  2.42615302 -1.43962748  3.22213589 -1.98014089]\n [ 2.42615302  3.44204392 -0.39668661  1.96145718 -0.18451717]\n [-1.43962748 -0.39668661  2.02620681  0.20972367  2.79204537]\n [ 3.22213589  1.96145718  0.20972367  2.87802662  0.9190702 ]\n [-1.98014089 -0.18451717  2.79204537  0.9190702   4.31655632]] \n\n\n\n\neigen_values, eigen_vectors = eig(B)\nprint(\"Eigen values = \", eigen_values)\n\nEigen values =  [1.07007907e+01 6.31151224e+00 2.00747918e+00 1.24979393e-03\n 4.01605076e-01]\n\n\n\nc = cholesky(B)  #A = c@c'\nprint(np.allclose(B, c@c.T), \"\\n\")\n\nTrue \n\n\n\n\ny = forward(c, b)\nx = backward(c.T, y)\nprint(\"Solution x from Cholesky decomposition:\")\nprint(x)\n\nprint(\"\\nSolution x from A inverse\")\nprint(np.linalg.inv(B).dot(b))\n\nSolution x from Cholesky decomposition:\n[ 255.85772214   52.2097322  -577.02114312 -469.10314857  592.88299097]\n\nSolution x from A inverse\n[ 255.85772214   52.2097322  -577.02114312 -469.10314857  592.88299097]\n\n\n\n###################################\n#QR decomposition\n###################################\nQ, R = qr(A)\nprint(np.allclose(A, Q@R))\n\nTrue\n\n\n\nx = backward(R, Q.T @ b)\nprint(\"Solution x from QR decomposition:\")\nprint(x)\n\nprint(\"\\nSolution x from A inverse\")\nprint(np.linalg.inv(A).dot(b))\n\nSolution x from QR decomposition:\n[ 12.76083942   2.28155216 -26.85469595 -23.45033461  28.17326524]\n\nSolution x from A inverse\n[ 12.76083942   2.28155216 -26.85469595 -23.45033461  28.17326524]\n\n\n\n###################################\n#SVD decomposition\n###################################\nU, S, Vh = svd(A)\nprint(np.allclose(A, U @ np.diag(S) @ Vh))\n\nTrue\n\n\n\nx = Vh.T @ np.diag(1/S) @ U.T @ b\nprint(\"Solution x from SVD decomposition:\")\nprint(x)\n\nprint(\"\\nSolution x from A inverse\")\nprint(np.linalg.inv(A).dot(b))\n\nSolution x from SVD decomposition:\n[ 12.76083942   2.28155216 -26.85469595 -23.45033461  28.17326524]\n\nSolution x from A inverse\n[ 12.76083942   2.28155216 -26.85469595 -23.45033461  28.17326524]\n\n\n\n\n4.1.2 Equations - time\n\nn = 1000\nA = np.random.randn(n,n)\nb = np.random.randn(n)\n\n###################################\n# LU Decomposition\n###################################\n# LU 분해 수행: A = P @ L @ U\nt0 = time.time()\nP, L, U = lu(A)\nPb = np.dot(P.T, b)\ny = forward(L, Pb)\nx = backward(U, y)\nt1 = time.time()\n\n# 결과 출력\nprint(\"\\nSolution x from PLU decomposition:\")\nprint(\"Time = \", t1-t0)\n\n###################################\n#cholesky decomposition\n###################################\nB = A.T @ A\n\nt0 = time.time()\nc = cholesky(B)  #A = c@c'\ny = forward(c, b)\nx = backward(c.T, y)\nt1 = time.time()\n\nprint(\"\\nSolution x from Cholesky decomposition:\")\nprint(\"Time = \", t1-t0)\n\n###################################\n#QR decomposition\n###################################\nt0 = time.time()\nQ, R = qr(A)\nx = backward(R, Q.T @ b)\nt1 = time.time()\n\nprint(\"\\nSolution x from QR decomposition:\")\nprint(\"Time = \", t1-t0)\n\n###################################\n#SVD decomposition\n###################################\nt0 = time.time()\nU, S, Vh = svd(A)\nx = Vh.T @ np.diag(1/S) @ U.T @ b\nt1 = time.time()\nprint(\"\\nSolution x from SVD decomposition:\")\nprint(\"Time = \", t1-t0)\n\n###################################\n#A inverse\n###################################\nprint(\"\\nSolution x from A inverse\")\nt0 = time.time()\nAinv = np.linalg.inv(A)\nx = Ainv.dot(b)\nt1 = time.time()\nprint(\"Time = \", t1-t0)\n\n###################################\n# Numpy solution\n###################################\nprint(\"\\nSolution x from Numpy solution(np.linalg.solve)\")\nt0 = time.time()\nx = np.linalg.solve(A,b)\nt1 = time.time()\nprint(\"Time = \", t1-t0)\n\n\nSolution x from PLU decomposition:\nTime =  0.025469064712524414\n\nSolution x from Cholesky decomposition:\nTime =  0.13914179801940918\n\nSolution x from QR decomposition:\nTime =  1.0981662273406982\n\nSolution x from SVD decomposition:\nTime =  0.5532040596008301\n\nSolution x from A inverse\nTime =  0.02708721160888672\n\nSolution x from Numpy solution(np.linalg.solve)\nTime =  0.00940704345703125\n\n\n\n\n4.1.3 Linear system iterative\n\nimport numpy as np\nimport matplotlib.pyplot as plt \n\n# 예제 행렬 A와 벡터 b 정의\nA = np.array([[1,2,3],[3,2,1],[5,1,1]], dtype=float)\nA = A.T@A # 이거 안하면 발산\nb = np.array([12,10,8], dtype=float)\n\nprint(\"Solution x from A inverse\")\nsol = np.linalg.inv(A).dot(b)\nprint(sol)\n\nSolution x from A inverse\n[-0.3125  2.875  -1.3125]\n\n\n\n#Gauss-Seidel\nn = len(b)\nx = np.ones(n) #initial value\nidx = np.arange(n)\niter = 50\nxs = np.empty((iter,n))\nfor j in range(iter):\n    for i in range(n):\n        mask = idx!=i\n        x[i] = (b[i] - (A[i,mask] * x[mask]).sum()) / A[i,i]\n    xs[j,:] = x\n\nplt.plot(xs,'.-')\nfor i in range(n):\n    plt.plot(np.arange(iter), np.ones(iter)*sol[i], \":y\")\n\n\n\n\n\n\n\n\n\n#SOR\nomega = 0.5\nn = len(b)\nx = np.ones(n) #initial value\niter = 50\nxs = np.empty((iter,n))\nfor j in range(iter):\n    for i in range(n):\n        x[i] = x[i] + omega * (b[i] - (A[i,:] * x).sum()) / A[i,i]\n    xs[j,:] = x\n\nplt.plot(xs,'.-')\nfor i in range(n):\n    plt.plot(np.arange(iter), np.ones(iter)*sol[i], \":y\")",
    "crumbs": [
      "수치해석학('24 가을)",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>수치해석기법 실습</span>"
    ]
  },
  {
    "objectID": "수치해석실습.html#ch4.-finite-difference-method",
    "href": "수치해석실습.html#ch4.-finite-difference-method",
    "title": "4  수치해석기법 실습",
    "section": "4.2 Ch4. Finite Difference Method",
    "text": "4.2 Ch4. Finite Difference Method\n\n4.2.1 1 factor FDM\n\nfrom FDM_blackscholes import bsprice\nfrom FDM_fdm import fdm_vanilla_option, exfdm_vanilla_option\nimport numpy as np \nimport time\n\ns = 100\nk = 100\nr = 0.03\nq = 0.01\nt = 0.25\nsigma = 0.2\noptionType = 'put'\n\n#Analytic Formula\nt0 = time.time()\nprice = bsprice(s,k,r,q,t,sigma,optionType)\nprint(f\"Analytic Price = {price:0.6f}\")\nprint(\"computation time = \", time.time()-t0, \"\\n\")\n\nmaxS, n, m = s*2, 1000, 10000\nt0 = time.time()\nv, ex_price = exfdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                   maxS, n, m)\nprint(f\"EX-FDM Price = {ex_price:0.6f}\")\nprint(\"computation time = \", time.time()-t0, \"\\n\")\n\nt0 = time.time()\nv, ex_price = fdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                   maxS, n, m, 0)\nprint(f\"EX-FDM Price = {ex_price:0.6f}\")\nprint(\"computation time = \", time.time()-t0, \"\\n\")\n\nt0 = time.time()\nv, im_price = fdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                   maxS, n, m)\nprint(f\"IM-FDM Price = {im_price:0.6f}\")\nprint(\"computation time = \", time.time()-t0, \"\\n\")\n\nt0 = time.time()\nv, cn_price = fdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                   maxS, n, m, 0.5)\nprint(f\"CN-FDM Price = {cn_price:0.6f}\")\nprint(\"computation time = \", time.time()-t0, \"\\n\")\n\nAnalytic Price = 3.724086\ncomputation time =  0.000476837158203125 \n\nEX-FDM Price = 3.723938\ncomputation time =  0.09713983535766602 \n\nEX-FDM Price = 3.723938\ncomputation time =  0.6065318584442139 \n\nIM-FDM Price = 3.723837\ncomputation time =  0.5502662658691406 \n\nCN-FDM Price = 3.723888\ncomputation time =  0.542182207107544 \n\n\n\n\n'''\nExplicit FDM이 빠르고 좋아보이지만, 수치적 불안정성 문제가 있을 수 있어 안쓰는게 좋음\n특히, 델타s&lt;델타t인 경우, 발산할 가능성이 큼. 변동성이 커도 발산할 가능성이 큼.\n정밀도는 s에 달려있어서 수렴성을 고려하면 잘 안써야하는게 맞음\n'''\nmaxS, n, m = s*2, 1000, 9500\nv, ex_price = exfdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                maxS, n, m)\nprint(f\"EX-FDM Price = {ex_price:0.6f}\")\n\nv, ex_price = fdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                maxS, n, m, 0)\nprint(f\"EX-FDM Price = {ex_price:0.6f}\")\n\nv, im_price = fdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                maxS, n, m)\nprint(f\"IM-FDM Price = {im_price:0.6f}\")\n\nv, cn_price = fdm_vanilla_option(s, k, r, q, t, sigma, optionType, \n                                maxS, n, m, 0.5)\nprint(f\"CN-FDM Price = {cn_price:0.6f}\")\n\nEX-FDM Price = -0.300684\nEX-FDM Price = -0.300684\nIM-FDM Price = 3.723835\nCN-FDM Price = 3.723888",
    "crumbs": [
      "수치해석학('24 가을)",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>수치해석기법 실습</span>"
    ]
  },
  {
    "objectID": "리스크관리1.html",
    "href": "리스크관리1.html",
    "title": "금융시장 리스크관리",
    "section": "",
    "text": "Lecture2 : How Traders Manage Their Risks?\nGreeks letters & Scenario analysis",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리"
    ]
  },
  {
    "objectID": "리스크관리1.html#lecture2-how-traders-manage-their-risks",
    "href": "리스크관리1.html#lecture2-how-traders-manage-their-risks",
    "title": "금융시장 리스크관리",
    "section": "",
    "text": "Delta hedging\n\\(\\Delta=\\frac{\\partial P}{\\partial S}\\)\n가장 기본적인 헷징방법으로, 파생상품과 같은 금융상품으로 구성된 포트폴리오에 대해\n기초자산의 가격변동에 대한 민감도인 델타를 계산하여 이를 0으로 만듦으로써\n기초자산의 가격변화로 인한 포트폴리오의 가치변화를 0으로 만드는 방법.\n포트폴리오의 payoff가 선형이라면, 한번의 헷징만으로 완전헷지(perfect hedge)가 가능\n이를 Hedge and forget이라고 함.\n그러나 비선형이라면, 기초자산의 가격변동에 따라 델타도 변하게 됨.\n\n\n\n\n\n\n델타헷지 예시\n\n\n\n은행이 특정 주식 10만주에 대한 콜옵션을 30만불에 매도할 수 있음.\n블랙숄즈공식에 따른 이 옵션의 가치는 24만불 (\\(S_0=49,K=50,r=0.05,\\sigma=0.2,T=20w\\))\n어떻게 6만불의 차익거래를 실현시킬지?\n\n풋콜페리티 또는 시장에서 동일한 옵션을 24만불에 매수하여 실현\n그러나, 옵션매수가 불가능한 경우 기초자산 주식을 이용한 델타헷징을 반복\n\n즉, 옵션 매도포지션의 델타만큼 주식을 매수하고 매주 리밸런싱\n20주 후 주식 매도수를 반복하여 구축한 델타헷징은 약 26만불의 비용이 발생하였음\n-&gt; 약 4만불의 차익거래를 실현함\n2만불은 어디로 증발함? : 델타헷징에 드는 비용 (거래비용 등)\n헷지를 자주할수록, 거래비용이 적을수록, 기초자산의 가격변동이 작을수록 차익은 6만불로 수렴\n\n\n기초자산을 이용한 델타헷징은 비용이 발생할수밖에 없음.\n콜옵션을 기준으로 할 때, 기초자산의 가격이 상승하면 콜옵션의 머니니스가 증가하면서 델타가 증가함.\n콜옵션 매도를 델타헷징하다보면, 주가 상승 -&gt; 델타 상승 -&gt; 주식 매수\n반대로, 주가 하락 -&gt; 델타 감소 -&gt; 주식 매도\n즉, 주식이 오르면 팔고 내리면 팔아야함 (Sell low, Buy high Strategy)\n\n\n기타 그릭스\nGamma (\\(\\Gamma=\\frac{\\partial\\Delta}{\\partial S}=\\frac{\\partial^2P}{\\partial S^2}\\))\n베가 로 그런거는 대충넘어갔음\n\n\nTaylor Series Expansion\n테일러 전개는 다항전개식의 일종으로, 복잡한 함수를 다항함수를 이용하여 간단히 전개할 수 있어 근사식에 많이 활용\n\\[f(x)=f(x_0)+f'(x_0)(x-x_0)+\\frac{1}{2}f''(x_0)(x-x_0)^2+\\dotsm\\]\n금융시장에서 이를 적용한다면? \\(f(x)\\)는 포트폴리오의 가격함수이며, \\(x\\)는 기초자산가격으로 대입 가능\n\\(\\Rightarrow f(x)-f(x_0)=f'(x_0)(x-x_0)+\\frac{1}{2}f''(x_0)(x-x_0)^2\\)\n\\(\\Rightarrow \\Delta f(x)=f'(x_0)\\Delta x+\\frac{1}{2}f''(x_0)\\Delta x^2\\)\n기초자산의 변화(\\(\\Delta x\\))에 따른 포트폴리오 가치변화(\\(\\Delta f\\))는 델타(듀레이션) 및 감마(컨벡시티)로 근사 가능\n포트폴리오 \\(P\\)를 기초자산의 가격 및 시간에 따른 함수 \\(P(S,t)\\)라고 한다면, (변동성은 상수로 가정)\n\\[\\Delta P=\\frac{\\partial P}{\\partial S}\\Delta S+\\frac{\\partial P}{\\partial t}\\Delta t+\\frac{1}{2}\\frac{\\partial^2P}{\\partial S^2}\\Delta S^2+\\frac{1}{2}\\frac{\\partial^2P}{\\partial t^2}\\Delta t^2+\\frac{\\partial^2P}{\\partial S\\partial t}\\Delta S\\Delta t+\\dotsm\\]\n일반적으로 \\(\\Delta t^2=0, \\Delta S\\Delta t=0\\)으로 가정하므로,\n\\[\\Rightarrow \\Delta P\\approx \\frac{\\partial P}{\\partial S}\\Delta S+\\frac{\\partial P}{\\partial t}\\Delta t+\\frac{1}{2}\\frac{\\partial^2P}{\\partial S^2}\\Delta S^2\\]\n즉, 포트폴리오의 가치변화는 델타, 세타, 감마로 표현되며 델타중립 포트폴리오를 구성했다면,\n\\[\\Delta P=\\Theta \\Delta t+\\frac{1}{2}\\Gamma \\Delta S^2\\]\n\n\n\n\n\n\nNote\n\n\n\n아래로 볼록한 형태인 옵션 매수는 positive gamma,\n위로 볼록한 형태인 옵션 매도는 negative gamma (관리 어려움)\n\n\n만약 변동성이 변수라면?\n\\(\\Delta P=\\delta \\Delta S+Vega\\Delta\\sigma+\\Theta\\Delta t+\\frac{1}{2}\\Gamma\\Delta S^2\\)\n\n\nHedging in practice\n델타헷징은 보통 매일하고, 감마나 베가는 영향이 매우 크지는 않아서 모니터링하다가,\n일정 임계치를 넘어가면 헷지 시작(헷지도 어렵고 비용도 보다 많이 듬)\n특히, 만기가 임박한 ATM옵션은 감마와 베가가 매우 크므로, 주로 관리하게됨",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리"
    ]
  },
  {
    "objectID": "리스크관리1.html#lecture3-volatility",
    "href": "리스크관리1.html#lecture3-volatility",
    "title": "금융시장 리스크관리",
    "section": "Lecture3 : Volatility",
    "text": "Lecture3 : Volatility\nStandard approach to estimating Volatility\n\\(\\sigma_n^2=\\frac{1}{m-1}\\sum_{i=1}^m(u_{n-i}-\\bar{n})^2\\;for\\;u_i=\\ln(\\frac{S_i}{S_{i-1}})\\)\nSimplify, \\(\\sigma_n^2=\\frac{1}{m}\\sum_{i=1}^mu_{n-i}^2\\;for\\;u_i=\\frac{S_i-S_{i-1}}{S_{i-1}},\\bar{u}=0\\)\n\nWeighting Schemes\n$\\(\\sigma_n^2=\\sum_{i=1}^m\\alpha_iu_{n-i}^2\\;for\\;\\sum_i\\alpha_i=1\\)\nEWMA(Exponentially Weighted Moving Average) : \\(\\alpha_{i+1}=\\lambda\\alpha_i\\;where\\;0&lt;\\lambda&lt;1\\)\nARCH, GARCH 등등 많음\n\n\n최대우도법, Maximum Likelihood Method\n최대우도법이란, 우리에게 주어진 데이터가 있고, 이 데이터가 어떠한 분포를 따르는지 추정하기 위함.\n\n주어진 데이터가 있고\n어떤 분포를 따르는지 사전에 설정함\n분포에 따라 추정이 필요한 파라미터 \\(\\theta_n\\)이 생길 때,\n주어진 데이터에 대한 확률밀도함수의 곱(독립된 결합밀도함수)을 최대화시키는 \\(\\theta\\)를 찾는 것이 목표\n즉, 확률을 최대화시키는 파라미터를 추정하여 추정분포를 결정함\n\n주가수익률의 관측치 \\(u_i\\)가 평균이 0인 정규분포를 따른다고 가정한다면?\n변동성 \\(\\sigma\\)를 추정하기 위해 최대우도법을 사용할 수 있음.\nMaximize : \\(ML=\\Pi_{i=1}^n[\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{\\frac{-u_i^2}{2\\sigma}}]\\)\n\\(y=x\\)와 \\(y=\\ln x\\)는 일대일대응관계가 성립하므로, log transform을 통해\nSame to maximize : \\(\\ln ML=\\sum_{i=1}^n[\\ln(\\frac{1}{\\sqrt{2\\pi\\sigma^2}}e^{\\frac{-u_i^2}{2\\sigma^2}})]=n\\ln(\\frac{1}{\\sqrt{2\\pi\\sigma^2}})-\\frac{1}{2\\sigma^2}\\sum_{i=1}^nu_i^2\\)\n위 식을 \\(\\sigma\\)에 대해 다시 정리하면, \\(n\\ln(\\frac{1}{\\sqrt{2\\pi}})-\\frac{n}{2}\\ln(\\sigma^2)-\\sum u_i^2\\frac{1}{2\\sigma^2}\\)\n\\(\\sigma^2\\)에 대해 미분을 통해, \\(\\ln ML_{\\sigma^2}=-\\frac{n}{2\\sigma^2}+\\frac{\\sum u_i}{2(\\sigma^2)^2}\\)\n미분계수가 0인 점이 ML 함수를 극대화 시키는 점이므로, \\(-\\frac{n}{2\\sigma^2}+\\frac{\\sum u_i}{2(\\sigma^2)^2}=0\\)\n\\(\\Rightarrow\\;n\\sigma^2=\\sum u_i,\\;\\therefore\\;\\sigma^2=\\frac{\\sum u_i}{n}\\)\n\n\nCharacteristics of Volatility\n상수는 아님\n근데 경향성이 있음 (persistence), 따라서 모아놓으면 군집화 경향이 있음 (Clustering)\n평균회귀 성향이 있음 (mean reverting)\n주가수익률과 음의 상관관계가 있음. (경기침체에 변동성 증가)\n근데 EWMA, GARCH는 이런 음의 상관관계를 반영하지는 않음\n\n\nHow Good is the Model?\n변동성 모델을 평가할 때, 일반적으로 \\(u_n\\sim N(0,\\sigma_n^2)\\)을 따르므로\n\\(\\frac{u_n}{\\sigma_n}\\sim Z\\)를 통해서 검증함.\n이 의미는, 매일매일 자산수익률과 모델변동성을 통해 독립된 Z분포를 따르는 \\(z_n=\\frac{u_n}{\\sigma_n}\\)을 생성할 수 있고\n이 \\(z_n\\)은 서로 독립인지를 봄으로써 검증할 수 있음.\n이건 Ljung-Box Test로 널리 알려져 있음.\n\\(z_n\\)을 통해 autocorrelation=0(H0)임을 검증하는 테스트임.",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리"
    ]
  },
  {
    "objectID": "리스크관리1.html#lecture6-value-at-risk-and-expected-shortfall",
    "href": "리스크관리1.html#lecture6-value-at-risk-and-expected-shortfall",
    "title": "금융시장 리스크관리",
    "section": "Lecture6 : Value at Risk and Expected Shortfall",
    "text": "Lecture6 : Value at Risk and Expected Shortfall\nVaR : 임계값\nExpected Shortfall : \\(E[loss\\;|\\;loss&gt;VaR]\\)\n\nProperties of Coherent Risk Measures\n\nMonotonicity : if \\(X\\leq Y\\) then \\(\\eta(X)\\geq\\eta(Y)\\)\nTranslation invariance : For \\(K&gt;0,\\;\\eta(X+K)=\\eta(X)-K\\)\nPositive homogeneity : For \\(I&gt;0,\\;\\eta(IX)=I\\times\\eta(X)\\)\nSubadditivity : \\(\\eta(X+Y)\\leq\\eta(X)+\\eta(Y)\\)\n\n\n\nVaR vs. ES\nVaR은 Subadditivity 만족하지 않음.\nES는 다 만족함.",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리"
    ]
  },
  {
    "objectID": "리스크관리hw1.html",
    "href": "리스크관리hw1.html",
    "title": "금융시장 리스크관리 과제1",
    "section": "",
    "text": "Question 1-3",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리 과제1"
    ]
  },
  {
    "objectID": "리스크관리hw1.html#question-1-3",
    "href": "리스크관리hw1.html#question-1-3",
    "title": "금융시장 리스크관리 과제1",
    "section": "",
    "text": "Answer\n주어진 기간의 코스피지수에 대한 GARCH(1,1) 모델의 파라미터는 아래와 같습니다.\n\\(\\omega=0.00000363,\\;\\alpha=0.115,\\;\\beta=0.844\\)\n이 모델을 이용하여 추정한 2020년 8월 3일 장 종료 후 코스피지수의 연환산 변동성은 약 13.4%입니다.\n위 내용의 산출과정은 아래와 같습니다.\n\n주어진 코스피 지수의 일별 값(Sheet1)을 C열에 채운다. (vlookup 사용)\n코스피 지수의 일별 산술수익률을 D열에 채운다. (\\(r_i=\\frac{p_i-p_{i-1}}{p_{i-1}}\\))\nGARCH(1,1) 모델의 파라미터 초기값을 이용하여 당일 장 종료 시점의 추정 분산을 산출하고, E열에 채운다. (\\(\\sigma_i^2=\\omega+\\alpha r_i^2+\\beta \\sigma_{i-1}^2\\))\n일별 추정분산을 이용하여 일별 로그우도값(\\(LH=-\\ln \\sigma^2_i-\\frac{r_i^2}{\\sigma^2}\\))을 계산하여 F열에 채우고, 이를 모두 더하여 전체 우도값을 산출한다.\n전체 우도값을 최대화시키는 파라미터를 solver 기능을 이용하여 추정한다.\n적정 파라미터를 추정하였으면, 8/3일의 분산값을 통해 연환산 변동성을 산출한다. (\\(\\sigma_{annual}=\\sqrt{252}\\sigma_{8.3}\\))",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리 과제1"
    ]
  },
  {
    "objectID": "리스크관리hw1.html#question-4-6",
    "href": "리스크관리hw1.html#question-4-6",
    "title": "금융시장 리스크관리 과제1",
    "section": "Question 4-6",
    "text": "Question 4-6\n\n\nAnswer 4-5\n주어진 기간의 코스피지수에 대한 EWMA 모델의 파라미터 \\(\\lambda=0.934\\)입니다.\n이 모델을 이용하여 추정한 2020년 8월 3일 장 종료 후 코스피지수의 연환산 변동성은 약 17.6%입니다.\n위 내용의 산출 과정은 아래와 같습니다.\n\n주어진 코스피 지수의 일별 값(Sheet1)을 C열에 채운다. (vlookup 사용)\n코스피 지수의 일별 산술수익률을 D열에 채운다. (\\(r_i=\\frac{p_i-p_{i-1}}{p_{i-1}}\\))\nEWMA 모델의 람다 초기값을 이용하여 당일 장 종료 시점의 추정 분산을 산출하고, E열에 채운다. (\\(\\sigma_i^2=\\lambda \\sigma_{i-1}^2+(1-\\lambda)r_i^2\\))\n일별 추정분산을 이용하여 일별 로그우도값(\\(LH=-\\ln \\sigma^2_i-\\frac{r_i^2}{\\sigma^2}\\))을 계산하여 F열에 채우고, 이를 모두 더하여 전체 우도값을 산출한다.\n전체 우도값을 최대화시키는 람다를 solver 기능을 이용하여 추정한다.\n적정 파라미터를 추정하였으면, 8/3일의 분산값을 통해 연환산 변동성을 산출한다. (\\(\\sigma_{annual}=\\sqrt{252}\\sigma_{8.3}\\))\n\n\n\nAnswer 6\n\n2018년 ~ 2020년 8월 4일까지 코스피 지수(회식 면) 및 GARCH(적색), EWMA(청색)을 도식화하였습니다.\n먼저, 전체적인 추세를 볼 때 GARCH(1,1) 모형과 EWMA 모형이 추정한 일 변동성은 크게 다르지 않습니다. 근본적으로 GARCH(1,1) 모형에서 장기변동성을 제외한 모형이 EWMA이며, GARCH(1,1)의 세 파라미터 중 장기변동성의 가중치가 가장 낮기 때문입니다.\n두 번째로는, 코스피 지수(회색 면)의 하락폭이 클 때 모델의 추정변동성이 급등하는 경향이 있습니다. 이러한 경향은 2020년 3월경 코로나19 펜데믹으로 인해 주가가 매우 큰 폭으로 급락하였을 때 잘 나타납니다. 주가는 상승할 때는 완만히 상승하다가 하락할 때는 급락하는 경향이 있는데, 두 모델이 이러한 특성을 잘 반영하여 하락시 변동성이 급등하는 현상을 잘 표현하는 것으로 보입니다.\n모델의 식을 생각해보면, 우리가 사용한 모델에서 GARCH(1,1)은 약 11.5%(\\(\\alpha\\)), EWMA는 약 6.6%(\\(1-\\lambda\\))만큼 당일 수익률의 제곱을 추정변동성에 반영하고 있습니다. 따라서, 주가가 오늘 급등락하였다면 해당 비율만큼 추정변동성에 영향을 주게되고, 그 급등락이 클수록 추정변동성이 급등하게 되는 것 입니다.\n한편, 두 모델의 차이는 이러한 변동성 급등 및 평균회귀(mean reverting) 과정에서 잘 나타납니다. 먼저, 급등시에는 당일 주가수익률의 반영비율이 큰 GARCH(1,1) 모형의 추정변동성이 더 급등하는 패턴을 관측할 수 있습니다.(적색&gt;청색)\n다음으로, 변동성이 급등하고나서 시간이 지남에 따라 반영비율이 희석되면서 변동성이 평균 수준으로 회귀하게 되는데, 이때에도 당일 주가수익률의 반영비율이 큰, 직전 추정변동성의 반영비율이 상대적으로 낮은 GARCH(1,1) 모형의 회귀 속도가 빠르게 됩니다. 이러한 패턴은 20년 3월 변동성 급등 이후 20년 6월경까지 변동성이 하락할 때 잘 관측됩니다.\n추가적으로, GARCH(1,1) 모형은 그 반영비율이 낮기는 하지만 장기변동성을 포함하여 변동성을 추정하기 때문에, 역시 EWMA보다 평균회귀가 빠른 이점을 가지게 됩니다. 따라서, 일시적인 주가 급등락으로 변동성이 급등하는 경우에는 GARCH(1,1) 모형이 정상수준으로 잘 회귀한다는 점에서 EWMA보다 적합한 모형인 것으로 보입니다.",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리 과제1"
    ]
  },
  {
    "objectID": "리스크관리hw1.html#question-7-8",
    "href": "리스크관리hw1.html#question-7-8",
    "title": "금융시장 리스크관리 과제1",
    "section": "Question 7-8",
    "text": "Question 7-8\n\n\nAnswer 7\nEWMA의 \\(\\lambda\\)가 증가한다는 의미는, 변동성을 추정할 때 최신 데이터의 반영비율을 늘린다는 의미입니다.\nEWMA는 \\(\\sigma_i^2=\\sum_k \\lambda r_{i-k}^2\\)의 방식으로 변동성을 추정하는데, 여기에서 람다값이 증가하면 가장 최근에 형성된 수익률이 보다 많이 반영되게 됩니다.\n따라서, 최근 주가흐름이 추정변동성에 미치는 영향이 커지게 되므로, 급등락장이 이어졌다면 추정 변동성이 보다 빠르게 급등할 것이고, 보합장이 이어졌다면 추정변동성이 빠르게 감소할 것으로 보입니다.\n\n\nAnswer 8\n주어진 파라미터와 현재 일 변동성이 1%임을 활용하여 30일 변동성을 산출하겠습니다.\n이 때 이용하는 수식은 \\(E[\\sigma^2_{n+30}|I_{n-1}]=V_L+(\\alpha+\\beta)^{30}(\\sigma^2_n-V_L)\\) 입니다.\n먼저, 장기변동성 \\(V_L=\\frac{\\omega}{1-\\alpha-\\beta}=0.0002045\\)입니다.\n이에 따라 현재까지의 정보를 이용하여 30일 뒤의 일변동성을 추정하면 약 1.09%가 됩니다.\n\\[E[\\sigma^2_{n+30}|I_{n-1}]=0.0002045+0.9934^{30}(0.01^2-0.0002045)=0.0001188\\]\n\\[E[\\sigma_{n+30}|I_{n-1}]=\\sqrt{E[\\sigma^2_{n+30}|I_{n-1}]}=\\sqrt{0.0001188}=1.09\\%\\]",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리 과제1"
    ]
  },
  {
    "objectID": "리스크관리hw1.html#question-9",
    "href": "리스크관리hw1.html#question-9",
    "title": "금융시장 리스크관리 과제1",
    "section": "Question 9",
    "text": "Question 9\n\n\n\n\n\n\n\nAnswer\n먼저, 목표는 1% 이하의 확률로 발생할 수 있는 포트폴리오의 손실액을 찾는 것입니다. 이는 포트폴리오의 확률분포를 통해 알 수 있으며, CDF에서 하위 1% 임계값을 통해 계산할 수 있습니다. 이 의미는, 향후 시장상황에 따라 약 1%의 확률로 해당 임계값보다 큰 손실이 발생할 수 있다는 뜻이며, 이를 VaR(Value at Risk)라고 부릅니다.\n이제 문제에서 주어진 정보를 이용하여 이 임계값을 계산해보겠습니다.\n문제에서 \\(PC_1,PC_2\\)는 각각 평균이 0인 정규분포를 따르므로, 각각의 표준편차를 \\(\\sigma_1,\\sigma_2\\)라고 하겠습니다.\n이에 따라 포트폴리오의 가격변동 \\(\\Delta P=0.05PC_1-3.88PC_2\\)는 두 정규분포의 선형결합이므로 joint normal distribution이 되고, 각 \\(PC\\)는 평균이 0, 독립임을 이용하여 \\(\\Delta P\\)의 평균과 표준편차 \\(\\sigma\\)는 아래와 같이 계산할 수 있습니다.\n\\(1.\\;E[\\Delta P]=0.05E[PC_1]-3.88E[PC_2]=0\\)\n\\(2.\\;\\sigma^2=E[\\Delta P^2]-(E[\\Delta P])^2=0.05^2\\sigma_1^2+3.88^2\\sigma_2^2\\)\n\n\n\n\n\n\n정규분포이고 독립인 두 확률변수 \\(X,Y\\)에 대해 \\(E[XY]=E[X]E[Y]\\)가 성립합니다.\n따라서, \\(E[\\Delta P^2]=E[0.05^2PC_1^2-2\\times 0.05\\times 3.88 PC_1PC_2+3.88^2PC_2^2]\\)\n\\(\\;\\;\\;\\;\\;\\;\\;\\;=0.05^2E[PC_1^2]+3.88^2E[PC_2^2]=0.05^2\\sigma_1^2+3.88^2\\sigma_2^2\\)\n\n\n\n즉, \\(\\Delta P\\sim N(0,\\;0.05^2\\sigma_1^2+3.88^2\\sigma_2^2)\\)이므로 각 \\(PC\\)의 표준편차를 알면 1% 임계값을 알 수 있습니다. Table2에 따라 \\(\\sigma_1=17.55,\\;\\sigma_2=4.77\\)이므로 이를 이용하면,\n\\(\\sigma^2=0.05^2\\sigma_1^2+3.88^2\\sigma_2^2=343.30,\\;\\;\\therefore\\sigma=18.53\\)\n\\(z_{0.01}=-2.33\\)임이 잘 알려져 있으므로, 1% 임계값은 \\(-2.33\\sigma\\approx -43.17\\)입니다.\n따라서, 약 1% 확률로 발생할 수 있는 포트폴리오의 예상손실액은 최소 43.17 million $ 입니다.",
    "crumbs": [
      "금융시장 리스크관리('24 가을)",
      "금융시장 리스크관리 과제1"
    ]
  },
  {
    "objectID": "미시1.html",
    "href": "미시1.html",
    "title": "미시경제학 Ch1",
    "section": "",
    "text": "Law of demand\n가격이 상승하면 수요는 하락하고, 가격이 하락하면 수요는 증가한다\nwhen Other things equal(ceteris paribus)\n따라서, x축이 수요량이고 y축이 가격일 때 수요곡선은 우하향함",
    "crumbs": [
      "미시경제학('24 가을)",
      "미시경제학 Ch1"
    ]
  },
  {
    "objectID": "미시1.html#law-of-demand",
    "href": "미시1.html#law-of-demand",
    "title": "미시경제학 Ch1",
    "section": "",
    "text": "Other things?\n이는 수요곡선 자체를 변화시키는 모든 변수 일체를 의미함.\n\nIncome : normal goods vs. inferior goods\nNumber of buyers\nSubstitutes vs. Complements\nTastes\n\n\n1. Income\n일반적인 재화는 소득이 증가하면 수요가 증가함.\n즉, 수요곡선을 오른쪽으로 평행이동시킴 Normal Goods\n그러나, 대중교통이나 감자같은 재화는 소득이 증가하면 오히려 수요가 감소할 수 있음.\n이 경우는 수요곡선을 왼쪽으로 평행이동시킴 Inferior Goods\n이는 재화에 따라 고정되어있지 않으며,\n때로는 소득수준이 증가함에 따라 수요가 증가하는 Normal goods였다가 소득수준이 더 크게 증가하면 수요가 감소하는 Inferior goods가 되기도 함. (e.g. Hamburger)\n\n\n2. Substitutes vs. Complements\n대체제(e.g. 맥도날드, 버거킹)는 대체관계에 있는 재화들로, 대체제의 수요가 감소하면 재화의 수요가 증가함.\n즉, 대체제의 가격상승은 재화의 수요곡선을 우측 평행이동시킴\n보완재(자동차, 기름)은 상호보완관계에 있는 재화로, 보완재의 수요가 증가하면 재화의 수요가 감소함. 보완재 가격상승은 수요곡선 좌측 평행이동\n\n\n이외의 수요곡선을 이동시키는건 매우 많을 수 있음\n중요한건, 특정재화의 수요에 영향을 미치는 방법은\n\n다른 요소를 건드려서 수요곡선 자체를 이동시키거나\n재화의 가격을 건드려서 수요곡선 내에서 이동시키는거임",
    "crumbs": [
      "미시경제학('24 가을)",
      "미시경제학 Ch1"
    ]
  },
  {
    "objectID": "미시1.html#law-of-supply",
    "href": "미시1.html#law-of-supply",
    "title": "미시경제학 Ch1",
    "section": "Law of Supply",
    "text": "Law of Supply\n공급의 법칙\n똑같음. 가격이 올라가면 공급이 늘어나고 감소하면 공급도 감소함\n따라서 일반적으로 우상향하는 공급곡선이 나타남.\n언제? 다른 모든 것들이 동일할 때\n\n공급곡선의 이동\n\n생산가격 Input price\nTechnology\nNumber of sellers\n\n\n1. Input price\n생산단가가 감소하면 공급은 증가함. 공급곡선 우측 이동\n생산단가 증가 - 공급량 감소 - 곡선 좌측 이동\n\n\n2. Technology\n기술수준이 상승하면 생산단가가 감소함. 공급곡선 우측이동.\na+b a+b+c+f+g c+f+g\nc+d c+d+b+e b+e\nsubsidy expenditure b+c+e+f+g+h\nb+c+e+f+g -b-c-e-f-g-h -h : dead weight loss",
    "crumbs": [
      "미시경제학('24 가을)",
      "미시경제학 Ch1"
    ]
  },
  {
    "objectID": "미시hw1.html",
    "href": "미시hw1.html",
    "title": "Microanalysis of financial economics Assignment1",
    "section": "",
    "text": "Sample Question",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment1"
    ]
  },
  {
    "objectID": "미시hw1.html#sample-question",
    "href": "미시hw1.html#sample-question",
    "title": "Microanalysis of financial economics Assignment1",
    "section": "",
    "text": "Answer\nBecomes more expensive for steel production\n-&gt; Increase input prices for steel production\n-&gt; Supply curve shifts to the left.\nReduced the demand for steel products\n-&gt; Decrease number of buyers for steel production\n-&gt; Demand curve shifts to the left.\nBoth curves will shift to the left side,\nso NEW equilibrium point also shift to the left side.\nIt is clear that NEW equilibrium quantity will increase, but price is not.\nWhether equilibrium price increase or not, it depends on how each curves shifts and their elasticity.\n\n\n\nSample question",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment1"
    ]
  },
  {
    "objectID": "미시hw1.html#assignments-1",
    "href": "미시hw1.html#assignments-1",
    "title": "Microanalysis of financial economics Assignment1",
    "section": "Assignments 1",
    "text": "Assignments 1\n\n\nAnswer\nWe can say that price elasticity, \\(E_p=\\frac{\\frac{\\Delta Q}{Q}}{\\frac{\\Delta P}{P}}=\\frac{P}{Q}\\frac{\\Delta Q}{\\Delta P}\\)\nSince \\(P_0=3.46,\\;Q_0^D=Q_0^S=2630\\) and \\(\\frac{\\Delta Q^D}{\\Delta P^D}=-266,\\;\\frac{\\Delta Q^S}{\\Delta P^S}=240\\),\nPrice elasticity of Demand is \\(\\frac{3.46}{2630}\\times -266\\approx -0.35\\).\nPrice elasticity of Supply is \\(\\frac{3.46}{2630}\\times 240\\approx 0.32\\)",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment1"
    ]
  },
  {
    "objectID": "미시hw2.html",
    "href": "미시hw2.html",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "",
    "text": "Question 1",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw2.html#question-1",
    "href": "미시hw2.html#question-1",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "",
    "text": "Answer1",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw2.html#question-2",
    "href": "미시hw2.html#question-2",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "Question 2",
    "text": "Question 2\n\n\nAnswer2\n1. Increase\nBecause of hurricane, input price of coffee bean will increase, supply curve of coffee bean shift to the left.\nSo, price of coffee beans will increase.\n2. Both increase\nSince price of coffee beans increases, input price of cups of coffee will increase, supply curve of coffee shift to the left.\nso, price of cups of coffee will increase and quantity will decrease.\nBy the question, cups of coffee have inelastic demand.\nso, \\(P\\times Q&lt;(P+\\Delta P)(Q-\\Delta Q)\\). Total revenue increases.\n3. Both decrease\nSince cups of coffe and donuts are complements, increase of price of cups of coffee causes decrease of demand of donuts.\nSo, demand curve of donuts shift to the left, price and quantity will decrease.\nTherefore, Total revenue of donuts decrease.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw2.html#question-3",
    "href": "미시hw2.html#question-3",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "Question 3",
    "text": "Question 3\n\n\nAnswer 3\n\nsellers bear more burden of the tax than buyers.\nbuyers bear more burden of the tax than sellers.\nboth participants bear same burden of the tax.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw2.html#question-4",
    "href": "미시hw2.html#question-4",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "Question 4",
    "text": "Question 4\n\n\nAnswer 4\n1. P=100, Q=200\n\\(Q^S=Q^D\\;\\;\\Rightarrow\\;\\;2P=300-P\\;\\;\\therefore P=100,Q=200\\)\n2. Yes. \\(P=90\\;Q^S=180,\\;Q^D=210,\\;Shortage=30\\)\n3. No. \\(P=100,\\;Q^S=Q^D=200\\)\n4. No. \\(P^*=120,\\;Q^{S^*}=Q^{D^*}=180\\)",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw2.html#question-5",
    "href": "미시hw2.html#question-5",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "Question 5",
    "text": "Question 5\n\n\nAnswer 5\nIt depends on elasticity of labor market and ratio of using extra revenues.\nIf all of extra revenues can be used for workers, it will make workers better. (when demand of labor is not perfect elatic.)\nBut if just part of extra can be used for workers and demand is more elastic than supply in labor market, it will be different.\nWorkers bear more burden than firm when tax paid by firms raises,\nso it can make workers poor.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw2.html#question-6",
    "href": "미시hw2.html#question-6",
    "title": "Microanalysis of financial economics Assignment2",
    "section": "Question 6",
    "text": "Question 6\n\n1. Less than 2%\n2% tax-cut of workers makes supply curve shifting to the right in labor market.\nSo, price of labor(wage) will decrease and its magnitude depends on elasticity of demand curve.\nIt will be less than 2% when demand curve is not zero elasticity.\nIf demand is zero elastic, it is exactly 2%.\nSince tax-cut makes workers take-home pay rises 2%,\nTotal change of workers’ take-home pay will be less than 2%.\n\nMore elastic take less benefit.\n\nBy explain (1), it depends on elasticity in labor market.\nMore elastic bear less burden of tax.\nIt means more elastic take less benefit of tax-cut.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment2"
    ]
  },
  {
    "objectID": "미시hw3.html",
    "href": "미시hw3.html",
    "title": "Microanalysis of financial economics Assignment3",
    "section": "",
    "text": "Question",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment3"
    ]
  },
  {
    "objectID": "미시hw3.html#question",
    "href": "미시hw3.html#question",
    "title": "Microanalysis of financial economics Assignment3",
    "section": "",
    "text": "Answer : (a) $200\nAt equilibrium(p=70), consumer surplus is 800(\\(20\\times 80\\times 0.5\\)) and supplier surplus is 400.(\\(20\\times 40\\times 0.5\\)) so total surplus is 1200.\nIf there exists a price floor of $110, quantity decrease to 10 and price is $110. so consumer surplus will be 200 (\\(10\\times 40 \\times 0.5\\)) and suplier surplus will be 700(\\(10\\times 60+10\\times 20\\times 0.5\\)).\nNow, total surplus decrease to 900 and deadweight loss occur 300.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment3"
    ]
  },
  {
    "objectID": "미시hw4.html",
    "href": "미시hw4.html",
    "title": "Microanalysis of financial economics Assignment4",
    "section": "",
    "text": "Question",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment4"
    ]
  },
  {
    "objectID": "미시hw4.html#question",
    "href": "미시hw4.html#question",
    "title": "Microanalysis of financial economics Assignment4",
    "section": "",
    "text": "Answer\n\nIndirect tax : 28.2%\nIncome tax : 35.1%\nCorporate tax : 24.4%\nValue-added tax : 22.4%",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment4"
    ]
  },
  {
    "objectID": "미시hw5.html",
    "href": "미시hw5.html",
    "title": "Microanalysis of financial economics Assignment5",
    "section": "",
    "text": "Question 1",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment5"
    ]
  },
  {
    "objectID": "미시hw5.html#question-1",
    "href": "미시hw5.html#question-1",
    "title": "Microanalysis of financial economics Assignment5",
    "section": "",
    "text": "Answer\n\n\\(Q_S=Q_D\\;\\Rightarrow\\;2P=300-P\\;\\Rightarrow\\;P^*=100,Q^*=200\\)\n\\(300-P-T=2P\\;\\Rightarrow\\;P^T=100-T/3,Q^T=200-2T/3\\)\n\\(T\\times Q^T=200T-2T^2/3\\)\n\\(T\\times (Q^*-Q^T)\\div 2=T^2/3\\)\nif \\(T=200\\), \\(P^T=Q^T=200/3\\) and DWL occurs the amount of \\(40000/3\\). Since the supply curve is elastic and the demand curve’s slope is 1, any policy about price control should be bad for market. Because quantity change very fast, it causes many DWL.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment5"
    ]
  },
  {
    "objectID": "미시hw5.html#question-2",
    "href": "미시hw5.html#question-2",
    "title": "Microanalysis of financial economics Assignment5",
    "section": "Question 2",
    "text": "Question 2\n\n\nAnswer\n\nIn U.S., china’s industry expands makes U.S. cloth importing supply curve shift to the right. Price goes down and quantity goes up. CS and TS should increase, but PS depends on demand curve’s elasticity. If elastic, PS will increase.\nIn export nations, demand curve shifts to the left. Both price and quantity go down. CS, PS, TS should decrease.\nImporting sides, it is good for total surplus. But exporting sides, it should be bad.",
    "crumbs": [
      "미시경제학('24 가을)",
      "Microanalysis of financial economics Assignment5"
    ]
  },
  {
    "objectID": "이자율hw2.html",
    "href": "이자율hw2.html",
    "title": "이자율파생상품 과제1",
    "section": "",
    "text": "Question 1",
    "crumbs": [
      "이자율파생상품('24 가을)",
      "이자율파생상품 과제1"
    ]
  }
]